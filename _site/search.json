[
  {
    "objectID": "resources-idx.html",
    "href": "resources-idx.html",
    "title": "R for Geospatial Data Analysis: Learning Resources",
    "section": "",
    "text": "Please check out the Resources page of the main course site, there are already many books and online publications that can support your out-of-classroom GIS learning.\nI hope this page will also be helpful by putting together urls that I mentioned in TA session.\n\n\nIn this section, I gathered the following cheatsheets for most of the packages that we have been using in this class, mainly from the Posit cheatsheets listing page, and rstudio github page\n\n\n\n\n\ntidyverse\n\n\n\n\n\n\ndplyr\ntidyr\nstringr\n\n\nreadr\npurrr\nlubridate\n\n\nggplot\n\nforcats\n\n\n\n\n\n\n\nbaseR cheatsheet\n\n\n\n\n\nsf\n\n\n\n\n\nPackage Manuals and Books\n\n\n\nsf\nspatstat\nspdep:\n\nspdep book\nspdep functions\n\nsfdep: sfdep\n\n\n\nmapview\nrnaturalearth\nr-spatial\nggplot for sf\nleaflet\n\n\n\nterra\nstars\ntidyterra\n\n\n\n\n\n\n\nGoogle the error message you received, and look for links to github issues in the results page",
    "crumbs": [
      "Coding Workshop",
      "Resources"
    ]
  },
  {
    "objectID": "resources-idx.html#extra-resources",
    "href": "resources-idx.html#extra-resources",
    "title": "R for Geospatial Data Analysis: Learning Resources",
    "section": "",
    "text": "Please check out the Resources page of the main course site, there are already many books and online publications that can support your out-of-classroom GIS learning.\nI hope this page will also be helpful by putting together urls that I mentioned in TA session.\n\n\nIn this section, I gathered the following cheatsheets for most of the packages that we have been using in this class, mainly from the Posit cheatsheets listing page, and rstudio github page\n\n\n\n\n\ntidyverse\n\n\n\n\n\n\ndplyr\ntidyr\nstringr\n\n\nreadr\npurrr\nlubridate\n\n\nggplot\n\nforcats\n\n\n\n\n\n\n\nbaseR cheatsheet\n\n\n\n\n\nsf\n\n\n\n\n\nPackage Manuals and Books\n\n\n\nsf\nspatstat\nspdep:\n\nspdep book\nspdep functions\n\nsfdep: sfdep\n\n\n\nmapview\nrnaturalearth\nr-spatial\nggplot for sf\nleaflet\n\n\n\nterra\nstars\ntidyterra\n\n\n\n\n\n\n\nGoogle the error message you received, and look for links to github issues in the results page",
    "crumbs": [
      "Coding Workshop",
      "Resources"
    ]
  },
  {
    "objectID": "w3-idx.html#outline-for-today",
    "href": "w3-idx.html#outline-for-today",
    "title": "R Coding Workshop",
    "section": "Outline for Today",
    "text": "Outline for Today\n\nBase R syntax and coding style\nR data types and data structures\n\nWorking with Vectors and Data Frames",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#base-r-syntax-and-coding-style",
    "href": "w3-idx.html#base-r-syntax-and-coding-style",
    "title": "R Coding Workshop",
    "section": "Base R syntax and coding style",
    "text": "Base R syntax and coding style",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#print-and-comment-out",
    "href": "w3-idx.html#print-and-comment-out",
    "title": "R Coding Workshop",
    "section": "print() and comment out",
    "text": "print() and comment out\n\n\"Welcome to R Coding Workshop!\"\n\n[1] \"Welcome to R Coding Workshop!\"\n\n\n\nprint(\"Welcome to R Coding Workshop!\")\n\n[1] \"Welcome to R Coding Workshop!\"\n\n2025\n\n[1] 2025\n\n\n\n⌘ + /: Commenting\n\n\n# 2025\n# command + forward slash to comment out",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#variables",
    "href": "w3-idx.html#variables",
    "title": "R Coding Workshop",
    "section": "Variables",
    "text": "Variables\n&lt;-: initialize a variable and assign a value\n\n# variable_name &lt;- variable_value\nx &lt;- 1984\ny &lt;- \"World Geodetic System\"\n\n\n\n\n\n\n\n\nR variable naming",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#r-data-types-class",
    "href": "w3-idx.html#r-data-types-class",
    "title": "R Coding Workshop",
    "section": "R Data Types class()",
    "text": "R Data Types class()\n\n\n\n“numeric”\n\ndouble\ninteger\n\n“character”\n“logical”\n\n\n\nprint(class(x))\n\n[1] \"numeric\"\n\nprint(class(y))\n\n[1] \"character\"\n\nz &lt;- class(x) == class(y)\nprint(class(z))\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n\n\n\nOperators and Logical Operators\nType Casting",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#r-data-structures",
    "href": "w3-idx.html#r-data-structures",
    "title": "R Coding Workshop",
    "section": "R Data Structures",
    "text": "R Data Structures\n\nVector\nMatrix\nArray\nFactor\nList\nData Frame",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#starting-with-vectors",
    "href": "w3-idx.html#starting-with-vectors",
    "title": "R Coding Workshop",
    "section": "Starting with Vectors",
    "text": "Starting with Vectors\n\n\nWays to create a vector\n\nc()\nseq(from, to, by)\n:\n\n\n\nv1 &lt;- c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    )\nv2 &lt;- 1:5\nv2\n\n[1] 1 2 3 4 5\n\n\n\nv3 &lt;- seq(21.9, 25.3, 0.1)\nis.vector(v2)\n\n[1] TRUE",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#subsetting-a-vector",
    "href": "w3-idx.html#subsetting-a-vector",
    "title": "R Coding Workshop",
    "section": "Subsetting a Vector",
    "text": "Subsetting a Vector\n\nIndexing\n\n\n# v1 &lt;- c(\n    # \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    # )\nv1[1]\n\n[1] \"Bryce Canyon\"\n\nv1[-1]\n\n[1] \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\n\n\nSubsetting using Logical Vectors\n\n\nv4 &lt;- 1:12\nbool_v4 &lt;- v4 &gt; 8\nv4[bool_v4]\n\n[1]  9 10 11 12\n\n\n\nAccess by name\n\n\nnames(v4) &lt;- month.abb\nv4[\"Jan\"]\n\nJan \n  1",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#data-frame-objects",
    "href": "w3-idx.html#data-frame-objects",
    "title": "R Coding Workshop",
    "section": "Data Frame objects",
    "text": "Data Frame objects\n\nThinking of data.frame as a collection of column vectors\n\nWays to create a df\n\nmth_df &lt;- data.frame(\n    mth = 1:12,\n    mth_str = month.abb\n)\nmth_df\n\n\n\n\n\nmth\nmth_str\n\n\n\n\n1\nJan\n\n\n2\nFeb\n\n\n3\nMar\n\n\n4\nApr\n\n\n5\nMay\n\n\n6\nJun\n\n\n7\nJul\n\n\n8\nAug\n\n\n9\nSep\n\n\n10\nOct\n\n\n11\nNov\n\n\n12\nDec\n\n\n\n\n\n\n\nmth_df |&gt; class()\n\n[1] \"data.frame\"\n\n\n\n\n\n\n\n\n\nimport external tabular dataset",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#data.frame-attributes",
    "href": "w3-idx.html#data.frame-attributes",
    "title": "R Coding Workshop",
    "section": "data.frame attributes",
    "text": "data.frame attributes\n\nutah_df &lt;- data.frame(\n    national_park = v1,\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\n\n\nhead(utah_df, 2)\n\n\n\n\n\nnational_park\nlat\nlon\n\n\n\n\nBryce Canyon\n37.64062\n-112.1696\n\n\nCanyonlands\n38.47878\n-109.8252\n\n\n\n\n\n\n\n# nrow() and ncol()\ndim(utah_df)\n\n[1] 5 3\n\n\n\ncolnames(utah_df)\n\n[1] \"national_park\" \"lat\"           \"lon\"",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#subsetting-data.frame",
    "href": "w3-idx.html#subsetting-data.frame",
    "title": "R Coding Workshop",
    "section": "Subsetting data.frame",
    "text": "Subsetting data.frame\n\nprint(utah_df[, 1])\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\nprint(utah_df[1, ])\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n\nprint(utah_df$national_park)\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\nutah_df[[\"national_park\"]]\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#r-list",
    "href": "w3-idx.html#r-list",
    "title": "R Coding Workshop",
    "section": "R List",
    "text": "R List\n\nA vector that allows to have elements of different data type\nNested\n\n\nsummary(utah_df)\n\n national_park           lat             lon        \n Length:5           Min.   :37.20   Min.   :-113.0  \n Class :character   1st Qu.:37.64   1st Qu.:-112.2  \n Mode  :character   Median :38.29   Median :-111.3  \n                    Mean   :38.05   Mean   :-111.2  \n                    3rd Qu.:38.48   3rd Qu.:-109.8  \n                    Max.   :38.62   Max.   :-109.6  \n\n\n\nclass(utah_df[1])\n\n[1] \"data.frame\"",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-idx.html#getting-to-sf-and-a-map",
    "href": "w3-idx.html#getting-to-sf-and-a-map",
    "title": "R Coding Workshop",
    "section": "Getting to sf and a map",
    "text": "Getting to sf and a map\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(mapview)\nutah_sf &lt;- st_as_sf(\n    utah_df,\n    coords = c('lon', 'lat'),\n    crs = 4326\n)\nutah_sf |&gt; mapview()\n\n\n\n\n\n\nutah_sf\n\n\n\n\n\nnational_park\ngeometry\n\n\n\n\nBryce Canyon\nPOINT (-112.1696 37.64062)\n\n\nCanyonlands\nPOINT (-109.8252 38.47878)\n\n\nArches\nPOINT (-109.6198 38.61676)\n\n\nZion\nPOINT (-112.987 37.20027)\n\n\nCapitol Reef\nPOINT (-111.2619 38.2916)\n\n\n\n\n\n\n\n\n\n\n\n\n\nprelude to factor class: How were the points colored? Why are we having a legend on the map?\n\nHow to avoid presenting this map",
    "crumbs": [
      "Coding Workshop",
      "Week 3"
    ]
  },
  {
    "objectID": "w3-slides.html#intro-to-coding-workshop",
    "href": "w3-slides.html#intro-to-coding-workshop",
    "title": "R Coding Workshop",
    "section": "Intro to Coding Workshop!",
    "text": "Intro to Coding Workshop!"
  },
  {
    "objectID": "w3-slides.html#outline-for-today",
    "href": "w3-slides.html#outline-for-today",
    "title": "R Coding Workshop",
    "section": "Outline for Today",
    "text": "Outline for Today\n\nBase R syntax and coding style\nR data types and data structures\n\nWorking with Vectors and Data Frames"
  },
  {
    "objectID": "w3-slides.html#base-r-syntax-and-coding-style",
    "href": "w3-slides.html#base-r-syntax-and-coding-style",
    "title": "R Coding Workshop",
    "section": "Base R syntax and coding style",
    "text": "Base R syntax and coding style"
  },
  {
    "objectID": "w3-slides.html#print-and-comment-out",
    "href": "w3-slides.html#print-and-comment-out",
    "title": "R Coding Workshop",
    "section": "print() and comment out",
    "text": "print() and comment out\n\n\"Welcome to R Coding Workshop!\"\n\n[1] \"Welcome to R Coding Workshop!\"\n\n\n\nprint(\"Welcome to R Coding Workshop!\")\n\n[1] \"Welcome to R Coding Workshop!\"\n\n2025\n\n[1] 2025\n\n\n\n⌘ + /: Commenting\n\n\n# 2025\n# command + forward slash to comment out"
  },
  {
    "objectID": "w3-slides.html#variables",
    "href": "w3-slides.html#variables",
    "title": "R Coding Workshop",
    "section": "Variables",
    "text": "Variables\n&lt;-: initialize a variable and assign a value\n\n# variable_name &lt;- variable_value\nx &lt;- 1984\ny &lt;- \"World Geodetic System\"\n\n\n\n\n\nR variable naming"
  },
  {
    "objectID": "w3-slides.html#r-data-types-class",
    "href": "w3-slides.html#r-data-types-class",
    "title": "R Coding Workshop",
    "section": "R Data Types class()",
    "text": "R Data Types class()\n\n\n\n“numeric”\n\ndouble\ninteger\n\n“character”\n“logical”\n\n\n\nprint(class(x))\n\n[1] \"numeric\"\n\nprint(class(y))\n\n[1] \"character\"\n\nz &lt;- class(x) == class(y)\nprint(class(z))\n\n[1] \"logical\"\n\n\n\n\n\n\n\nOperators and Logical Operators\nType Casting"
  },
  {
    "objectID": "w3-slides.html#r-data-structures",
    "href": "w3-slides.html#r-data-structures",
    "title": "R Coding Workshop",
    "section": "R Data Structures",
    "text": "R Data Structures\n\nVector\nMatrix\nArray\nFactor\nList\nData Frame"
  },
  {
    "objectID": "w3-slides.html#starting-with-vectors",
    "href": "w3-slides.html#starting-with-vectors",
    "title": "R Coding Workshop",
    "section": "Starting with Vectors",
    "text": "Starting with Vectors\n\n\nWays to create a vector\n\nc()\nseq(from, to, by)\n:\n\n\n\nv1 &lt;- c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    )\nv2 &lt;- 1:5\nv2\n\n[1] 1 2 3 4 5\n\n\n\nv3 &lt;- seq(21.9, 25.3, 0.1)\nis.vector(v2)\n\n[1] TRUE"
  },
  {
    "objectID": "w3-slides.html#subsetting-a-vector",
    "href": "w3-slides.html#subsetting-a-vector",
    "title": "R Coding Workshop",
    "section": "Subsetting a Vector",
    "text": "Subsetting a Vector\n\nIndexing\n\n\n# v1 &lt;- c(\n    # \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    # )\nv1[1]\n\n[1] \"Bryce Canyon\"\n\nv1[-1]\n\n[1] \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\n\n\nSubsetting using Logical Vectors\n\n\nv4 &lt;- 1:12\nbool_v4 &lt;- v4 &gt; 8\nv4[bool_v4]\n\n[1]  9 10 11 12\n\n\n\nAccess by name\n\n\nnames(v4) &lt;- month.abb\nv4[\"Jan\"]\n\nJan \n  1"
  },
  {
    "objectID": "w3-slides.html#data-frame-objects",
    "href": "w3-slides.html#data-frame-objects",
    "title": "R Coding Workshop",
    "section": "Data Frame objects",
    "text": "Data Frame objects\n\nThinking of data.frame as a collection of column vectors\n\nWays to create a df\n\nmth_df &lt;- data.frame(\n    mth = 1:12,\n    mth_str = month.abb\n)\nmth_df\n\n\n\n\n\nmth\nmth_str\n\n\n\n\n1\nJan\n\n\n2\nFeb\n\n\n3\nMar\n\n\n4\nApr\n\n\n5\nMay\n\n\n6\nJun\n\n\n7\nJul\n\n\n8\nAug\n\n\n9\nSep\n\n\n10\nOct\n\n\n11\nNov\n\n\n12\nDec\n\n\n\n\n\n\n\nmth_df |&gt; class()\n\n[1] \"data.frame\"\n\n\n\n\n\n\nimport external tabular dataset"
  },
  {
    "objectID": "w3-slides.html#data.frame-attributes",
    "href": "w3-slides.html#data.frame-attributes",
    "title": "R Coding Workshop",
    "section": "data.frame attributes",
    "text": "data.frame attributes\n\nutah_df &lt;- data.frame(\n    national_park = v1,\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\n\n\nhead(utah_df, 2)\n\n\n\n\n\nnational_park\nlat\nlon\n\n\n\n\nBryce Canyon\n37.64062\n-112.1696\n\n\nCanyonlands\n38.47878\n-109.8252\n\n\n\n\n\n\n\n# nrow() and ncol()\ndim(utah_df)\n\n[1] 5 3\n\n\n\ncolnames(utah_df)\n\n[1] \"national_park\" \"lat\"           \"lon\""
  },
  {
    "objectID": "w3-slides.html#subsetting-data.frame",
    "href": "w3-slides.html#subsetting-data.frame",
    "title": "R Coding Workshop",
    "section": "Subsetting data.frame",
    "text": "Subsetting data.frame\n\nprint(utah_df[, 1])\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\nprint(utah_df[1, ])\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n\nprint(utah_df$national_park)\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\"\n\nutah_df[[\"national_park\"]]\n\n[1] \"Bryce Canyon\" \"Canyonlands\"  \"Arches\"       \"Zion\"         \"Capitol Reef\""
  },
  {
    "objectID": "w3-slides.html#r-list",
    "href": "w3-slides.html#r-list",
    "title": "R Coding Workshop",
    "section": "R List",
    "text": "R List\n\nA vector that allows to have elements of different data type\nNested\n\n\nsummary(utah_df)\n\n national_park           lat             lon        \n Length:5           Min.   :37.20   Min.   :-113.0  \n Class :character   1st Qu.:37.64   1st Qu.:-112.2  \n Mode  :character   Median :38.29   Median :-111.3  \n                    Mean   :38.05   Mean   :-111.2  \n                    3rd Qu.:38.48   3rd Qu.:-109.8  \n                    Max.   :38.62   Max.   :-109.6  \n\n\n\nclass(utah_df[1])\n\n[1] \"data.frame\""
  },
  {
    "objectID": "w3-slides.html#getting-to-sf-and-a-map",
    "href": "w3-slides.html#getting-to-sf-and-a-map",
    "title": "R Coding Workshop",
    "section": "Getting to sf and a map",
    "text": "Getting to sf and a map\n\nlibrary(sf)\nlibrary(mapview)\nutah_sf &lt;- st_as_sf(\n    utah_df,\n    coords = c('lon', 'lat'),\n    crs = 4326\n)\nutah_sf |&gt; mapview()\n\n\n\n\n\n\nutah_sf\n\n\n\n\n\nnational_park\ngeometry\n\n\n\n\nBryce Canyon\nPOINT (-112.1696 37.64062)\n\n\nCanyonlands\nPOINT (-109.8252 38.47878)\n\n\nArches\nPOINT (-109.6198 38.61676)\n\n\nZion\nPOINT (-112.987 37.20027)\n\n\nCapitol Reef\nPOINT (-111.2619 38.2916)\n\n\n\n\n\n\n\n\n\n\nprelude to factor class: How were the points colored? Why are we having a legend on the map?\n\nHow to avoid presenting this map"
  },
  {
    "objectID": "w7-idx.html#outline",
    "href": "w7-idx.html#outline",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Outline",
    "text": "Outline\n\nresources\nCombining Data Frames\nmore on df to sf, sf to df\ndebugging",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#working-with-multiple-data-frames",
    "href": "w7-idx.html#working-with-multiple-data-frames",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Working with Multiple Data Frames",
    "text": "Working with Multiple Data Frames\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(terra)\n\nterra 1.7.78\n\nAttachement du package : 'terra'\n\nL'objet suivant est masqué depuis 'package:tidyr':\n\n    extract\n\nlibrary(mapview)\nlibrary(rnaturalearth)",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#combining-data-frames-of-the-same-shape",
    "href": "w7-idx.html#combining-data-frames-of-the-same-shape",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Combining data frames of the same shape",
    "text": "Combining data frames of the same shape\n\nbind_cols() and bind_rows() can combine two or more data frames\ncbind() and rbind()\n\n\ndivision_df &lt;- tibble(\n    division_str = c(\n        'New England', 'Middle Atlantic', 'East North Central',\n        'West North Central', 'South Atlantic', 'East South Central',\n        'West South Central', 'Mountain', 'Pacific'\n    )\n)\ndivision_code_df &lt;- tibble(\n    division_code = 1:9\n)\npaste(\n    'Dimensions of division_df:', dim(division_df),\n    'Dimensions of division_code_df', dim(division_code_df)) |&gt; print()\n\n[1] \"Dimensions of division_df: 9 Dimensions of division_code_df 9\"\n[2] \"Dimensions of division_df: 1 Dimensions of division_code_df 1\"\n\n\n\ndivision_lookup &lt;- bind_cols(\n    division_code_df, division_df\n)\ndivision_lookup\n\n\n\n\n\ndivision_code\ndivision_str\n\n\n\n\n1\nNew England\n\n\n2\nMiddle Atlantic\n\n\n3\nEast North Central\n\n\n4\nWest North Central\n\n\n5\nSouth Atlantic\n\n\n6\nEast South Central\n\n\n7\nWest South Central\n\n\n8\nMountain\n\n\n9\nPacific",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#bind_rows",
    "href": "w7-idx.html#bind_rows",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "bind_rows():",
    "text": "bind_rows():\n\ncheck if colnames align\n\n\nbook_df &lt;- read_csv('data/book-challenge11.csv')\n\nRows: 931 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): title, author, state\ndbl  (13): book_id, year, removed, explicit, antifamily, occult, language, l...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nremoved_tb &lt;- book_df |&gt; count(state, removed) |&gt; filter(removed == 1)\nchallenged_tb &lt;- book_df |&gt; count(state)\nremoved_tb |&gt; dim() |&gt; print()\n\n[1] 39  3\n\nchallenged_tb |&gt; dim() |&gt; print()\n\n[1] 47  2\n\n\n\nnot_removed_tb &lt;- book_df |&gt;\n  group_by(state) |&gt;\n  summarize(n = sum(removed == 0)) |&gt;\n  mutate(var = 'not removed')\nnot_removed_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n16\nnot removed\n\n\nVT\n13\nnot removed\n\n\nWA\n6\nnot removed\n\n\nWI\n7\nnot removed\n\n\nWV\n3\nnot removed\n\n\nWY\n3\nnot removed\n\n\n\n\n\n\n\nremoved_tb &lt;- book_df |&gt;\n  group_by(state) |&gt;\n  summarize(n = sum(removed == 1)) |&gt;\n  mutate(var = 'removed')\nremoved_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n18\nremoved\n\n\nVT\n0\nremoved\n\n\nWA\n3\nremoved\n\n\nWI\n3\nremoved\n\n\nWV\n0\nremoved\n\n\nWY\n1\nremoved\n\n\n\n\n\n\n\nall_tb &lt;- book_df |&gt;\n  count(state) |&gt;\n  mutate(var = 'all')\nall_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n34\nall\n\n\nVT\n13\nall\n\n\nWA\n9\nall\n\n\nWI\n10\nall\n\n\nWV\n3\nall\n\n\nWY\n4\nall\n\n\n\n\n\n\n\ncount_df &lt;- bind_rows(all_tb, removed_tb, not_removed_tb)\ncount_df |&gt; dim()\n\n[1] 141   3\n\n\n\ncount_df |&gt; arrange(state) |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nWV\n3\nall\n\n\nWV\n0\nremoved\n\n\nWV\n3\nnot removed\n\n\nWY\n4\nall\n\n\nWY\n1\nremoved\n\n\nWY\n3\nnot removed\n\n\n\n\n\n\n\nremoved_df &lt;- book_df |&gt;\n  mutate(removed = as.factor(removed)) |&gt;\n  count(state, removed, .drop = FALSE)\nremoved_df |&gt; dim()\n\n[1] 94  3",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#joins",
    "href": "w7-idx.html#joins",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins",
    "text": "Joins\n\nleft_join(), inner_join(), right_join(), full_join(), semi_join(), and anti_join().\nBinary operation on dataframes\n\ntakes pair of data frames (x, y)\n\n\n\nregion_lookup &lt;- tibble(\n    region_code = 1:4,\n    region_str = c('Northeast', 'Midwest', 'South','West')\n)\n\n\nregions &lt;- state.region |&gt; \n  recode(\"North Central\" = \"Midwest\")\nregions\n\n [1] South     West      West      South     West      West      Northeast\n [8] South     South     South     West      West      Midwest   Midwest  \n[15] Midwest   Midwest   South     South     Northeast South     Northeast\n[22] Midwest   Midwest   South     Midwest   West      Midwest   West     \n[29] Northeast Northeast West      Northeast South     Midwest   Midwest  \n[36] South     West      Northeast Northeast South     Midwest   South    \n[43] South     West      Northeast South     West      South     Midwest  \n[50] West     \nLevels: Northeast South Midwest West\n\n\n\nstate_region_df &lt;- tibble(\n  state_abb = state.abb,\n  region_str = regions\n)\n\nleft_join() retains the number of rows of the data frame on the left (x)\n\nstate_region_df &lt;- state_region_df |&gt;\n  left_join(region_lookup, join_by(region_str))\nstate_region_df\n\n\n\n\n\nstate_abb\nregion_str\nregion_code\n\n\n\n\nAL\nSouth\n3\n\n\nAK\nWest\n4\n\n\nAZ\nWest\n4\n\n\nAR\nSouth\n3\n\n\nCA\nWest\n4\n\n\nCO\nWest\n4\n\n\nCT\nNortheast\n1\n\n\nDE\nSouth\n3\n\n\nFL\nSouth\n3\n\n\nGA\nSouth\n3\n\n\nHI\nWest\n4\n\n\nID\nWest\n4\n\n\nIL\nMidwest\n2\n\n\nIN\nMidwest\n2\n\n\nIA\nMidwest\n2\n\n\nKS\nMidwest\n2\n\n\nKY\nSouth\n3\n\n\nLA\nSouth\n3\n\n\nME\nNortheast\n1\n\n\nMD\nSouth\n3\n\n\nMA\nNortheast\n1\n\n\nMI\nMidwest\n2\n\n\nMN\nMidwest\n2\n\n\nMS\nSouth\n3\n\n\nMO\nMidwest\n2\n\n\nMT\nWest\n4\n\n\nNE\nMidwest\n2\n\n\nNV\nWest\n4\n\n\nNH\nNortheast\n1\n\n\nNJ\nNortheast\n1\n\n\nNM\nWest\n4\n\n\nNY\nNortheast\n1\n\n\nNC\nSouth\n3\n\n\nND\nMidwest\n2\n\n\nOH\nMidwest\n2\n\n\nOK\nSouth\n3\n\n\nOR\nWest\n4\n\n\nPA\nNortheast\n1\n\n\nRI\nNortheast\n1\n\n\nSC\nSouth\n3\n\n\nSD\nMidwest\n2\n\n\nTN\nSouth\n3\n\n\nTX\nSouth\n3\n\n\nUT\nWest\n4\n\n\nVT\nNortheast\n1\n\n\nVA\nSouth\n3\n\n\nWA\nWest\n4\n\n\nWV\nSouth\n3\n\n\nWI\nMidwest\n2\n\n\nWY\nWest\n4",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#joins-sf-and-df",
    "href": "w7-idx.html#joins-sf-and-df",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins sf and df",
    "text": "Joins sf and df\n\nTIGER/Line Shapefiles\n\n\nstate_vars &lt;- c('REGION10', 'DIVISION10', 'GEOID10', 'STUSPS10', 'NAME10', 'ALAND10', \n'AWATER10', 'INTPTLAT10', 'INTPTLON10', 'geometry')\n\n\nst_layers('data/tl_2010_us_state10')\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ngeomtype\ndriver\nfeatures\nfields\ncrs\n\n\n\n\ntl_2010_us_state10\nPolygon\nESRI Shapefile\n52\n14\nNAD83 , GEOGCRS[“NAD83”,\n\n\n\nDATUM[\"North American Datum 1983\",\n    ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n        LENGTHUNIT[\"metre\",1]]],\nPRIMEM[\"Greenwich\",0,\n    ANGLEUNIT[\"degree\",0.0174532925199433]],\nCS[ellipsoidal,2],\n    AXIS[\"latitude\",north,\n        ORDER[1],\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    AXIS[\"longitude\",east,\n        ORDER[2],\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\nID[\"EPSG\",4269]] |\n\n\nus_state_sf &lt;- st_read('data/tl_2010_us_state10')|&gt;\n  select(any_of(state_vars))\n\nReading layer `tl_2010_us_state10' from data source \n  `/Users/toyuan/dohnanyi/data/tl_2010_us_state10' using driver `ESRI Shapefile'\nSimple feature collection with 52 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: 17.83151 xmax: 179.8597 ymax: 71.44106\nGeodetic CRS:  NAD83\n\nus_state_sf |&gt; head(4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREGION10\nDIVISION10\nGEOID10\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\ngeometry\n\n\n\n\n4\n8\n56\nWY\nWyoming\n251470069067\n1864445306\n+42.9918024\n-107.5419255\nMULTIPOLYGON (((-108.6213 4…\n\n\n1\n2\n42\nPA\nPennsylvania\n115883064314\n3397122731\n+40.9042486\n-077.8280624\nMULTIPOLYGON (((-80.51909 3…\n\n\n2\n3\n39\nOH\nOhio\n105828706692\n10269012119\n+40.4149297\n-082.7119975\nMULTIPOLYGON (((-84.05271 3…\n\n\n4\n8\n35\nNM\nNew Mexico\n314160748240\n756659673\n+34.4391265\n-106.1261511\nMULTIPOLYGON (((-109.0462 3…\n\n\n\n\n\n\n\nus_state_sf |&gt; st_crs()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\n\n\nimls\n\n\nlib_df &lt;- read_csv('data/public-libraries-2010.csv')\n\nRows: 55 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): STABR\ndbl (9): POPU_LSA, POPU_ST, CENTLIB, BRANLIB, BKMOB, BKVOL, LIBRARIA, VISITS...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlib_df |&gt; summary()\n\n    STABR              POPU_LSA           POPU_ST            CENTLIB     \n Length:55          Min.   :   53883   Min.   :   53883   Min.   :  0.0  \n Class :character   1st Qu.: 1409268   1st Qu.: 1322416   1st Qu.: 54.5  \n Mode  :character   Median : 4141264   Median : 3751351   Median :100.0  \n                    Mean   : 5595942   Mean   : 5663819   Mean   :165.7  \n                    3rd Qu.: 6540910   3rd Qu.: 6497622   3rd Qu.:234.0  \n                    Max.   :38647288   Max.   :38648090   Max.   :755.0  \n    BRANLIB          BKMOB           BKVOL             LIBRARIA     \n Min.   :  1.0   Min.   : 0.00   Min.   :      -1   Min.   :  -1.0  \n 1st Qu.: 28.5   1st Qu.: 2.00   1st Qu.: 4423164   1st Qu.: 206.1  \n Median : 83.0   Median : 7.00   Median : 9575400   Median : 587.0  \n Mean   :140.1   Mean   :13.44   Mean   :14772714   Mean   : 855.7  \n 3rd Qu.:192.0   3rd Qu.:17.50   3rd Qu.:17074348   3rd Qu.:1063.4  \n Max.   :942.0   Max.   :81.00   Max.   :74753745   Max.   :4062.5  \n     VISITS              REGBOR        \n Min.   :       -1   Min.   :      -1  \n 1st Qu.:  6216945   1st Qu.:  763359  \n Median : 18282842   Median : 1938999  \n Mean   : 28628594   Mean   : 3118459  \n 3rd Qu.: 39948818   3rd Qu.: 4129365  \n Max.   :178979300   Max.   :22275618  \n\n\n\nlib_sf &lt;- lib_df |&gt; left_join(us_state_sf, join_by(STABR == STUSPS10))\n\n\nlib_sf |&gt; mapview()\n\nError: \noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class spec_tbl_df. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class tbl_df. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class tbl. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class data.frame. \nEither convert lib_sf to a spatial object or provide xcol and ycol.",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#joins-df-to-sf",
    "href": "w7-idx.html#joins-df-to-sf",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins df to sf",
    "text": "Joins df to sf\n\ncheck missing values in geometry column\n\n\nlib_sf &lt;- lib_df |&gt; filter(!(STABR %in% c('GU', 'MP', 'VI'))) |&gt; left_join(us_state_sf, join_by(STABR == STUSPS10))\n\n\nlib_sf &lt;- lib_sf |&gt;\n  st_as_sf(\n    geometry = lib_sf$geometry,\n    crs = 4269\n)\nlib_sf |&gt; mapview(zcol = 'CENTLIB')\n\n\n\n\n\n\nlib_sf |&gt; class()\n\n[1] \"sf\"          \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n# result of subsetting\n\n\nlib_sf2 &lt;- us_state_sf |&gt; left_join(lib_df, join_by(STUSPS10 == STABR))\nlib_sf2 |&gt; mapview(zcol = 'CENTLIB')\n\n\n\n\n\n\nlib_sf2 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREGION10\nDIVISION10\nGEOID10\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\nPOPU_LSA\nPOPU_ST\nCENTLIB\nBRANLIB\nBKMOB\nBKVOL\nLIBRARIA\nVISITS\nREGBOR\ngeometry\n\n\n\n\n4\n8\n56\nWY\nWyoming\n251470069067\n1864445306\n+42.9918024\n-107.5419255\n544270\n544270\n23\n53\n2\n2497545\n189.16\n3872783\n383126\nMULTIPOLYGON (((-108.6213 4…\n\n\n1\n2\n42\nPA\nPennsylvania\n115883064314\n3397122731\n+40.9042486\n-077.8280624\n12054201\n12284183\n451\n183\n29\n27790282\n1445.81\n47188171\n5549200\nMULTIPOLYGON (((-80.51909 3…\n\n\n2\n3\n39\nOH\nOhio\n105828706692\n10269012119\n+40.4149297\n-082.7119975\n11551941\n11551941\n240\n480\n58\n45224425\n2725.65\n88255852\n8767349\nMULTIPOLYGON (((-84.05271 3…\n\n\n4\n8\n35\nNM\nNew Mexico\n314160748240\n756659673\n+34.4391265\n-106.1261511\n1588981\n2009671\n91\n27\n1\n4518130\n290.37\n8324986\n1140637\nMULTIPOLYGON (((-109.0462 3…\n\n\n3\n5\n24\nMD\nMaryland\n25141638381\n6989579585\n+38.9466584\n-076.6744939\n5633514\n5618344\n15\n169\n18\n13954140\n1297.29\n33662473\n3271760\nMULTIPOLYGON (((-75.74776 3…\n\n\n1\n1\n44\nRI\nRhode Island\n2677566454\n1323668539\n+41.5978358\n-071.5252895\n1430385\n1052587\n47\n26\n2\n4636067\n232.11\n6279148\n574776\nMULTIPOLYGON (((-71.65321 4…",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-idx.html#debugging",
    "href": "w7-idx.html#debugging",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Debugging",
    "text": "Debugging",
    "crumbs": [
      "Coding Workshop",
      "Week 7"
    ]
  },
  {
    "objectID": "w7-slides.html#r-coding-workshop-5th-meeting",
    "href": "w7-slides.html#r-coding-workshop-5th-meeting",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "R Coding Workshop: 5th Meeting",
    "text": "R Coding Workshop: 5th Meeting"
  },
  {
    "objectID": "w7-slides.html#outline",
    "href": "w7-slides.html#outline",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Outline",
    "text": "Outline\n\nresources\nCombining Data Frames\nmore on df to sf, sf to df\ndebugging"
  },
  {
    "objectID": "w7-slides.html#working-with-multiple-data-frames",
    "href": "w7-slides.html#working-with-multiple-data-frames",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Working with Multiple Data Frames",
    "text": "Working with Multiple Data Frames\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(terra)\nlibrary(mapview)\nlibrary(rnaturalearth)"
  },
  {
    "objectID": "w7-slides.html#combining-data-frames-of-the-same-shape",
    "href": "w7-slides.html#combining-data-frames-of-the-same-shape",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Combining data frames of the same shape",
    "text": "Combining data frames of the same shape\n\nbind_cols() and bind_rows() can combine two or more data frames\ncbind() and rbind()\n\n\ndivision_df &lt;- tibble(\n    division_str = c(\n        'New England', 'Middle Atlantic', 'East North Central',\n        'West North Central', 'South Atlantic', 'East South Central',\n        'West South Central', 'Mountain', 'Pacific'\n    )\n)\ndivision_code_df &lt;- tibble(\n    division_code = 1:9\n)\npaste(\n    'Dimensions of division_df:', dim(division_df),\n    'Dimensions of division_code_df', dim(division_code_df)) |&gt; print()\n\n[1] \"Dimensions of division_df: 9 Dimensions of division_code_df 9\"\n[2] \"Dimensions of division_df: 1 Dimensions of division_code_df 1\"\n\n\n\ndivision_lookup &lt;- bind_cols(\n    division_code_df, division_df\n)\ndivision_lookup\n\n\n\n\n\ndivision_code\ndivision_str\n\n\n\n\n1\nNew England\n\n\n2\nMiddle Atlantic\n\n\n3\nEast North Central\n\n\n4\nWest North Central\n\n\n5\nSouth Atlantic\n\n\n6\nEast South Central\n\n\n7\nWest South Central\n\n\n8\nMountain\n\n\n9\nPacific"
  },
  {
    "objectID": "w7-slides.html#bind_rows",
    "href": "w7-slides.html#bind_rows",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "bind_rows():",
    "text": "bind_rows():\n\ncheck if colnames align\n\n\nbook_df &lt;- read_csv('data/book-challenge11.csv')\n\n\nremoved_tb &lt;- book_df |&gt; count(state, removed) |&gt; filter(removed == 1)\nchallenged_tb &lt;- book_df |&gt; count(state)\nremoved_tb |&gt; dim() |&gt; print()\n\n[1] 39  3\n\nchallenged_tb |&gt; dim() |&gt; print()\n\n[1] 47  2\n\n\n\nnot_removed_tb &lt;- book_df |&gt;\n  group_by(state) |&gt;\n  summarize(n = sum(removed == 0)) |&gt;\n  mutate(var = 'not removed')\nnot_removed_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n16\nnot removed\n\n\nVT\n13\nnot removed\n\n\nWA\n6\nnot removed\n\n\nWI\n7\nnot removed\n\n\nWV\n3\nnot removed\n\n\nWY\n3\nnot removed\n\n\n\n\n\n\n\nremoved_tb &lt;- book_df |&gt;\n  group_by(state) |&gt;\n  summarize(n = sum(removed == 1)) |&gt;\n  mutate(var = 'removed')\nremoved_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n18\nremoved\n\n\nVT\n0\nremoved\n\n\nWA\n3\nremoved\n\n\nWI\n3\nremoved\n\n\nWV\n0\nremoved\n\n\nWY\n1\nremoved\n\n\n\n\n\n\n\nall_tb &lt;- book_df |&gt;\n  count(state) |&gt;\n  mutate(var = 'all')\nall_tb |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nVA\n34\nall\n\n\nVT\n13\nall\n\n\nWA\n9\nall\n\n\nWI\n10\nall\n\n\nWV\n3\nall\n\n\nWY\n4\nall\n\n\n\n\n\n\n\ncount_df &lt;- bind_rows(all_tb, removed_tb, not_removed_tb)\ncount_df |&gt; dim()\n\n[1] 141   3\n\n\n\ncount_df |&gt; arrange(state) |&gt; tail()\n\n\n\n\n\nstate\nn\nvar\n\n\n\n\nWV\n3\nall\n\n\nWV\n0\nremoved\n\n\nWV\n3\nnot removed\n\n\nWY\n4\nall\n\n\nWY\n1\nremoved\n\n\nWY\n3\nnot removed\n\n\n\n\n\n\n\nremoved_df &lt;- book_df |&gt;\n  mutate(removed = as.factor(removed)) |&gt;\n  count(state, removed, .drop = FALSE)\nremoved_df |&gt; dim()\n\n[1] 94  3"
  },
  {
    "objectID": "w7-slides.html#joins",
    "href": "w7-slides.html#joins",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins",
    "text": "Joins\n\nleft_join(), inner_join(), right_join(), full_join(), semi_join(), and anti_join().\nBinary operation on dataframes\n\ntakes pair of data frames (x, y)\n\n\n\nregion_lookup &lt;- tibble(\n    region_code = 1:4,\n    region_str = c('Northeast', 'Midwest', 'South','West')\n)\n\n\nregions &lt;- state.region |&gt; \n  recode(\"North Central\" = \"Midwest\")\nregions\n\n [1] South     West      West      South     West      West      Northeast\n [8] South     South     South     West      West      Midwest   Midwest  \n[15] Midwest   Midwest   South     South     Northeast South     Northeast\n[22] Midwest   Midwest   South     Midwest   West      Midwest   West     \n[29] Northeast Northeast West      Northeast South     Midwest   Midwest  \n[36] South     West      Northeast Northeast South     Midwest   South    \n[43] South     West      Northeast South     West      South     Midwest  \n[50] West     \nLevels: Northeast South Midwest West\n\n\n\nstate_region_df &lt;- tibble(\n  state_abb = state.abb,\n  region_str = regions\n)\n\nleft_join() retains the number of rows of the data frame on the left (x)\n\nstate_region_df &lt;- state_region_df |&gt;\n  left_join(region_lookup, join_by(region_str))\nstate_region_df\n\n\n\n\n\nstate_abb\nregion_str\nregion_code\n\n\n\n\nAL\nSouth\n3\n\n\nAK\nWest\n4\n\n\nAZ\nWest\n4\n\n\nAR\nSouth\n3\n\n\nCA\nWest\n4\n\n\nCO\nWest\n4\n\n\nCT\nNortheast\n1\n\n\nDE\nSouth\n3\n\n\nFL\nSouth\n3\n\n\nGA\nSouth\n3\n\n\nHI\nWest\n4\n\n\nID\nWest\n4\n\n\nIL\nMidwest\n2\n\n\nIN\nMidwest\n2\n\n\nIA\nMidwest\n2\n\n\nKS\nMidwest\n2\n\n\nKY\nSouth\n3\n\n\nLA\nSouth\n3\n\n\nME\nNortheast\n1\n\n\nMD\nSouth\n3\n\n\nMA\nNortheast\n1\n\n\nMI\nMidwest\n2\n\n\nMN\nMidwest\n2\n\n\nMS\nSouth\n3\n\n\nMO\nMidwest\n2\n\n\nMT\nWest\n4\n\n\nNE\nMidwest\n2\n\n\nNV\nWest\n4\n\n\nNH\nNortheast\n1\n\n\nNJ\nNortheast\n1\n\n\nNM\nWest\n4\n\n\nNY\nNortheast\n1\n\n\nNC\nSouth\n3\n\n\nND\nMidwest\n2\n\n\nOH\nMidwest\n2\n\n\nOK\nSouth\n3\n\n\nOR\nWest\n4\n\n\nPA\nNortheast\n1\n\n\nRI\nNortheast\n1\n\n\nSC\nSouth\n3\n\n\nSD\nMidwest\n2\n\n\nTN\nSouth\n3\n\n\nTX\nSouth\n3\n\n\nUT\nWest\n4\n\n\nVT\nNortheast\n1\n\n\nVA\nSouth\n3\n\n\nWA\nWest\n4\n\n\nWV\nSouth\n3\n\n\nWI\nMidwest\n2\n\n\nWY\nWest\n4"
  },
  {
    "objectID": "w7-slides.html#joins-sf-and-df",
    "href": "w7-slides.html#joins-sf-and-df",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins sf and df",
    "text": "Joins sf and df\n\nTIGER/Line Shapefiles\n\n\nstate_vars &lt;- c('REGION10', 'DIVISION10', 'GEOID10', 'STUSPS10', 'NAME10', 'ALAND10', \n'AWATER10', 'INTPTLAT10', 'INTPTLON10', 'geometry')\n\n\nst_layers('data/tl_2010_us_state10')\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\ngeomtype\ndriver\nfeatures\nfields\ncrs\n\n\n\n\ntl_2010_us_state10\nPolygon\nESRI Shapefile\n52\n14\nNAD83 , GEOGCRS[“NAD83”,\n\n\n\nDATUM[\"North American Datum 1983\",\n    ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n        LENGTHUNIT[\"metre\",1]]],\nPRIMEM[\"Greenwich\",0,\n    ANGLEUNIT[\"degree\",0.0174532925199433]],\nCS[ellipsoidal,2],\n    AXIS[\"latitude\",north,\n        ORDER[1],\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    AXIS[\"longitude\",east,\n        ORDER[2],\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\nID[\"EPSG\",4269]] |\n\n\nus_state_sf &lt;- st_read('data/tl_2010_us_state10')|&gt;\n  select(any_of(state_vars))\n\nReading layer `tl_2010_us_state10' from data source \n  `/Users/toyuan/dohnanyi/data/tl_2010_us_state10' using driver `ESRI Shapefile'\nSimple feature collection with 52 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: 17.83151 xmax: 179.8597 ymax: 71.44106\nGeodetic CRS:  NAD83\n\nus_state_sf |&gt; head(4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREGION10\nDIVISION10\nGEOID10\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\ngeometry\n\n\n\n\n4\n8\n56\nWY\nWyoming\n251470069067\n1864445306\n+42.9918024\n-107.5419255\nMULTIPOLYGON (((-108.6213 4…\n\n\n1\n2\n42\nPA\nPennsylvania\n115883064314\n3397122731\n+40.9042486\n-077.8280624\nMULTIPOLYGON (((-80.51909 3…\n\n\n2\n3\n39\nOH\nOhio\n105828706692\n10269012119\n+40.4149297\n-082.7119975\nMULTIPOLYGON (((-84.05271 3…\n\n\n4\n8\n35\nNM\nNew Mexico\n314160748240\n756659673\n+34.4391265\n-106.1261511\nMULTIPOLYGON (((-109.0462 3…\n\n\n\n\n\n\n\nus_state_sf |&gt; st_crs()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\n\n\nimls\n\n\nlib_df &lt;- read_csv('data/public-libraries-2010.csv')\nlib_df |&gt; summary()\n\n    STABR              POPU_LSA           POPU_ST            CENTLIB     \n Length:55          Min.   :   53883   Min.   :   53883   Min.   :  0.0  \n Class :character   1st Qu.: 1409268   1st Qu.: 1322416   1st Qu.: 54.5  \n Mode  :character   Median : 4141264   Median : 3751351   Median :100.0  \n                    Mean   : 5595942   Mean   : 5663819   Mean   :165.7  \n                    3rd Qu.: 6540910   3rd Qu.: 6497622   3rd Qu.:234.0  \n                    Max.   :38647288   Max.   :38648090   Max.   :755.0  \n    BRANLIB          BKMOB           BKVOL             LIBRARIA     \n Min.   :  1.0   Min.   : 0.00   Min.   :      -1   Min.   :  -1.0  \n 1st Qu.: 28.5   1st Qu.: 2.00   1st Qu.: 4423164   1st Qu.: 206.1  \n Median : 83.0   Median : 7.00   Median : 9575400   Median : 587.0  \n Mean   :140.1   Mean   :13.44   Mean   :14772714   Mean   : 855.7  \n 3rd Qu.:192.0   3rd Qu.:17.50   3rd Qu.:17074348   3rd Qu.:1063.4  \n Max.   :942.0   Max.   :81.00   Max.   :74753745   Max.   :4062.5  \n     VISITS              REGBOR        \n Min.   :       -1   Min.   :      -1  \n 1st Qu.:  6216945   1st Qu.:  763359  \n Median : 18282842   Median : 1938999  \n Mean   : 28628594   Mean   : 3118459  \n 3rd Qu.: 39948818   3rd Qu.: 4129365  \n Max.   :178979300   Max.   :22275618  \n\n\n\nlib_sf &lt;- lib_df |&gt; left_join(us_state_sf, join_by(STABR == STUSPS10))\n\n\nlib_sf |&gt; mapview()\n\nError: \noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class spec_tbl_df. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class tbl_df. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class tbl. \nEither convert lib_sf to a spatial object or provide xcol and ycol.\noops! Arguments xcol and/or ycol are missing!\nYou probably expected lib_sf to be a spatial object. \nHowever it is of class data.frame. \nEither convert lib_sf to a spatial object or provide xcol and ycol."
  },
  {
    "objectID": "w7-slides.html#joins-df-to-sf",
    "href": "w7-slides.html#joins-df-to-sf",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Joins df to sf",
    "text": "Joins df to sf\n\ncheck missing values in geometry column\n\n\nlib_sf &lt;- lib_df |&gt; filter(!(STABR %in% c('GU', 'MP', 'VI'))) |&gt; left_join(us_state_sf, join_by(STABR == STUSPS10))\n\n\nlib_sf &lt;- lib_sf |&gt;\n  st_as_sf(\n    geometry = lib_sf$geometry,\n    crs = 4269\n)\nlib_sf |&gt; mapview(zcol = 'CENTLIB')\n\n\n\n\n\n\nlib_sf |&gt; class()\n\n[1] \"sf\"          \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n# result of subsetting\n\n\nlib_sf2 &lt;- us_state_sf |&gt; left_join(lib_df, join_by(STUSPS10 == STABR))\nlib_sf2 |&gt; mapview(zcol = 'CENTLIB')\n\n\n\n\n\n\nlib_sf2 |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nREGION10\nDIVISION10\nGEOID10\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\nPOPU_LSA\nPOPU_ST\nCENTLIB\nBRANLIB\nBKMOB\nBKVOL\nLIBRARIA\nVISITS\nREGBOR\ngeometry\n\n\n\n\n4\n8\n56\nWY\nWyoming\n251470069067\n1864445306\n+42.9918024\n-107.5419255\n544270\n544270\n23\n53\n2\n2497545\n189.16\n3872783\n383126\nMULTIPOLYGON (((-108.6213 4…\n\n\n1\n2\n42\nPA\nPennsylvania\n115883064314\n3397122731\n+40.9042486\n-077.8280624\n12054201\n12284183\n451\n183\n29\n27790282\n1445.81\n47188171\n5549200\nMULTIPOLYGON (((-80.51909 3…\n\n\n2\n3\n39\nOH\nOhio\n105828706692\n10269012119\n+40.4149297\n-082.7119975\n11551941\n11551941\n240\n480\n58\n45224425\n2725.65\n88255852\n8767349\nMULTIPOLYGON (((-84.05271 3…\n\n\n4\n8\n35\nNM\nNew Mexico\n314160748240\n756659673\n+34.4391265\n-106.1261511\n1588981\n2009671\n91\n27\n1\n4518130\n290.37\n8324986\n1140637\nMULTIPOLYGON (((-109.0462 3…\n\n\n3\n5\n24\nMD\nMaryland\n25141638381\n6989579585\n+38.9466584\n-076.6744939\n5633514\n5618344\n15\n169\n18\n13954140\n1297.29\n33662473\n3271760\nMULTIPOLYGON (((-75.74776 3…\n\n\n1\n1\n44\nRI\nRhode Island\n2677566454\n1323668539\n+41.5978358\n-071.5252895\n1430385\n1052587\n47\n26\n2\n4636067\n232.11\n6279148\n574776\nMULTIPOLYGON (((-71.65321 4…"
  },
  {
    "objectID": "w7-slides.html#debugging",
    "href": "w7-slides.html#debugging",
    "title": "R Coding Workshop: 5th Meeting",
    "section": "Debugging",
    "text": "Debugging"
  },
  {
    "objectID": "w6-idx.html#outline",
    "href": "w6-idx.html#outline",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Outline",
    "text": "Outline\n\nR Functions\ndplyr functions\n\narrange()\nslice_sample()\n\ndefine your own function\nggplot2",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#r-functions",
    "href": "w6-idx.html#r-functions",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "R Functions",
    "text": "R Functions\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\n\nLe chargement a nécessité le package : viridisLite",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#using-base-and-imported-functions",
    "href": "w6-idx.html#using-base-and-imported-functions",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Using base and imported functions",
    "text": "Using base and imported functions\n\n\nFunctions from Base R\n\nclass(print) |&gt; print()\n\n[1] \"function\"\n\nclass(class)\n\n[1] \"function\"\n\n\n\nlong_df &lt;- tibble(\n    value = 1:37\n)\nprint(long_df)\n\n# A tibble: 37 × 1\n   value\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n# ℹ 27 more rows\n\n\n\nlong_df |&gt; print(n = 37)\n\n# A tibble: 37 × 1\n   value\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n11    11\n12    12\n13    13\n14    14\n15    15\n16    16\n17    17\n18    18\n19    19\n20    20\n21    21\n22    22\n23    23\n24    24\n25    25\n26    26\n27    27\n28    28\n29    29\n30    30\n31    31\n32    32\n33    33\n34    34\n35    35\n36    36\n37    37\n\n\n\nImported functions\n\nclass(select)\n\n[1] \"function\"\n\nclass(mapview)\n\n[1] \"standardGeneric\"\nattr(,\"package\")\n[1] \"methods\"",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#components-of-a-function",
    "href": "w6-idx.html#components-of-a-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Components of a Function",
    "text": "Components of a Function",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#when-we-want-to-write-our-own-function",
    "href": "w6-idx.html#when-we-want-to-write-our-own-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "When we want to write our own Function",
    "text": "When we want to write our own Function\n\ncopy-and-paste\nvector operations\ncreating plots",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#components-of-a-function-1",
    "href": "w6-idx.html#components-of-a-function-1",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Components of a Function",
    "text": "Components of a Function\n\nFunction Name: Usually a verb\nParameters: Variable provided when you defined your function,they act as a placeholder for expected input\nArguments: Variable specified at the time you use the function\nReturn: Output of the function\n\n\nadd_four &lt;- function(x) x + 4\nadd_four |&gt; class() |&gt; print()\n\n[1] \"function\"\n\n\n\n\n\nadd_four &lt;- function(x) x + 4\nadd_four |&gt; class() |&gt; print()\n\n[1] \"function\"\n\n\n\n\na &lt;- 1.46\nadd_four(a)\n\n[1] 5.46\n\nv1 &lt;- c(1, 9, 8, 8)\nadd_four(v1)\n\n[1]  5 13 12 12\n\n\n\nv1 + 4\n\n[1]  5 13 12 12\n\n\n\nsapply(v1, add_four)\n\n[1]  5 13 12 12\n\n\n\nlong_df$value |&gt; add_four()\n\n [1]  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n[26] 30 31 32 33 34 35 36 37 38 39 40 41\n\n\n\n\n\nbook_challenge_sf &lt;- st_read('data/book-challenges-state-sf.gpkg')\n\nReading layer `book-challenges-state-sf' from data source \n  `/Users/toyuan/dohnanyi/data/book-challenges-state-sf.gpkg' \n  using driver `GPKG'\nSimple feature collection with 51 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1435 ymin: 18.90612 xmax: 179.7809 ymax: 71.4125\nGeodetic CRS:  WGS 84\n\nbook_challenge_sf |&gt; mapview(zcol = 'count')",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#getting-familiar-with-how-functions-work",
    "href": "w6-idx.html#getting-familiar-with-how-functions-work",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Getting familiar with how functions work",
    "text": "Getting familiar with how functions work\n\npaste() and paste0() function\n\n\ncreate_label &lt;- function(unit, count) {\n    paste0(unit, ': ', count)\n}\n\n\nbook_challenge_sf &lt;- book_challenge_sf |&gt; mutate(lab = create_label(gn_name, count))\nbook_challenge_sf |&gt; mapview(zcol = 'count', label = 'lab')",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#plotting-function",
    "href": "w6-idx.html#plotting-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Plotting Function",
    "text": "Plotting Function\n\n\n\nbook_challenge_sf |&gt;\n  filter(!(postal %in% c('HI', 'AK'))) |&gt;\n  ggplot() +\n  geom_sf(\n    aes(fill = count),\n    color = 'white',\n    size = 0.1\n  ) +\n  geom_sf_label(\n    aes(label = postal),\n    size = 2.5,\n    fill = 'white',\n    alpha = 0.7,\n    color = 'black'\n  ) +\n  scale_fill_viridis(na.value = '#E2E2E2') +\n  theme_minimal() +\n  labs(\n    title = 'Book Challenges by State',\n    subtitle = '2000-2010'\n  )\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\n\n\nplot_state_choropleth &lt;- function(sf, col_str, plt_title) {\n    sf |&gt;\n    filter(!(postal %in% c('HI', 'AK'))) |&gt;\n    ggplot() +\n    geom_sf(\n      aes_string(fill = col_str),\n      color = 'white',\n      size = 0.1\n    ) +\n    geom_sf_label(\n      aes(label = postal),\n      size = 2.5,\n      fill = 'white',\n      alpha = 0.7,\n      color = 'black'\n    ) +\n    scale_fill_viridis(na.value = '#E2E2E2') +\n    theme_minimal() +\n    labs(\n      title = plt_title,\n      subtitle = '2000-2010'\n    )\n}\n\n\n\n\nplot_state_choropleth(\n    book_challenge_sf,\n    'count',\n    'Book Challenges by State'\n    )\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\n\nplot_state_choropleth(book_challenge_sf, 'median_income', 'State Median Income')\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\n\n\n\n\n\n\nbook_challenge_sf |&gt; plot_state_choropleth('political_value_index', 'Political Value Index')\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#arrange",
    "href": "w6-idx.html#arrange",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "arrange()",
    "text": "arrange()\n\nSort observations by column value\n\n\nbook_challenge_sf |&gt;\n  arrange(desc(count)) |&gt;\n  pull(lab)\n\n [1] \"Pennsylvania: 147\"        \"Oregon: 118\"             \n [3] \"Colorado: 80\"             \"California: 50\"          \n [5] \"Illinois: 39\"             \"Michigan: 34\"            \n [7] \"Virginia: 33\"             \"Ohio: 29\"                \n [9] \"Florida: 26\"              \"New York: 24\"            \n[11] \"Oklahoma: 23\"             \"North Carolina: 20\"      \n[13] \"Indiana: 20\"              \"Minnesota: 17\"           \n[15] \"South Carolina: 15\"       \"Idaho: 14\"               \n[17] \"Vermont: 13\"              \"Georgia: 13\"             \n[19] \"Kansas: 13\"               \"Iowa: 13\"                \n[21] \"Kentucky: 13\"             \"Tennessee: 13\"           \n[23] \"Arizona: 12\"              \"Louisiana: 12\"           \n[25] \"New Jersey: 11\"           \"Missouri: 11\"            \n[27] \"Alabama: 10\"              \"Wisconsin: 10\"           \n[29] \"Washington: 9\"            \"Alaska: 9\"               \n[31] \"Massachusetts: 8\"         \"Montana: 7\"              \n[33] \"New Hampshire: 7\"         \"North Dakota: 6\"         \n[35] \"Connecticut: 6\"           \"Maryland: 5\"             \n[37] \"Arkansas: 5\"              \"Wyoming: 4\"              \n[39] \"Maine: 3\"                 \"New Mexico: 3\"           \n[41] \"Rhode Island: 3\"          \"South Dakota: 3\"         \n[43] \"West Virginia: 3\"         \"Delaware: 2\"             \n[45] \"Nebraska: 2\"              \"Mississippi: 1\"          \n[47] \"Utah: 1\"                  \"Texas: NA\"               \n[49] \"District of Columbia: NA\" \"Hawaii: NA\"              \n[51] \"Nevada: NA\"              \n\n\n\nbook_challenge_sf |&gt;\n  arrange(political_value_index) |&gt;\n  select(gn_name, count, political_value_index)\n\n\n\n\n\n\n\n\n\n\n\ngn_name\ncount\npolitical_value_index\ngeom\n\n\n\n\nUtah\n1\n-20.2\nMULTIPOLYGON (((-111.0502 4…\n\n\nWyoming\n4\n-19.7\nMULTIPOLYGON (((-109.0463 4…\n\n\nIdaho\n14\n-17.4\nMULTIPOLYGON (((-117.0382 4…\n\n\nOklahoma\n23\n-16.9\nMULTIPOLYGON (((-103.0002 3…\n\n\nNebraska\n2\n-13.5\nMULTIPOLYGON (((-104.0537 4…\n\n\nAlaska\n9\n-13.4\nMULTIPOLYGON (((-141.0056 6…\n\n\nAlabama\n10\n-13.2\nMULTIPOLYGON (((-87.41958 3…\n\n\nKansas\n13\n-11.5\nMULTIPOLYGON (((-102.0396 3…\n\n\nNorth Dakota\n6\n-10.4\nMULTIPOLYGON (((-104.0476 4…\n\n\nKentucky\n13\n-10.4\nMULTIPOLYGON (((-89.42446 3…\n\n\nLouisiana\n12\n-9.7\nMULTIPOLYGON (((-89.52599 3…\n\n\nMississippi\n1\n-9.5\nMULTIPOLYGON (((-88.40221 3…\n\n\nSouth Dakota\n3\n-8.9\nMULTIPOLYGON (((-104.0567 4…\n\n\nArkansas\n5\n-8.8\nMULTIPOLYGON (((-90.30422 3…\n\n\nTennessee\n13\n-8.7\nMULTIPOLYGON (((-90.30422 3…\n\n\nWest Virginia\n3\n-7.9\nMULTIPOLYGON (((-82.58945 3…\n\n\nSouth Carolina\n15\n-7.8\nMULTIPOLYGON (((-78.57316 3…\n\n\nMontana\n7\n-7.1\nMULTIPOLYGON (((-116.0482 4…\n\n\nGeorgia\n13\n-6.8\nMULTIPOLYGON (((-80.89029 3…\n\n\nIndiana\n20\n-6.2\nMULTIPOLYGON (((-84.80608 4…\n\n\nArizona\n12\n-6.1\nMULTIPOLYGON (((-111.0063 3…\n\n\nNorth Carolina\n20\n-4.3\nMULTIPOLYGON (((-76.03173 3…\n\n\nMissouri\n11\n-3.1\nMULTIPOLYGON (((-95.31725 4…\n\n\nFlorida\n26\n-1.8\nMULTIPOLYGON (((-87.44734 3…\n\n\nVirginia\n33\n-1.7\nMULTIPOLYGON (((-76.01325 3…\n\n\nOhio\n29\n-0.7\nMULTIPOLYGON (((-80.52023 4…\n\n\nColorado\n80\n-0.2\nMULTIPOLYGON (((-109.0463 4…\n\n\nIowa\n13\n1.0\nMULTIPOLYGON (((-96.48266 4…\n\n\nNew Hampshire\n7\n1.6\nMULTIPOLYGON (((-71.50585 4…\n\n\nPennsylvania\n147\n2.0\nMULTIPOLYGON (((-79.76301 4…\n\n\nMinnesota\n17\n2.3\nMULTIPOLYGON (((-97.22609 4…\n\n\nNew Mexico\n3\n2.4\nMULTIPOLYGON (((-108.1375 3…\n\n\nWisconsin\n10\n2.4\nMULTIPOLYGON (((-87.80425 4…\n\n\nMichigan\n34\n3.8\nMULTIPOLYGON (((-84.4913 46…\n\n\nOregon\n118\n4.0\nMULTIPOLYGON (((-124.4924 4…\n\n\nNew Jersey\n11\n4.4\nMULTIPOLYGON (((-75.54133 3…\n\n\nWashington\n9\n5.0\nMULTIPOLYGON (((-122.753 48…\n\n\nMaine\n3\n5.5\nMULTIPOLYGON (((-71.08495 4…\n\n\nDelaware\n2\n7.0\nMULTIPOLYGON (((-75.05809 3…\n\n\nConnecticut\n6\n7.1\nMULTIPOLYGON (((-73.6417 41…\n\n\nCalifornia\n50\n7.4\nMULTIPOLYGON (((-114.7243 3…\n\n\nIllinois\n39\n7.7\nMULTIPOLYGON (((-89.1237 36…\n\n\nMaryland\n5\n8.5\nMULTIPOLYGON (((-75.64786 3…\n\n\nNew York\n24\n10.2\nMULTIPOLYGON (((-79.06523 4…\n\n\nRhode Island\n3\n11.2\nMULTIPOLYGON (((-71.23686 4…\n\n\nMassachusetts\n8\n11.7\nMULTIPOLYGON (((-71.19396 4…\n\n\nVermont\n13\n13.4\nMULTIPOLYGON (((-73.35134 4…\n\n\nTexas\nNA\nNA\nMULTIPOLYGON (((-103.3115 2…\n\n\nDistrict of Columbia\nNA\nNA\nMULTIPOLYGON (((-77.02293 3…\n\n\nHawaii\nNA\nNA\nMULTIPOLYGON (((-154.8996 1…\n\n\nNevada\nNA\nNA\nMULTIPOLYGON (((-114.0425 4…\n\n\n\n\n\n\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\n\nRows: 931 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): title, author, state\ndbl  (13): book_id, year, removed, explicit, antifamily, occult, language, l...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nbook_challenge_df |&gt; arrange(author, title) |&gt; head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nGo and Come Back\n721\nAbelove, Joan\n2000-06-18\n2000\n0\n1\n0\n0\n0\n0\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.2237299\n\n\nFinding Our Way–The Teen Girl Survival Guide\n695\nAbner, Allison\n2002-05-21\n2002\n0\n1\n0\n0\n0\n0\n0\nAZ\n-6.1\n3490.5\n1.438042\n-0.5237299\n\n\nDeath Blossoms\n522\nAbu-Jamal, Mumia\n2005-07-03\n2005\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nTijuana Bibles\n1811\nAdelman, Bob\n2000-06-29\n2000\n0\n1\n0\n0\n0\n0\n1\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nArt for Lovers\n160\nAdler, Sabine\n2005-04-08\n2005\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nPsychic Academy Series\n1484\nAki, Katsu\n2008-06-07\n2008\n0\n0\n0\n0\n0\n0\n0\nVA\n-1.7\n11296.0\n1.938042\n5.4762701\n\n\nMonkey High Vol. 3\n1277\nAkira, Shouko\n2009-05-06\n2009\n0\n0\n0\n0\n0\n0\n0\nMI\n3.8\n2966.0\n3.838042\n-2.2237299\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2008-10-02\n2008\n1\n0\n0\n0\n0\n0\n0\nIA\n1.0\n3921.5\n6.538042\n-2.8237299\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2009-05-04\n2009\n0\n1\n0\n0\n1\n0\n0\nIL\n7.7\n6489.5\n1.838042\n2.0762701\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2010-05-12\n2010\n1\n0\n0\n0\n1\n0\n1\nMO\n-3.1\n1279.5\n1.738042\n-2.4237299",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-idx.html#slice_sample",
    "href": "w6-idx.html#slice_sample",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "slice_sample()",
    "text": "slice_sample()\n\nbook_challenge_df |&gt; slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nWait Till Helen Comes\n1907\nHahn, Mary Downing\n2010-03-19\n2010\n0\n0\n0\n0\n0\n0\n0\nNH\n1.6\n17303.0\n7.838042\n4.67627\n\n\nKing & King\n1083\nde Haan, Linda\n2003-04-15\n2003\n0\n0\n0\n0\n0\n1\n0\nMA\n11.7\n14048.5\n5.238042\n9.17627\n\n\nRadiant Identities\n1495\nSturges, Jock\n2000-06-29\n2000\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.07627\n\n\nFire From Within, The\n696\nCastaneda, Carlos\n2000-06-29\n2000\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.07627\n\n\nVampires\n1892\nYolen, Jane and Martin H. Greenberg\n2007-07-22\n2007\n0\n1\n0\n0\n0\n0\n0\nCA\n7.4\n10119.0\n-2.761958\n2.57627\n\n\nTTYL\n1849\nMyracle, Lauren\n2008-09-15\n2008\n1\n0\n0\n0\n0\n0\n0\nMO\n-3.1\n1279.5\n1.738042\n-2.42373\n\n\nLook At Me\n1170\nEgan, Jennifer\n2001-12-10\n2001\n0\n1\n0\n0\n0\n0\n0\nMI\n3.8\n2966.0\n3.838042\n-2.22373\n\n\nTenth Circle, The\n1773\nPicoult, Jodi\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2.0\n4218.0\n2.338042\n-1.62373\n\n\nPinky and Rex and the Bully\n1451\nHowe, James\n2003-04-15\n2003\n0\n0\n0\n0\n0\n1\n0\nMI\n3.8\n2966.0\n3.838042\n-2.22373\n\n\nPaula\n1429\nNA\n2001-05-25\n2001\n1\n0\n0\n0\n0\n0\n0\nVA\n-1.7\n11296.0\n1.938042\n5.47627\n\n\n\n\n\n\n\nbook_challenge_df |&gt;\n  filter(state == 'PA') |&gt;\n  slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nRhymes With Witches\n1528\nMyracle, Lauren\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nOne Flew Over the Cuckoo’s Nest\n1393\nKesey, Ken\n2008-10-17\n2008\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nBody Drama\n268\nRedd, Nancy Amanda\n2008-09-14\n2008\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nAs I Lay Dying\n165\nFaulkner, William\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nSpeak\n1684\nAnderson, Laurie Halse\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nRabbit (series)\n1492\nUpdike, John\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nEarth, My Butt and Other Big Round Things, The\n607\nMackler, Carolyn\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nGlass Castle, The\n718\nWalls, Jeannette\n2009-08-26\n2009\n0\n0\n0\n0\n1\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nAre You In the House Alone?\n155\nPeck, Richard\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nI Know What You Did Last Summer\n957\nDuncan, Lois\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373",
    "crumbs": [
      "Coding Workshop",
      "Week 6"
    ]
  },
  {
    "objectID": "w6-slides.html#r-coding-workshop-4th-meeting",
    "href": "w6-slides.html#r-coding-workshop-4th-meeting",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "R Coding Workshop: 4th Meeting",
    "text": "R Coding Workshop: 4th Meeting"
  },
  {
    "objectID": "w6-slides.html#outline",
    "href": "w6-slides.html#outline",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Outline",
    "text": "Outline\n\nR Functions\ndplyr functions\n\narrange()\nslice_sample()\n\ndefine your own function\nggplot2"
  },
  {
    "objectID": "w6-slides.html#r-functions",
    "href": "w6-slides.html#r-functions",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "R Functions",
    "text": "R Functions\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)"
  },
  {
    "objectID": "w6-slides.html#using-base-and-imported-functions",
    "href": "w6-slides.html#using-base-and-imported-functions",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Using base and imported functions",
    "text": "Using base and imported functions\n\n\nFunctions from Base R\n\nclass(print) |&gt; print()\n\n[1] \"function\"\n\nclass(class)\n\n[1] \"function\"\n\n\n\nlong_df &lt;- tibble(\n    value = 1:37\n)\nprint(long_df)\n\n# A tibble: 37 × 1\n   value\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n# ℹ 27 more rows\n\n\n\nlong_df |&gt; print(n = 37)\n\n# A tibble: 37 × 1\n   value\n   &lt;int&gt;\n 1     1\n 2     2\n 3     3\n 4     4\n 5     5\n 6     6\n 7     7\n 8     8\n 9     9\n10    10\n11    11\n12    12\n13    13\n14    14\n15    15\n16    16\n17    17\n18    18\n19    19\n20    20\n21    21\n22    22\n23    23\n24    24\n25    25\n26    26\n27    27\n28    28\n29    29\n30    30\n31    31\n32    32\n33    33\n34    34\n35    35\n36    36\n37    37\n\n\n\nImported functions\n\nclass(select)\n\n[1] \"function\"\n\nclass(mapview)\n\n[1] \"standardGeneric\"\nattr(,\"package\")\n[1] \"methods\""
  },
  {
    "objectID": "w6-slides.html#components-of-a-function",
    "href": "w6-slides.html#components-of-a-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Components of a Function",
    "text": "Components of a Function"
  },
  {
    "objectID": "w6-slides.html#when-we-want-to-write-our-own-function",
    "href": "w6-slides.html#when-we-want-to-write-our-own-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "When we want to write our own Function",
    "text": "When we want to write our own Function\n\ncopy-and-paste\nvector operations\ncreating plots"
  },
  {
    "objectID": "w6-slides.html#components-of-a-function-1",
    "href": "w6-slides.html#components-of-a-function-1",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Components of a Function",
    "text": "Components of a Function\n\nFunction Name: Usually a verb\nParameters: Variable provided when you defined your function,they act as a placeholder for expected input\nArguments: Variable specified at the time you use the function\nReturn: Output of the function\n\n\nadd_four &lt;- function(x) x + 4\nadd_four |&gt; class() |&gt; print()\n\n[1] \"function\"\n\n\n\n\n\nadd_four &lt;- function(x) x + 4\nadd_four |&gt; class() |&gt; print()\n\n[1] \"function\"\n\n\n\n\na &lt;- 1.46\nadd_four(a)\n\n[1] 5.46\n\nv1 &lt;- c(1, 9, 8, 8)\nadd_four(v1)\n\n[1]  5 13 12 12\n\n\n\nv1 + 4\n\n[1]  5 13 12 12\n\n\n\nsapply(v1, add_four)\n\n[1]  5 13 12 12\n\n\n\nlong_df$value |&gt; add_four()\n\n [1]  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29\n[26] 30 31 32 33 34 35 36 37 38 39 40 41\n\n\n\n\nbook_challenge_sf &lt;- st_read('data/book-challenges-state-sf.gpkg')\n\nReading layer `book-challenges-state-sf' from data source \n  `/Users/toyuan/dohnanyi/data/book-challenges-state-sf.gpkg' \n  using driver `GPKG'\nSimple feature collection with 51 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1435 ymin: 18.90612 xmax: 179.7809 ymax: 71.4125\nGeodetic CRS:  WGS 84\n\nbook_challenge_sf |&gt; mapview(zcol = 'count')"
  },
  {
    "objectID": "w6-slides.html#getting-familiar-with-how-functions-work",
    "href": "w6-slides.html#getting-familiar-with-how-functions-work",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Getting familiar with how functions work",
    "text": "Getting familiar with how functions work\n\npaste() and paste0() function\n\n\ncreate_label &lt;- function(unit, count) {\n    paste0(unit, ': ', count)\n}\n\n\nbook_challenge_sf &lt;- book_challenge_sf |&gt; mutate(lab = create_label(gn_name, count))\nbook_challenge_sf |&gt; mapview(zcol = 'count', label = 'lab')"
  },
  {
    "objectID": "w6-slides.html#plotting-function",
    "href": "w6-slides.html#plotting-function",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "Plotting Function",
    "text": "Plotting Function\n\n\n\nbook_challenge_sf |&gt;\n  filter(!(postal %in% c('HI', 'AK'))) |&gt;\n  ggplot() +\n  geom_sf(\n    aes(fill = count),\n    color = 'white',\n    size = 0.1\n  ) +\n  geom_sf_label(\n    aes(label = postal),\n    size = 2.5,\n    fill = 'white',\n    alpha = 0.7,\n    color = 'black'\n  ) +\n  scale_fill_viridis(na.value = '#E2E2E2') +\n  theme_minimal() +\n  labs(\n    title = 'Book Challenges by State',\n    subtitle = '2000-2010'\n  )\n\n\n\n\n\n\n\n\n\n\nplot_state_choropleth &lt;- function(sf, col_str, plt_title) {\n    sf |&gt;\n    filter(!(postal %in% c('HI', 'AK'))) |&gt;\n    ggplot() +\n    geom_sf(\n      aes_string(fill = col_str),\n      color = 'white',\n      size = 0.1\n    ) +\n    geom_sf_label(\n      aes(label = postal),\n      size = 2.5,\n      fill = 'white',\n      alpha = 0.7,\n      color = 'black'\n    ) +\n    scale_fill_viridis(na.value = '#E2E2E2') +\n    theme_minimal() +\n    labs(\n      title = plt_title,\n      subtitle = '2000-2010'\n    )\n}\n\n\n\nplot_state_choropleth(\n    book_challenge_sf,\n    'count',\n    'Book Challenges by State'\n    )\n\n\n\n\n\n\n\n\n\nplot_state_choropleth(book_challenge_sf, 'median_income', 'State Median Income')\n\n\n\n\n\n\n\n\n\nbook_challenge_sf |&gt; plot_state_choropleth('political_value_index', 'Political Value Index')"
  },
  {
    "objectID": "w6-slides.html#arrange",
    "href": "w6-slides.html#arrange",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "arrange()",
    "text": "arrange()\n\nSort observations by column value\n\n\nbook_challenge_sf |&gt;\n  arrange(desc(count)) |&gt;\n  pull(lab)\n\n [1] \"Pennsylvania: 147\"        \"Oregon: 118\"             \n [3] \"Colorado: 80\"             \"California: 50\"          \n [5] \"Illinois: 39\"             \"Michigan: 34\"            \n [7] \"Virginia: 33\"             \"Ohio: 29\"                \n [9] \"Florida: 26\"              \"New York: 24\"            \n[11] \"Oklahoma: 23\"             \"North Carolina: 20\"      \n[13] \"Indiana: 20\"              \"Minnesota: 17\"           \n[15] \"South Carolina: 15\"       \"Idaho: 14\"               \n[17] \"Vermont: 13\"              \"Georgia: 13\"             \n[19] \"Kansas: 13\"               \"Iowa: 13\"                \n[21] \"Kentucky: 13\"             \"Tennessee: 13\"           \n[23] \"Arizona: 12\"              \"Louisiana: 12\"           \n[25] \"New Jersey: 11\"           \"Missouri: 11\"            \n[27] \"Alabama: 10\"              \"Wisconsin: 10\"           \n[29] \"Washington: 9\"            \"Alaska: 9\"               \n[31] \"Massachusetts: 8\"         \"Montana: 7\"              \n[33] \"New Hampshire: 7\"         \"North Dakota: 6\"         \n[35] \"Connecticut: 6\"           \"Maryland: 5\"             \n[37] \"Arkansas: 5\"              \"Wyoming: 4\"              \n[39] \"Maine: 3\"                 \"New Mexico: 3\"           \n[41] \"Rhode Island: 3\"          \"South Dakota: 3\"         \n[43] \"West Virginia: 3\"         \"Delaware: 2\"             \n[45] \"Nebraska: 2\"              \"Mississippi: 1\"          \n[47] \"Utah: 1\"                  \"Texas: NA\"               \n[49] \"District of Columbia: NA\" \"Hawaii: NA\"              \n[51] \"Nevada: NA\"              \n\n\n\nbook_challenge_sf |&gt;\n  arrange(political_value_index) |&gt;\n  select(gn_name, count, political_value_index)\n\n\n\n\n\n\n\n\n\n\n\ngn_name\ncount\npolitical_value_index\ngeom\n\n\n\n\nUtah\n1\n-20.2\nMULTIPOLYGON (((-111.0502 4…\n\n\nWyoming\n4\n-19.7\nMULTIPOLYGON (((-109.0463 4…\n\n\nIdaho\n14\n-17.4\nMULTIPOLYGON (((-117.0382 4…\n\n\nOklahoma\n23\n-16.9\nMULTIPOLYGON (((-103.0002 3…\n\n\nNebraska\n2\n-13.5\nMULTIPOLYGON (((-104.0537 4…\n\n\nAlaska\n9\n-13.4\nMULTIPOLYGON (((-141.0056 6…\n\n\nAlabama\n10\n-13.2\nMULTIPOLYGON (((-87.41958 3…\n\n\nKansas\n13\n-11.5\nMULTIPOLYGON (((-102.0396 3…\n\n\nNorth Dakota\n6\n-10.4\nMULTIPOLYGON (((-104.0476 4…\n\n\nKentucky\n13\n-10.4\nMULTIPOLYGON (((-89.42446 3…\n\n\nLouisiana\n12\n-9.7\nMULTIPOLYGON (((-89.52599 3…\n\n\nMississippi\n1\n-9.5\nMULTIPOLYGON (((-88.40221 3…\n\n\nSouth Dakota\n3\n-8.9\nMULTIPOLYGON (((-104.0567 4…\n\n\nArkansas\n5\n-8.8\nMULTIPOLYGON (((-90.30422 3…\n\n\nTennessee\n13\n-8.7\nMULTIPOLYGON (((-90.30422 3…\n\n\nWest Virginia\n3\n-7.9\nMULTIPOLYGON (((-82.58945 3…\n\n\nSouth Carolina\n15\n-7.8\nMULTIPOLYGON (((-78.57316 3…\n\n\nMontana\n7\n-7.1\nMULTIPOLYGON (((-116.0482 4…\n\n\nGeorgia\n13\n-6.8\nMULTIPOLYGON (((-80.89029 3…\n\n\nIndiana\n20\n-6.2\nMULTIPOLYGON (((-84.80608 4…\n\n\nArizona\n12\n-6.1\nMULTIPOLYGON (((-111.0063 3…\n\n\nNorth Carolina\n20\n-4.3\nMULTIPOLYGON (((-76.03173 3…\n\n\nMissouri\n11\n-3.1\nMULTIPOLYGON (((-95.31725 4…\n\n\nFlorida\n26\n-1.8\nMULTIPOLYGON (((-87.44734 3…\n\n\nVirginia\n33\n-1.7\nMULTIPOLYGON (((-76.01325 3…\n\n\nOhio\n29\n-0.7\nMULTIPOLYGON (((-80.52023 4…\n\n\nColorado\n80\n-0.2\nMULTIPOLYGON (((-109.0463 4…\n\n\nIowa\n13\n1.0\nMULTIPOLYGON (((-96.48266 4…\n\n\nNew Hampshire\n7\n1.6\nMULTIPOLYGON (((-71.50585 4…\n\n\nPennsylvania\n147\n2.0\nMULTIPOLYGON (((-79.76301 4…\n\n\nMinnesota\n17\n2.3\nMULTIPOLYGON (((-97.22609 4…\n\n\nNew Mexico\n3\n2.4\nMULTIPOLYGON (((-108.1375 3…\n\n\nWisconsin\n10\n2.4\nMULTIPOLYGON (((-87.80425 4…\n\n\nMichigan\n34\n3.8\nMULTIPOLYGON (((-84.4913 46…\n\n\nOregon\n118\n4.0\nMULTIPOLYGON (((-124.4924 4…\n\n\nNew Jersey\n11\n4.4\nMULTIPOLYGON (((-75.54133 3…\n\n\nWashington\n9\n5.0\nMULTIPOLYGON (((-122.753 48…\n\n\nMaine\n3\n5.5\nMULTIPOLYGON (((-71.08495 4…\n\n\nDelaware\n2\n7.0\nMULTIPOLYGON (((-75.05809 3…\n\n\nConnecticut\n6\n7.1\nMULTIPOLYGON (((-73.6417 41…\n\n\nCalifornia\n50\n7.4\nMULTIPOLYGON (((-114.7243 3…\n\n\nIllinois\n39\n7.7\nMULTIPOLYGON (((-89.1237 36…\n\n\nMaryland\n5\n8.5\nMULTIPOLYGON (((-75.64786 3…\n\n\nNew York\n24\n10.2\nMULTIPOLYGON (((-79.06523 4…\n\n\nRhode Island\n3\n11.2\nMULTIPOLYGON (((-71.23686 4…\n\n\nMassachusetts\n8\n11.7\nMULTIPOLYGON (((-71.19396 4…\n\n\nVermont\n13\n13.4\nMULTIPOLYGON (((-73.35134 4…\n\n\nTexas\nNA\nNA\nMULTIPOLYGON (((-103.3115 2…\n\n\nDistrict of Columbia\nNA\nNA\nMULTIPOLYGON (((-77.02293 3…\n\n\nHawaii\nNA\nNA\nMULTIPOLYGON (((-154.8996 1…\n\n\nNevada\nNA\nNA\nMULTIPOLYGON (((-114.0425 4…\n\n\n\n\n\n\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\n\n\nbook_challenge_df |&gt; arrange(author, title) |&gt; head(10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nGo and Come Back\n721\nAbelove, Joan\n2000-06-18\n2000\n0\n1\n0\n0\n0\n0\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.2237299\n\n\nFinding Our Way–The Teen Girl Survival Guide\n695\nAbner, Allison\n2002-05-21\n2002\n0\n1\n0\n0\n0\n0\n0\nAZ\n-6.1\n3490.5\n1.438042\n-0.5237299\n\n\nDeath Blossoms\n522\nAbu-Jamal, Mumia\n2005-07-03\n2005\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nTijuana Bibles\n1811\nAdelman, Bob\n2000-06-29\n2000\n0\n1\n0\n0\n0\n0\n1\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nArt for Lovers\n160\nAdler, Sabine\n2005-04-08\n2005\n0\n0\n0\n0\n0\n0\n0\nOR\n4.0\n1274.5\n5.538042\n1.0762701\n\n\nPsychic Academy Series\n1484\nAki, Katsu\n2008-06-07\n2008\n0\n0\n0\n0\n0\n0\n0\nVA\n-1.7\n11296.0\n1.938042\n5.4762701\n\n\nMonkey High Vol. 3\n1277\nAkira, Shouko\n2009-05-06\n2009\n0\n0\n0\n0\n0\n0\n0\nMI\n3.8\n2966.0\n3.838042\n-2.2237299\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2008-10-02\n2008\n1\n0\n0\n0\n0\n0\n0\nIA\n1.0\n3921.5\n6.538042\n-2.8237299\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2009-05-04\n2009\n0\n1\n0\n0\n1\n0\n0\nIL\n7.7\n6489.5\n1.838042\n2.0762701\n\n\nAbsolutely True Diary of a Part-Time Indian, The\n69\nAlexie, Sherman\n2010-05-12\n2010\n1\n0\n0\n0\n1\n0\n1\nMO\n-3.1\n1279.5\n1.738042\n-2.4237299"
  },
  {
    "objectID": "w6-slides.html#slice_sample",
    "href": "w6-slides.html#slice_sample",
    "title": "R Coding Workshop: 4th Meeting",
    "section": "slice_sample()",
    "text": "slice_sample()\n\nbook_challenge_df |&gt; slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nJoy of Gay Sex, The\n1054\nSilverstein, Dr. Charles and Felice Picano\n2009-01-02\n2009\n1\n1\n0\n0\n0\n0\n0\nKS\n-11.5\n144.5\n6.4380421\n1.7762701\n\n\nYu Yu Hakusho (series)\n2057\nTogashi, Yoshihiro\n2008-11-14\n2008\n0\n1\n0\n0\n0\n0\n1\nAZ\n-6.1\n3490.5\n1.4380421\n-0.5237299\n\n\nTenderness\n1772\nCormier, Robert\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2.0\n4218.0\n2.3380421\n-1.6237299\n\n\nLittle Giant Book of Whodunits, The\n1147\nConrad, Hy\n2008-01-04\n2008\n0\n0\n1\n0\n1\n0\n1\nNY\n10.2\n5007.5\n-0.4619579\n3.3762701\n\n\nKilling Johnny Fry\n1080\nMosely, Walter\n2008-04-02\n2008\n0\n1\n0\n0\n0\n0\n0\nOK\n-16.9\n-3087.5\n1.0380421\n-3.7237299\n\n\nMessage Bible\n1251\nPeterson, Eugene H\n2010-05-26\n2010\n0\n0\n0\n0\n0\n0\n0\nNC\n-4.3\n-310.0\n-1.4619579\n-1.5237299\n\n\nSlaughterhouse-Five\n1643\nVonnegut, Kurt\n2001-04-25\n2001\n0\n1\n0\n0\n1\n0\n0\nTN\n-8.7\n-2995.5\n-3.6619579\n-4.4237299\n\n\nStarplace, The\n1699\nGrove, Vicki\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2.0\n4218.0\n2.3380421\n-1.6237299\n\n\nTransparent: Love, Family, and Living the T with Transgender Teenagers\n1834\nBeam, Chris\n2009-08-09\n2009\n0\n0\n0\n0\n0\n1\n0\nCA\n7.4\n10119.0\n-2.7619579\n2.5762701\n\n\nVillages\n1903\nUpdike, John\n2006-07-27\n2006\n0\n1\n0\n0\n1\n0\n0\nID\n-17.4\n3194.0\n5.1380421\n-2.3237299\n\n\n\n\n\n\n\nbook_challenge_df |&gt;\n  filter(state == 'PA') |&gt;\n  slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nThis Is What I Did\n1800\nEllis, Ann Dee\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nDiary of a Groupie\n539\nTyree, Omar\n2005-09-24\n2005\n0\n1\n0\n0\n1\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nThings They Carried, The\n1792\nO’Brein, Tim\n2001-04-25\n2001\n0\n1\n0\n0\n1\n0\n1\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nWhat Happened to Cass McBride?\n1944\nGiles, Gail\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nPrey\n1476\nMcDaniel, Lurlene\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nLike Sisters on the Homefront\n1139\nWilliams-Garcia, Rita\n2000-08-28\n2000\n1\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nMartian Chronicles, The\n1237\nBradbury, Ray\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nImpulse\n981\nHopkins, Ellen\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nLucky\n1199\nSebold, Alice\n2009-11-09\n2009\n0\n0\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373\n\n\nDanse Macabre\n503\nHamilton, Laurell K.\n2007-05-23\n2007\n0\n1\n0\n0\n0\n0\n0\nPA\n2\n4218\n2.338042\n-1.62373"
  },
  {
    "objectID": "w9-idx.html#goals-for-today",
    "href": "w9-idx.html#goals-for-today",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Goals for Today",
    "text": "Goals for Today\n\nReview R fundamentals\nWalk through the R workflow for (geospatial) data analysis\nMake sense of objects and functions in R\nMove back and forth with df, sf, ppp\nIntro to control flow (if and case_when)",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#review",
    "href": "w9-idx.html#review",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Review",
    "text": "Review\n\n\nEverything that exists in R is an object.(Chambers (2016))1\nR uses functions to perform operations.(James (2021))2",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#the-workflow-1-setting-up-the-environment",
    "href": "w9-idx.html#the-workflow-1-setting-up-the-environment",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The Workflow 1: Setting up the Environment",
    "text": "The Workflow 1: Setting up the Environment\n\nselect a working environment and explore their features(Positron, Jupyterhub)\nOpen your .qmd file or create one\n\n\nR Session\n\nUse getwd() and setwd() to get information about working directory the or set them manually to tell R where to look for files during this session\n\ngetwd()\nsetwd('~/myfolder')\n\nUse the library() function to load the packages for our R session.\n\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\nlibrary(spdep)\nlibrary(sfdep)\nlibrary(spatstat)\nlibrary(terra)\nlibrary(stars)",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#the-workflow-2-preparing-data-objects",
    "href": "w9-idx.html#the-workflow-2-preparing-data-objects",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The Workflow 2: Preparing Data objects",
    "text": "The Workflow 2: Preparing Data objects\n\nuni_df &lt;- tibble::tribble(\n  ~university, ~year, ~current_country, ~lat, ~lon, ~exist_today,\n  \"Paris\", 1150, \"France\", 48.8566, 2.3522, TRUE,\n  \"Salerno\", 1173,  \"Italy\", 40.7711, 14.7905, TRUE,\n  \"Reggio\", 1188, \"Italy\", 44.6450, 10.9277, TRUE,\n  \"Oxford\", 1190, \"United Kingdom\", 51.7520, -1.2576, TRUE,\n  \"Bologna\", 1200, \"Italy\", 44.4989, 11.3275, TRUE\n)\n# uni_df\nuni_sf &lt;- uni_df |&gt;\n    st_as_sf(\n        coords = c('lon','lat'),\n        crs = 4326\n    )\n# uni_sf |&gt; mapview(label = 'university')\nuni_sfc &lt;- uni_sf |&gt; pull(geometry)\n\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\n\nRows: 931 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): title, author, state\ndbl  (13): book_id, year, removed, explicit, antifamily, occult, language, l...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nne_vars &lt;- c(\"geounit\", \"pop_est\", \"pop_rank\", \"pop_year\", \"gdp_md\", \"gdp_year\", \"economy\", \"income_grp\", \"iso_a2\", \"continent\", \"region_un\", \"subregion\", \"region_wb\")\ncca_sf &lt;- ne_countries(\n    country = c(\n        \"Kazakhstan\", \"Kyrgyzstan\", \"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Armenia\", \"Azerbaijan\", \"Georgia\"),\n    scale = 50) |&gt; select(any_of(ne_vars))\ncca_sfc &lt;- cca_sf |&gt; st_geometry()\n\n\nazerbaijan_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'AZ')\nazerbaijan_sfc &lt;- azerbaijan_sf |&gt; st_geometry()\n\n\ngeorgia_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'GE')\n\n\ncca_nb &lt;- cca_sf |&gt; st_contiguity()\n\nWarning in spdep::poly2nb(geometry, queen = queen, ...): neighbour object has 2 sub-graphs;\nif this sub-graph count seems unexpected, try increasing the snap argument.\n\ncca_listw &lt;- cca_nb |&gt; st_weights()",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#finding-help-read-function-documentations",
    "href": "w9-idx.html#finding-help-read-function-documentations",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "3. Finding Help: read function documentations",
    "text": "3. Finding Help: read function documentations\nWays to access function documentation:\n\nAdd a question mark in front of the function name: ?func_name\n\n\n?mutate\n\n\n??\"aggregate\"\n\n\nUse the help() function\n\n\nhelp('mutate')\n\n\nhelp('filter', package = 'dplyr')\n\n\nIf you are interested in the what are the arguments that the function can take, use args() to check\n\n\nmoran |&gt; class() |&gt; print()\n\n[1] \"function\"\n\nargs(moran)\n\nfunction (x, listw, n, S0, zero.policy = attr(listw, \"zero.policy\"), \n    NAOK = FALSE) \nNULL\n\n\n\nSimply, hover over the function name!\n\n\n'Try hover over a function in your code!' |&gt; print()\n\n[1] \"Try hover over a function in your code!\"",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#a-closer-look-at-the-data-structure-of-an-df-object",
    "href": "w9-idx.html#a-closer-look-at-the-data-structure-of-an-df-object",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "A closer look at the data structure of an df object",
    "text": "A closer look at the data structure of an df object\n\nclass() function tells us that uni_df is a “data.frame” object data object with an additional class `“tbl_df”\ntypeof() call shows the storage mode of uni_df, which is list\n\n\nuni_df |&gt; class() |&gt; print()\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nuni_df |&gt; typeof() |&gt; print()\n\n[1] \"list\"\n\n\n\ndescribe and extract attributes of a df object using dim() and colnames()\n\n\nuni_df |&gt; dim() |&gt; print()\n\n[1] 5 6\n\nuni_df |&gt; colnames()\n\n[1] \"university\"      \"year\"            \"current_country\" \"lat\"            \n[5] \"lon\"             \"exist_today\"",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#longer-and-wider-dataframes",
    "href": "w9-idx.html#longer-and-wider-dataframes",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Longer and Wider Dataframes",
    "text": "Longer and Wider Dataframes\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\n\nRows: 931 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (3): title, author, state\ndbl  (13): book_id, year, removed, explicit, antifamily, occult, language, l...\ndate  (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbook_challenge_df |&gt; dim() |&gt; print()\n\n[1] 931  17\n\n\n\nbasic display functions: head(), tail() and slice_sample()\n\n\nbook_challenge_df |&gt; tail()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nAnd Tango Makes Three\n143\nParnell, Peter and Justin Richardson\n2006-10-29\n2006\n0\n0\n0\n0\n0\n1\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.22373\n\n\nGo and Come Back\n721\nAbelove, Joan\n2000-06-18\n2000\n0\n1\n0\n0\n0\n0\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.22373\n\n\nWhen Dad Killed Mom\n1964\nLester, Julius\n2002-04-21\n2002\n1\n0\n0\n0\n0\n0\n1\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nGeology Book, The\n755\nMorris, Dr. John D.\n2010-05-05\n2010\n0\n0\n0\n0\n0\n0\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nAnd Tango Makes Three\n143\nParnell, Peter and Justin Richardson\n2009-08-22\n2009\n0\n0\n0\n0\n0\n1\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nDarkest Night of the Year\n505\nKoontz, Dean\n2007-12-03\n2007\n0\n1\n0\n0\n0\n0\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\n\n\n\n\n\nbook_challenge_df |&gt; slice_sample(n = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nWonderful Story Henry Sugar and Six More, The\n2034\nDahl, Roald\n2007-07-22\n2007\n1\n0\n0\n0\n0\n0\n1\nIL\n7.7\n6489.5\n1.838042\n2.07627\n\n\nWhale Talk\n1941\nCrutcher, Chris\n2005-06-09\n2005\n1\n0\n0\n0\n1\n0\n0\nAL\n-13.2\n-5054.0\n-4.261958\n-5.02373\n\n\nHarry Potter (series)\n868\nRowling, J.K.\n2001-04-25\n2001\n0\n0\n0\n1\n0\n0\n0\nMI\n3.8\n2966.0\n3.838042\n-2.22373\n\n\nThey’re All Named Wildfire\n1789\nSpringer, Nancy\n2005-08-02\n2005\n0\n0\n0\n0\n1\n0\n1\nCA\n7.4\n10119.0\n-2.761958\n2.57627\n\n\n\n\n\n\n\noptimized display to show all columns glimpse()\n\n\nbook_challenge_df |&gt; glimpse()\n\nRows: 931\nColumns: 17\n$ title                 &lt;chr&gt; \"House of the Spirits, The\", \"It's Not the Stork…\n$ book_id               &lt;dbl&gt; 927, 1024, 1087, 936, 764, 1087, 1489, 2023, 102…\n$ author                &lt;chr&gt; \"Allende, Isabel\", \"Harris, Robie\", \"Pyle, Howar…\n$ date                  &lt;date&gt; 2005-04-01, 2008-02-06, 2008-10-02, 2008-10-05,…\n$ year                  &lt;dbl&gt; 2005, 2008, 2008, 2008, 2008, 2003, 2003, 2003, …\n$ removed               &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, …\n$ explicit              &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, …\n$ antifamily            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ occult                &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ language              &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ lgbtq                 &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ violent               &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ state                 &lt;chr&gt; \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", …\n$ political_value_index &lt;dbl&gt; -13.4, -13.4, -13.4, -13.4, -13.4, -13.4, -13.4,…\n$ median_income         &lt;dbl&gt; 15707.5, 15707.5, 15707.5, 15707.5, 15707.5, 157…\n$ hs_grad_rate          &lt;dbl&gt; 8.738042, 8.738042, 8.738042, 8.738042, 8.738042…\n$ college_grad_rate     &lt;dbl&gt; 0.6762701, 0.6762701, 0.6762701, 0.6762701, 0.67…\n\n\n\nview() tidyverse summary() equivalent\n\n\nbook_challenge_df |&gt; view()",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#the-structure-and-the-components-of-an-sf-object",
    "href": "w9-idx.html#the-structure-and-the-components-of-an-sf-object",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The structure and the components of an sf object",
    "text": "The structure and the components of an sf object\n\n\n\nan sf object can simultaneously be of classes “sf”, “tbl_df” and “data.frame”\nUsing the function typeof() or mode() we can inspect that uni_sf is stored as using a list\n\n\n\nuni_sf |&gt; class()\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nuni_sf |&gt; typeof()\n\n[1] \"list\"\n\n\n\n\n\nAttributes of an sf object\n\ndf attributes\nsf column\n\ncoordinate reference system: st_crs()\nbounding box: st_bbox()\ngeometry type\n\nattribute-geometry-relationship\n\n\n\n\nuni_sf\n\n\n\n\n\n\n\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nexist_today\ngeometry\n\n\n\n\nParis\n1150\nFrance\nTRUE\nPOINT (2.3522 48.8566)\n\n\nSalerno\n1173\nItaly\nTRUE\nPOINT (14.7905 40.7711)\n\n\nReggio\n1188\nItaly\nTRUE\nPOINT (10.9277 44.645)\n\n\nOxford\n1190\nUnited Kingdom\nTRUE\nPOINT (-1.2576 51.752)\n\n\nBologna\n1200\nItaly\nTRUE\nPOINT (11.3275 44.4989)\n\n\n\n\n\n\n\n\nuni_sf |&gt; str()\n\nsf [5 × 5] (S3: sf/tbl_df/tbl/data.frame)\n $ university     : chr [1:5] \"Paris\" \"Salerno\" \"Reggio\" \"Oxford\" ...\n $ year           : num [1:5] 1150 1173 1188 1190 1200\n $ current_country: chr [1:5] \"France\" \"Italy\" \"Italy\" \"United Kingdom\" ...\n $ exist_today    : logi [1:5] TRUE TRUE TRUE TRUE TRUE\n $ geometry       :sfc_POINT of length 5; first list element:  'XY' num [1:2] 2.35 48.86\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:4] \"university\" \"year\" \"current_country\" \"exist_today\"\n\n\n\n\n\nuni_sf |&gt; st_crs()\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nuni_sf |&gt; st_bbox() |&gt; st_as_sfc() |&gt; st_as_sf() |&gt; mapview()",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#geometry-column-a-closer-look",
    "href": "w9-idx.html#geometry-column-a-closer-look",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Geometry column: a closer look",
    "text": "Geometry column: a closer look\n\nGet the name of the geometry column\n\n\nuni_sf |&gt; attr(which = 'sf_column')\n\n[1] \"geometry\"\n\n\n\nSingle out the geometry column\n\n\npull() tidyverse equivalent for $: input a df, a column name, output a vector\n\n\nuni_sf |&gt; pull(geometry) |&gt; class()\n\n[1] \"sfc_POINT\" \"sfc\"      \n\nuni_sfc &lt;- uni_sf |&gt; pull(geometry)\n# uni_sfc &lt;- uni_sf$geometry\n\n\nor st_geometry()\n\n\nuni_sfc &lt;- uni_sf |&gt; st_geometry()\n\n\nuni_sfc |&gt; class() |&gt; print()\n\n[1] \"sfc_POINT\" \"sfc\"      \n\nuni_sfc |&gt; typeof()\n\n[1] \"list\"\n\n\n\naccess list items\n\n\nuni_sfc[[4]]\n\nPOINT (-1.2576 51.752)\n\n\n\nuni_sfc[[4]] |&gt; class()\n\n[1] \"XY\"    \"POINT\" \"sfg\"  \n\n\nsummary\n\n\n\nsf: simple feature collection.\n\n\nuni_sf\n\n\n\n\n\n\n\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nexist_today\ngeometry\n\n\n\n\nParis\n1150\nFrance\nTRUE\nPOINT (2.3522 48.8566)\n\n\nSalerno\n1173\nItaly\nTRUE\nPOINT (14.7905 40.7711)\n\n\nReggio\n1188\nItaly\nTRUE\nPOINT (10.9277 44.645)\n\n\nOxford\n1190\nUnited Kingdom\nTRUE\nPOINT (-1.2576 51.752)\n\n\nBologna\n1200\nItaly\nTRUE\nPOINT (11.3275 44.4989)\n\n\n\n\n\n\n\n\nsfc: simple feature list-column(Pebesma and Bivand (2023))\n\n\nuni_sfc\n\nGeometry set for 5 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -1.2576 ymin: 40.7711 xmax: 14.7905 ymax: 51.752\nGeodetic CRS:  WGS 84\n\n\nPOINT (2.3522 48.8566)\n\n\nPOINT (14.7905 40.7711)\n\n\nPOINT (10.9277 44.645)\n\n\nPOINT (-1.2576 51.752)\n\n\nPOINT (11.3275 44.4989)\n\n\n\n\nsfg: single geometry\n\n\nuni_sfc[[4]]\n\nPOINT (-1.2576 51.752)",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#st_geometry-make-use-of-the-list-structure",
    "href": "w9-idx.html#st_geometry-make-use-of-the-list-structure",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "st_geometry: make use of the list structure",
    "text": "st_geometry: make use of the list structure\n\nazerbaijan_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'AZ')\n\n\nazerbaijan_sf |&gt; mapview()\n\n\n\n\n\n\nazerbaijan_sf |&gt; glimpse()\n\nRows: 1\nColumns: 14\n$ geounit    &lt;chr&gt; \"Azerbaijan\"\n$ pop_est    &lt;dbl&gt; 10023318\n$ pop_rank   &lt;int&gt; 14\n$ pop_year   &lt;int&gt; 2019\n$ gdp_md     &lt;int&gt; 48047\n$ gdp_year   &lt;int&gt; 2019\n$ economy    &lt;chr&gt; \"6. Developing region\"\n$ income_grp &lt;chr&gt; \"3. Upper middle income\"\n$ iso_a2     &lt;chr&gt; \"AZ\"\n$ continent  &lt;chr&gt; \"Asia\"\n$ region_un  &lt;chr&gt; \"Asia\"\n$ subregion  &lt;chr&gt; \"Western Asia\"\n$ region_wb  &lt;chr&gt; \"Europe & Central Asia\"\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((44.81719 39...\n\n\n\n\n\nsave the sf geometry column as azerbaijan_sfc\n\n\nazerbaijan_sfc &lt;- azerbaijan_sf |&gt; st_geometry()\nazerbaijan_sfc |&gt; glimpse()\n\nsfc_MULTIPOLYGON of length 1; first list element: List of 3\n $ :List of 1\n  ..$ : num [1:41, 1:2] 44.8 44.8 44.8 44.9 45 ...\n $ :List of 2\n  ..$ : num [1:206, 1:2] 48.9 48.8 48.6 48.6 48.4 ...\n  ..$ : num [1:8, 1:2] 45.6 45.6 45.5 45.5 45.5 ...\n $ :List of 1\n  ..$ : num [1:9, 1:2] 45 45 45 45 45 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n\n\n\n\nazerbaijan_sfc |&gt; class() |&gt; print()\n\n[1] \"sfc_MULTIPOLYGON\" \"sfc\"             \n\nazerbaijan_sfc |&gt; typeof() |&gt; print()\n\n[1] \"list\"\n\nazerbaijan_sfc[[1]][[3]][[1]] |&gt; class()\n\n[1] \"matrix\" \"array\" \n\nazerbaijan_sfc[[1]][[3]][[1]]\n\n          [,1]     [,2]\n [1,] 45.02363 41.02725\n [2,] 45.00205 41.01582\n [3,] 44.96904 41.02725\n [4,] 44.95889 41.05264\n [5,] 44.96143 41.07925\n [6,] 44.99434 41.08560\n [7,] 45.02109 41.07798\n [8,] 45.02871 41.05386\n [9,] 45.02363 41.02725\n\n\n\n\n\naz_poly1 &lt;- azerbaijan_sfc[[1]][[1]] |&gt; st_polygon()\naz_poly2 &lt;- azerbaijan_sfc[[1]][[2]] |&gt; st_polygon()\naz_poly3 &lt;- azerbaijan_sfc[[1]][[3]] |&gt; st_polygon()\n\nazer_piece_sfc &lt;- list(az_poly1, az_poly2, az_poly3) |&gt;\n  st_as_sfc()\n\n\nazer_piece_df &lt;- tibble(\n    geometry = azer_piece_sfc,\n    lab = c('Nagorno-Karabakh', 'Azerbaijan Main', 'Yukhari Askipara')\n)\nazer_piece_sf &lt;- azer_piece_df |&gt; st_as_sf(crs = 4326)\n\n\nazer_piece_sf |&gt; mapview(zcol = 'lab', label = 'lab')\n\n\n\n\nazer_piece_sf\n\n\n\n\n\ngeometry\nlab\n\n\n\n\nPOLYGON ((44.81719 39.65044…\nNagorno-Karabakh\n\n\nPOLYGON ((48.86875 38.4355,…\nAzerbaijan Main\n\n\nPOLYGON ((45.02363 41.02725…\nYukhari Askipara",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#sfg-to-sfc",
    "href": "w9-idx.html#sfg-to-sfc",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "sfg to sfc",
    "text": "sfg to sfc\n\nInner Ring\n\n\n\nazerbaijan_sfc[[1]][[2]][[2]] |&gt; class() |&gt; print()\n\n[1] \"matrix\" \"array\" \n\nazerbaijan_sfc[[1]][[2]][[2]]\n\n         [,1]     [,2]\n[1,] 45.55234 40.61606\n[2,] 45.56230 40.64917\n[3,] 45.53418 40.66401\n[4,] 45.50449 40.66484\n[5,] 45.47881 40.64834\n[6,] 45.47881 40.60698\n[7,] 45.51436 40.59956\n[8,] 45.55234 40.61606\n\n\n\n\nazerbaijan_sfc[[1]][[2]][[2]] |&gt; list() |&gt; st_polygon() |&gt; ggplot() + geom_sf() + theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nOuter Ring\n\n\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; dim() |&gt; print()\n\n[1] 206   2\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; head()\n\n         [,1]     [,2]\n[1,] 48.86875 38.43550\n[2,] 48.84033 38.43726\n[3,] 48.63555 38.39873\n[4,] 48.59268 38.41108\n[5,] 48.41738 38.58623\n[6,] 48.38125 38.60562\n\n\n\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; list() |&gt; st_polygon() |&gt; ggplot() + geom_sf() + theme_bw()\n\n\n\n\n\n\n\n\n\n\n\nazerbaijan_outer_ring &lt;- azerbaijan_sfc[[1]][[2]][[1]]\nazerbaijan_inner_ring &lt;- azerbaijan_sfc[[1]][[2]][[2]]\n\n\nazerbaijan_polygon &lt;- st_polygon(list(azerbaijan_outer_ring, azerbaijan_inner_ring))\n\nazerbaijan_polygon |&gt;\n    ggplot() +\n    geom_sf(fill = \"lightblue\") +\n    theme_bw()",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-idx.html#footnotes",
    "href": "w9-idx.html#footnotes",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\np. 4↩︎\nJames (2021), p. 43↩︎",
    "crumbs": [
      "Coding Workshop",
      "Week 9"
    ]
  },
  {
    "objectID": "w9-slides.html#r-coding-workshop-for-gis-7th-meeting",
    "href": "w9-slides.html#r-coding-workshop-for-gis-7th-meeting",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "R Coding Workshop for GIS: 7th Meeting",
    "text": "R Coding Workshop for GIS: 7th Meeting"
  },
  {
    "objectID": "w9-slides.html#goals-for-today",
    "href": "w9-slides.html#goals-for-today",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Goals for Today",
    "text": "Goals for Today\n\nReview R fundamentals\nWalk through the R workflow for (geospatial) data analysis\nMake sense of objects and functions in R\nMove back and forth with df, sf, ppp\nIntro to control flow (if and case_when)"
  },
  {
    "objectID": "w9-slides.html#review",
    "href": "w9-slides.html#review",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Review",
    "text": "Review\n\nEverything that exists in R is an object.(Chambers (2016))1\nR uses functions to perform operations.(James (2021))2\n\np. 4James (2021), p. 43"
  },
  {
    "objectID": "w9-slides.html#the-workflow-1-setting-up-the-environment",
    "href": "w9-slides.html#the-workflow-1-setting-up-the-environment",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The Workflow 1: Setting up the Environment",
    "text": "The Workflow 1: Setting up the Environment\n\nselect a working environment and explore their features(Positron, Jupyterhub)\nOpen your .qmd file or create one\n\nR Session\n\nUse getwd() and setwd() to get information about working directory the or set them manually to tell R where to look for files during this session\n\ngetwd()\nsetwd('~/myfolder')\n\nUse the library() function to load the packages for our R session.\n\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\nlibrary(spdep)\nlibrary(sfdep)\nlibrary(spatstat)\nlibrary(terra)\nlibrary(stars)"
  },
  {
    "objectID": "w9-slides.html#the-workflow-2-preparing-data-objects",
    "href": "w9-slides.html#the-workflow-2-preparing-data-objects",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The Workflow 2: Preparing Data objects",
    "text": "The Workflow 2: Preparing Data objects\n\nuni_df &lt;- tibble::tribble(\n  ~university, ~year, ~current_country, ~lat, ~lon, ~exist_today,\n  \"Paris\", 1150, \"France\", 48.8566, 2.3522, TRUE,\n  \"Salerno\", 1173,  \"Italy\", 40.7711, 14.7905, TRUE,\n  \"Reggio\", 1188, \"Italy\", 44.6450, 10.9277, TRUE,\n  \"Oxford\", 1190, \"United Kingdom\", 51.7520, -1.2576, TRUE,\n  \"Bologna\", 1200, \"Italy\", 44.4989, 11.3275, TRUE\n)\n# uni_df\nuni_sf &lt;- uni_df |&gt;\n    st_as_sf(\n        coords = c('lon','lat'),\n        crs = 4326\n    )\n# uni_sf |&gt; mapview(label = 'university')\nuni_sfc &lt;- uni_sf |&gt; pull(geometry)\n\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\n\n\nne_vars &lt;- c(\"geounit\", \"pop_est\", \"pop_rank\", \"pop_year\", \"gdp_md\", \"gdp_year\", \"economy\", \"income_grp\", \"iso_a2\", \"continent\", \"region_un\", \"subregion\", \"region_wb\")\ncca_sf &lt;- ne_countries(\n    country = c(\n        \"Kazakhstan\", \"Kyrgyzstan\", \"Tajikistan\", \"Turkmenistan\", \"Uzbekistan\", \"Armenia\", \"Azerbaijan\", \"Georgia\"),\n    scale = 50) |&gt; select(any_of(ne_vars))\ncca_sfc &lt;- cca_sf |&gt; st_geometry()\n\n\nazerbaijan_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'AZ')\nazerbaijan_sfc &lt;- azerbaijan_sf |&gt; st_geometry()\n\n\ngeorgia_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'GE')\n\n\ncca_nb &lt;- cca_sf |&gt; st_contiguity()\ncca_listw &lt;- cca_nb |&gt; st_weights()"
  },
  {
    "objectID": "w9-slides.html#finding-help-read-function-documentations",
    "href": "w9-slides.html#finding-help-read-function-documentations",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "3. Finding Help: read function documentations",
    "text": "3. Finding Help: read function documentations\nWays to access function documentation:\n\nAdd a question mark in front of the function name: ?func_name\n\n\n?mutate\n\n\n??\"aggregate\"\n\n\nUse the help() function\n\n\nhelp('mutate')\n\n\nhelp('filter', package = 'dplyr')\n\n\nIf you are interested in the what are the arguments that the function can take, use args() to check\n\n\nmoran |&gt; class() |&gt; print()\n\n[1] \"function\"\n\nargs(moran)\n\nfunction (x, listw, n, S0, zero.policy = attr(listw, \"zero.policy\"), \n    NAOK = FALSE) \nNULL\n\n\n\nSimply, hover over the function name!\n\n\n'Try hover over a function in your code!' |&gt; print()\n\n[1] \"Try hover over a function in your code!\""
  },
  {
    "objectID": "w9-slides.html#a-closer-look-at-the-data-structure-of-an-df-object",
    "href": "w9-slides.html#a-closer-look-at-the-data-structure-of-an-df-object",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "A closer look at the data structure of an df object",
    "text": "A closer look at the data structure of an df object\n\nclass() function tells us that uni_df is a “data.frame” object data object with an additional class `“tbl_df”\ntypeof() call shows the storage mode of uni_df, which is list\n\n\nuni_df |&gt; class() |&gt; print()\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nuni_df |&gt; typeof() |&gt; print()\n\n[1] \"list\"\n\n\n\ndescribe and extract attributes of a df object using dim() and colnames()\n\n\nuni_df |&gt; dim() |&gt; print()\n\n[1] 5 6\n\nuni_df |&gt; colnames()\n\n[1] \"university\"      \"year\"            \"current_country\" \"lat\"            \n[5] \"lon\"             \"exist_today\""
  },
  {
    "objectID": "w9-slides.html#longer-and-wider-dataframes",
    "href": "w9-slides.html#longer-and-wider-dataframes",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Longer and Wider Dataframes",
    "text": "Longer and Wider Dataframes\n\nbook_challenge_df &lt;- read_csv('data/book-challenge11.csv')\nbook_challenge_df |&gt; dim() |&gt; print()\n\n[1] 931  17\n\n\n\nbasic display functions: head(), tail() and slice_sample()\n\n\nbook_challenge_df |&gt; tail()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nAnd Tango Makes Three\n143\nParnell, Peter and Justin Richardson\n2006-10-29\n2006\n0\n0\n0\n0\n0\n1\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.22373\n\n\nGo and Come Back\n721\nAbelove, Joan\n2000-06-18\n2000\n0\n1\n0\n0\n0\n0\n0\nWV\n-7.9\n-7290.0\n-4.361958\n-9.22373\n\n\nWhen Dad Killed Mom\n1964\nLester, Julius\n2002-04-21\n2002\n1\n0\n0\n0\n0\n0\n1\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nGeology Book, The\n755\nMorris, Dr. John D.\n2010-05-05\n2010\n0\n0\n0\n0\n0\n0\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nAnd Tango Makes Three\n143\nParnell, Peter and Justin Richardson\n2009-08-22\n2009\n0\n0\n0\n0\n0\n1\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\nDarkest Night of the Year\n505\nKoontz, Dean\n2007-12-03\n2007\n0\n1\n0\n0\n0\n0\n0\nWY\n-19.7\n4081.5\n8.338042\n-2.12373\n\n\n\n\n\n\n\nbook_challenge_df |&gt; slice_sample(n = 4)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nBridge to Terabithia\n316\nPaterson, Katherine\n2005-04-01\n2005\n0\n1\n0\n0\n1\n0\n0\nVA\n-1.7\n11296.0\n1.938042\n5.47627\n\n\nTurning Angel\n1853\nIles, Greg\n2008-10-04\n2008\n0\n1\n0\n0\n1\n0\n1\nMD\n8.5\n19404.5\n4.238042\n7.37627\n\n\nLook At Me\n1170\nEgan, Jennifer\n2001-12-10\n2001\n0\n1\n0\n0\n0\n0\n0\nMI\n3.8\n2966.0\n3.838042\n-2.22373\n\n\nAngus, Thongs, and Full Frontal Snogging\n148\nRennison, Louise\n2006-07-15\n2006\n0\n0\n0\n0\n0\n0\n0\nVA\n-1.7\n11296.0\n1.938042\n5.47627\n\n\n\n\n\n\n\noptimized display to show all columns glimpse()\n\n\nbook_challenge_df |&gt; glimpse()\n\nRows: 931\nColumns: 17\n$ title                 &lt;chr&gt; \"House of the Spirits, The\", \"It's Not the Stork…\n$ book_id               &lt;dbl&gt; 927, 1024, 1087, 936, 764, 1087, 1489, 2023, 102…\n$ author                &lt;chr&gt; \"Allende, Isabel\", \"Harris, Robie\", \"Pyle, Howar…\n$ date                  &lt;date&gt; 2005-04-01, 2008-02-06, 2008-10-02, 2008-10-05,…\n$ year                  &lt;dbl&gt; 2005, 2008, 2008, 2008, 2008, 2003, 2003, 2003, …\n$ removed               &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, …\n$ explicit              &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, …\n$ antifamily            &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ occult                &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ language              &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, …\n$ lgbtq                 &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ violent               &lt;dbl&gt; 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ state                 &lt;chr&gt; \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", \"AK\", …\n$ political_value_index &lt;dbl&gt; -13.4, -13.4, -13.4, -13.4, -13.4, -13.4, -13.4,…\n$ median_income         &lt;dbl&gt; 15707.5, 15707.5, 15707.5, 15707.5, 15707.5, 157…\n$ hs_grad_rate          &lt;dbl&gt; 8.738042, 8.738042, 8.738042, 8.738042, 8.738042…\n$ college_grad_rate     &lt;dbl&gt; 0.6762701, 0.6762701, 0.6762701, 0.6762701, 0.67…\n\n\n\nview() tidyverse summary() equivalent\n\n\nbook_challenge_df |&gt; view()"
  },
  {
    "objectID": "w9-slides.html#the-structure-and-the-components-of-an-sf-object",
    "href": "w9-slides.html#the-structure-and-the-components-of-an-sf-object",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "The structure and the components of an sf object",
    "text": "The structure and the components of an sf object\n\n\n\nan sf object can simultaneously be of classes “sf”, “tbl_df” and “data.frame”\nUsing the function typeof() or mode() we can inspect that uni_sf is stored as using a list\n\n\n\nuni_sf |&gt; class()\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nuni_sf |&gt; typeof()\n\n[1] \"list\"\n\n\n\nAttributes of an sf object\n\ndf attributes\nsf column\n\ncoordinate reference system: st_crs()\nbounding box: st_bbox()\ngeometry type\n\nattribute-geometry-relationship\n\n\n\n\nuni_sf\n\n\n\n\n\n\n\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nexist_today\ngeometry\n\n\n\n\nParis\n1150\nFrance\nTRUE\nPOINT (2.3522 48.8566)\n\n\nSalerno\n1173\nItaly\nTRUE\nPOINT (14.7905 40.7711)\n\n\nReggio\n1188\nItaly\nTRUE\nPOINT (10.9277 44.645)\n\n\nOxford\n1190\nUnited Kingdom\nTRUE\nPOINT (-1.2576 51.752)\n\n\nBologna\n1200\nItaly\nTRUE\nPOINT (11.3275 44.4989)\n\n\n\n\n\n\n\n\nuni_sf |&gt; str()\n\nsf [5 × 5] (S3: sf/tbl_df/tbl/data.frame)\n $ university     : chr [1:5] \"Paris\" \"Salerno\" \"Reggio\" \"Oxford\" ...\n $ year           : num [1:5] 1150 1173 1188 1190 1200\n $ current_country: chr [1:5] \"France\" \"Italy\" \"Italy\" \"United Kingdom\" ...\n $ exist_today    : logi [1:5] TRUE TRUE TRUE TRUE TRUE\n $ geometry       :sfc_POINT of length 5; first list element:  'XY' num [1:2] 2.35 48.86\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA\n  ..- attr(*, \"names\")= chr [1:4] \"university\" \"year\" \"current_country\" \"exist_today\"\n\n\n\n\nuni_sf |&gt; st_crs()\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nuni_sf |&gt; st_bbox() |&gt; st_as_sfc() |&gt; st_as_sf() |&gt; mapview()"
  },
  {
    "objectID": "w9-slides.html#geometry-column-a-closer-look",
    "href": "w9-slides.html#geometry-column-a-closer-look",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "Geometry column: a closer look",
    "text": "Geometry column: a closer look\n\nGet the name of the geometry column\n\n\nuni_sf |&gt; attr(which = 'sf_column')\n\n[1] \"geometry\"\n\n\n\nSingle out the geometry column\n\n\npull() tidyverse equivalent for $: input a df, a column name, output a vector\n\n\nuni_sf |&gt; pull(geometry) |&gt; class()\n\n[1] \"sfc_POINT\" \"sfc\"      \n\nuni_sfc &lt;- uni_sf |&gt; pull(geometry)\n# uni_sfc &lt;- uni_sf$geometry\n\n\nor st_geometry()\n\n\nuni_sfc &lt;- uni_sf |&gt; st_geometry()\n\n\nuni_sfc |&gt; class() |&gt; print()\n\n[1] \"sfc_POINT\" \"sfc\"      \n\nuni_sfc |&gt; typeof()\n\n[1] \"list\"\n\n\n\naccess list items\n\n\nuni_sfc[[4]]\n\n\nuni_sfc[[4]] |&gt; class()\n\n[1] \"XY\"    \"POINT\" \"sfg\"  \n\n\nsummary\n\n\n\nsf: simple feature collection.\n\n\nuni_sf\n\n\n\n\n\n\n\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nexist_today\ngeometry\n\n\n\n\nParis\n1150\nFrance\nTRUE\nPOINT (2.3522 48.8566)\n\n\nSalerno\n1173\nItaly\nTRUE\nPOINT (14.7905 40.7711)\n\n\nReggio\n1188\nItaly\nTRUE\nPOINT (10.9277 44.645)\n\n\nOxford\n1190\nUnited Kingdom\nTRUE\nPOINT (-1.2576 51.752)\n\n\nBologna\n1200\nItaly\nTRUE\nPOINT (11.3275 44.4989)\n\n\n\n\n\n\n\n\nsfc: simple feature list-column(Pebesma and Bivand (2023))\n\n\nuni_sfc\n\nGeometry set for 5 features \nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -1.2576 ymin: 40.7711 xmax: 14.7905 ymax: 51.752\nGeodetic CRS:  WGS 84\n\n\n\n\nsfg: single geometry\n\n\nuni_sfc[[4]]"
  },
  {
    "objectID": "w9-slides.html#st_geometry-make-use-of-the-list-structure",
    "href": "w9-slides.html#st_geometry-make-use-of-the-list-structure",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "st_geometry: make use of the list structure",
    "text": "st_geometry: make use of the list structure\n\nazerbaijan_sf &lt;- cca_sf |&gt; filter(iso_a2 == 'AZ')\n\n\nazerbaijan_sf |&gt; mapview()\n\n\n\n\n\n\nazerbaijan_sf |&gt; glimpse()\n\nRows: 1\nColumns: 14\n$ geounit    &lt;chr&gt; \"Azerbaijan\"\n$ pop_est    &lt;dbl&gt; 10023318\n$ pop_rank   &lt;int&gt; 14\n$ pop_year   &lt;int&gt; 2019\n$ gdp_md     &lt;int&gt; 48047\n$ gdp_year   &lt;int&gt; 2019\n$ economy    &lt;chr&gt; \"6. Developing region\"\n$ income_grp &lt;chr&gt; \"3. Upper middle income\"\n$ iso_a2     &lt;chr&gt; \"AZ\"\n$ continent  &lt;chr&gt; \"Asia\"\n$ region_un  &lt;chr&gt; \"Asia\"\n$ subregion  &lt;chr&gt; \"Western Asia\"\n$ region_wb  &lt;chr&gt; \"Europe & Central Asia\"\n$ geometry   &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((44.81719 39...\n\n\n\n\n\nsave the sf geometry column as azerbaijan_sfc\n\n\nazerbaijan_sfc &lt;- azerbaijan_sf |&gt; st_geometry()\nazerbaijan_sfc |&gt; glimpse()\n\nsfc_MULTIPOLYGON of length 1; first list element: List of 3\n $ :List of 1\n  ..$ : num [1:41, 1:2] 44.8 44.8 44.8 44.9 45 ...\n $ :List of 2\n  ..$ : num [1:206, 1:2] 48.9 48.8 48.6 48.6 48.4 ...\n  ..$ : num [1:8, 1:2] 45.6 45.6 45.5 45.5 45.5 ...\n $ :List of 1\n  ..$ : num [1:9, 1:2] 45 45 45 45 45 ...\n - attr(*, \"class\")= chr [1:3] \"XY\" \"MULTIPOLYGON\" \"sfg\"\n\n\n\n\nazerbaijan_sfc |&gt; class() |&gt; print()\n\n[1] \"sfc_MULTIPOLYGON\" \"sfc\"             \n\nazerbaijan_sfc |&gt; typeof() |&gt; print()\n\n[1] \"list\"\n\nazerbaijan_sfc[[1]][[3]][[1]] |&gt; class()\n\n[1] \"matrix\" \"array\" \n\nazerbaijan_sfc[[1]][[3]][[1]]\n\n          [,1]     [,2]\n [1,] 45.02363 41.02725\n [2,] 45.00205 41.01582\n [3,] 44.96904 41.02725\n [4,] 44.95889 41.05264\n [5,] 44.96143 41.07925\n [6,] 44.99434 41.08560\n [7,] 45.02109 41.07798\n [8,] 45.02871 41.05386\n [9,] 45.02363 41.02725\n\n\n\n\naz_poly1 &lt;- azerbaijan_sfc[[1]][[1]] |&gt; st_polygon()\naz_poly2 &lt;- azerbaijan_sfc[[1]][[2]] |&gt; st_polygon()\naz_poly3 &lt;- azerbaijan_sfc[[1]][[3]] |&gt; st_polygon()\n\nazer_piece_sfc &lt;- list(az_poly1, az_poly2, az_poly3) |&gt;\n  st_as_sfc()\n\n\nazer_piece_df &lt;- tibble(\n    geometry = azer_piece_sfc,\n    lab = c('Nagorno-Karabakh', 'Azerbaijan Main', 'Yukhari Askipara')\n)\nazer_piece_sf &lt;- azer_piece_df |&gt; st_as_sf(crs = 4326)\n\n\nazer_piece_sf |&gt; mapview(zcol = 'lab', label = 'lab')\n\n\n\n\nazer_piece_sf\n\n\n\n\n\ngeometry\nlab\n\n\n\n\nPOLYGON ((44.81719 39.65044…\nNagorno-Karabakh\n\n\nPOLYGON ((48.86875 38.4355,…\nAzerbaijan Main\n\n\nPOLYGON ((45.02363 41.02725…\nYukhari Askipara"
  },
  {
    "objectID": "w9-slides.html#sfg-to-sfc",
    "href": "w9-slides.html#sfg-to-sfc",
    "title": "R Coding Workshop: 7th Meeting",
    "section": "sfg to sfc",
    "text": "sfg to sfc\nInner Ring\n\n\n\nazerbaijan_sfc[[1]][[2]][[2]] |&gt; class() |&gt; print()\n\n[1] \"matrix\" \"array\" \n\nazerbaijan_sfc[[1]][[2]][[2]]\n\n         [,1]     [,2]\n[1,] 45.55234 40.61606\n[2,] 45.56230 40.64917\n[3,] 45.53418 40.66401\n[4,] 45.50449 40.66484\n[5,] 45.47881 40.64834\n[6,] 45.47881 40.60698\n[7,] 45.51436 40.59956\n[8,] 45.55234 40.61606\n\n\n\n\nazerbaijan_sfc[[1]][[2]][[2]] |&gt; list() |&gt; st_polygon() |&gt; ggplot() + geom_sf() + theme_bw()\n\n\n\n\n\n\n\n\n\nOuter Ring\n\n\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; dim() |&gt; print()\n\n[1] 206   2\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; head()\n\n         [,1]     [,2]\n[1,] 48.86875 38.43550\n[2,] 48.84033 38.43726\n[3,] 48.63555 38.39873\n[4,] 48.59268 38.41108\n[5,] 48.41738 38.58623\n[6,] 48.38125 38.60562\n\n\n\n\nazerbaijan_sfc[[1]][[2]][[1]] |&gt; list() |&gt; st_polygon() |&gt; ggplot() + geom_sf() + theme_bw()\n\n\n\n\n\n\n\n\n\n\nazerbaijan_outer_ring &lt;- azerbaijan_sfc[[1]][[2]][[1]]\nazerbaijan_inner_ring &lt;- azerbaijan_sfc[[1]][[2]][[2]]\n\n\nazerbaijan_polygon &lt;- st_polygon(list(azerbaijan_outer_ring, azerbaijan_inner_ring))\n\nazerbaijan_polygon |&gt;\n    ggplot() +\n    geom_sf(fill = \"lightblue\") +\n    theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\nChambers, John M. 2016. Extending R. Milton, UNITED KINGDOM: CRC Press LLC.\n\n\nJames, Gareth. 2021. An Introduction to Statistical Learning: With Applications in R. Second edition. Springer Texts in Statistics. New York, NY: Springer.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial Data Science: With Applications in R. New York: Chapman and Hall/CRC. https://doi.org/10.1201/9780429459016."
  },
  {
    "objectID": "pp-idx.html#intro",
    "href": "pp-idx.html#intro",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Intro",
    "text": "Intro",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-idx.html#pipeline-how-we-learn-to-translate-manchu",
    "href": "pp-idx.html#pipeline-how-we-learn-to-translate-manchu",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Pipeline: How we learn (to translate) Manchu?",
    "text": "Pipeline: How we learn (to translate) Manchu?\n\n\n\nDigitization\nOCR and typing\n\n\n\nTransliteration\nTranslation",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-idx.html#literature-review",
    "href": "pp-idx.html#literature-review",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Literature Review",
    "text": "Literature Review\nOCR\n\nChoi et al., “Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu.” (2025)\n\nMachine Translation\n\nSeo et al., “Mergen: The First Manchu-Korean Machine Translation Model Trained on Augmented Data.” (2024)\nPei et al., “Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu.” (2025)",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-idx.html#data-and-methods",
    "href": "pp-idx.html#data-and-methods",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Data and Methods",
    "text": "Data and Methods\nParallel Corpora\nThe Diary of a Manchu Soldier in Seventeenth-Century China (Cosmo annotated, 2006) - size: 771 sentences - vocab siz: 961 words\nThe Dream of the Red Chamber (Cao, 1792) - source: Sibe translation (1993, Mu) - reference: English translation (1891, Joly) - size: 340 sentences, vocab size: 669 words\nModels\n\nBaseline: Translation with a Sequence to Sequence Network (LSTM) and Attention\nApply transfer learning with Pre-trained model\n\nMergen: Manchu-Korean NMT (Seo et al. 2024)",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-idx.html#results-progress-report",
    "href": "pp-idx.html#results-progress-report",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Results: Progress Report",
    "text": "Results: Progress Report\nEvaluation Metrics\n\nsentence-level BLEU\n\nBaseline: 0.0\nTransfer Learning: 42.89\n\n\nSource:     ai bithe hūlambi\nReference:  Which books are you reading\nPrediction:  what is is you\nBLEU  12.44\n\nSource:     bi sini funde buki\nReference:  I will contribute for you\nPrediction:  I I I you\nBLEU  14.79\n\nSource:     si genefi terede alaci ojorakū\nReference:  you must not tell him\nPrediction:  I you you you to to\nBLEU  8.12\n\nSource:     bi arkan seme jici suwe inu mimbe forome karame tuwarakū\nReference:  you pay no heed to me at all though I have managed to come after ever so much trouble\nPredicted:  I you you you you to to to to to\nBLEU  2.41\n\nSource:     ume jilidara\nReference:  dont be angry\nPredicted:  what you\nBLEU  0.00\n\nSource:     tere oci teni jihengge ainahai terei jalin simbe aldangga tuwara giyan binio\nReference:  how could I ever distance you on her account while she has only recently come\nPredicted:  but will will that to to to to to to to\nBLEU  0.00",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-idx.html#more-to-work-on",
    "href": "pp-idx.html#more-to-work-on",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "More to work on…",
    "text": "More to work on…\n\n\nEng-Korean MT\nNorman Manchu-English dictionary for data augmentation\nGenerative",
    "crumbs": [
      "Coding Workshop",
      "progress report"
    ]
  },
  {
    "objectID": "pp-slides.html#manchu-english-machine-translation-model",
    "href": "pp-slides.html#manchu-english-machine-translation-model",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Manchu-English Machine Translation Model",
    "text": "Manchu-English Machine Translation Model"
  },
  {
    "objectID": "pp-slides.html#intro",
    "href": "pp-slides.html#intro",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Intro",
    "text": "Intro"
  },
  {
    "objectID": "pp-slides.html#pipeline-how-we-learn-to-translate-manchu",
    "href": "pp-slides.html#pipeline-how-we-learn-to-translate-manchu",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Pipeline: How we learn (to translate) Manchu?",
    "text": "Pipeline: How we learn (to translate) Manchu?\n\n\n\nDigitization\nOCR and typing\n\n\n\nTransliteration\nTranslation"
  },
  {
    "objectID": "pp-slides.html#literature-review",
    "href": "pp-slides.html#literature-review",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Literature Review",
    "text": "Literature Review\nOCR\n\nChoi et al., “Finetuning Vision-Language Models as OCR Systems for Low-Resource Languages: A Case Study of Manchu.” (2025)\n\nMachine Translation\n\nSeo et al., “Mergen: The First Manchu-Korean Machine Translation Model Trained on Augmented Data.” (2024)\nPei et al., “Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu.” (2025)"
  },
  {
    "objectID": "pp-slides.html#data-and-methods",
    "href": "pp-slides.html#data-and-methods",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Data and Methods",
    "text": "Data and Methods\nParallel Corpora\nThe Diary of a Manchu Soldier in Seventeenth-Century China (Cosmo annotated, 2006) - size: 771 sentences - vocab siz: 961 words\nThe Dream of the Red Chamber (Cao, 1792) - source: Sibe translation (1993, Mu) - reference: English translation (1891, Joly) - size: 340 sentences, vocab size: 669 words\nModels\n\nBaseline: Translation with a Sequence to Sequence Network (LSTM) and Attention\nApply transfer learning with Pre-trained model\n\nMergen: Manchu-Korean NMT (Seo et al. 2024)"
  },
  {
    "objectID": "pp-slides.html#results-progress-report",
    "href": "pp-slides.html#results-progress-report",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "Results: Progress Report",
    "text": "Results: Progress Report\nEvaluation Metrics\n\nsentence-level BLEU\n\nBaseline: 0.0\nTransfer Learning: 42.89\n\n\nSource:     ai bithe hūlambi\nReference:  Which books are you reading\nPrediction:  what is is you\nBLEU  12.44\n\nSource:     bi sini funde buki\nReference:  I will contribute for you\nPrediction:  I I I you\nBLEU  14.79\n\nSource:     si genefi terede alaci ojorakū\nReference:  you must not tell him\nPrediction:  I you you you to to\nBLEU  8.12\n\nSource:     bi arkan seme jici suwe inu mimbe forome karame tuwarakū\nReference:  you pay no heed to me at all though I have managed to come after ever so much trouble\nPredicted:  I you you you you to to to to to\nBLEU  2.41\n\nSource:     ume jilidara\nReference:  dont be angry\nPredicted:  what you\nBLEU  0.00\n\nSource:     tere oci teni jihengge ainahai terei jalin simbe aldangga tuwara giyan binio\nReference:  how could I ever distance you on her account while she has only recently come\nPredicted:  but will will that to to to to to to to\nBLEU  0.00"
  },
  {
    "objectID": "pp-slides.html#more-to-work-on",
    "href": "pp-slides.html#more-to-work-on",
    "title": "DSAN6600 Final: Manchu Learning",
    "section": "More to work on…",
    "text": "More to work on…\n\n\nEng-Korean MT\nNorman Manchu-English dictionary for data augmentation\nGenerative"
  },
  {
    "objectID": "w13-idx.html#outline",
    "href": "w13-idx.html#outline",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Outline",
    "text": "Outline\n\nOpen Street Map\nProject checklist\nRaster Data",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#open-street-map",
    "href": "w13-idx.html#open-street-map",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Open Street Map",
    "text": "Open Street Map\n\nuse place name to search for bounding box\n\n\n?getbb\n\n\ntaipei_bb_results &lt;- getbb(place_name = 'taipei', format_out='sf_polygon')\ntaipei_bb_results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplace_id\nlicence\nosm_type\nosm_id\nlat\nlon\nclass\ntype\nplace_rank\nimportance\naddresstype\nname\ndisplay_name\ngeometry\n\n\n\n\n213710844\nData © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright\nrelation\n1293250\n25.0375198\n121.5636796\nboundary\nadministrative\n7\n0.7009468\ncity\n臺北市\n臺北市, 臺灣\nPOLYGON ((121.4571 25.10798…\n\n\n212454050\nData © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright\nrelation\n1527220\n25.0119970\n121.4656619\nboundary\nadministrative\n8\n0.6192987\ncity\n新北市\n新北市, 臺灣\nMULTIPOLYGON (((121.2826 25…\n\n\n\n\n\n\n\ntpc_bb &lt;- taipei_bb_results |&gt; filter(place_id == 213710844)\n\n\nntpc_bb &lt;- taipei_bb_results |&gt; filter(place_id == 212454050)\nntpc_bb |&gt; mapview()",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#osmdata",
    "href": "w13-idx.html#osmdata",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "osmdata",
    "text": "osmdata\n\ncreate a query\n\n\nassign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\n\n\ntpc_mosque_results &lt;- tpc_bb |&gt;\n  opq() |&gt; \n  add_osm_feature(key='building', value = 'mosque') |&gt;\n  osmdata_sf()\ntpc_mosque_results\n\nObject of class 'osmdata' with:\n                 $bbox : relation(id:1293250)\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 67 points\n            $osm_lines : NULL\n         $osm_polygons : 'sf' Simple Features Collection with 3 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : 'sf' Simple Features Collection with 1 multipolygons\n\n\n\nleaflet visualization\n\n\nleaflet() |&gt;\n  addProviderTiles('CartoDB.Positron') |&gt;\n  addPolygons(\n    data = tpc_mosque_results$osm_polygons,\n    color = \"purple\"\n  )\n\n\n\n\n\n\ntpc_mosque_polygon_sf &lt;- tpc_mosque_results$osm_polygons",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#osmdata-1",
    "href": "w13-idx.html#osmdata-1",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "osmdata",
    "text": "osmdata\n\nkentucky_bb &lt;- getbb('kentucky, USA')\nkentucky_bb\n\n        min       max\nx -89.57151 -81.96454\ny  36.49712  39.14780\n\n\n\nBounding Box\n\n\nky_results &lt;- kentucky_bb |&gt;\n  opq() |&gt;\n  add_osm_feature(key = 'boundary', value = 'administrative') |&gt;\n  add_osm_feature(key = 'admin_level', value = '4') |&gt;\n  add_osm_feature(key = 'name', value = 'Kentucky') |&gt;\n  osmdata_sf()\nky_results\n\nObject of class 'osmdata' with:\n                 $bbox : 36.497118,-89.571509,39.1477997,-81.9645413\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 10411 points\n            $osm_lines : 'sf' Simple Features Collection with 266 linestrings\n         $osm_polygons : 'sf' Simple Features Collection with 0 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : 'sf' Simple Features Collection with 1 multipolygons\n\n\n\nky_sf &lt;- ky_results$osm_multipolygons\nky_vars &lt;- c(\"osm_id\", \"name\", \"ISO3166-2\", \"admin_level\", \"border_type\", \n\"boundary\", \"nickname\", \"official_name\", \"ref\", \"ref:USCG\", \"ref:USPS\", \"ref:fips\", \n\"short_name\", \"source:short_name\", \"type\", \n\"wikidata\", \"wikipedia\", \"geometry\")\n\n\nky_sf &lt;- ky_sf |&gt; dplyr::select(all_of(ky_vars))\nky_sf |&gt; mapview()\n\n\n\n\n\n\nky_bookcase_results &lt;- kentucky_bb |&gt;\n  opq() |&gt;\n  add_osm_feature(key='amenity', value = 'public_bookcase') |&gt;\n  osmdata_sf()\nky_bookcase_results\n\nObject of class 'osmdata' with:\n                 $bbox : 36.497118,-89.571509,39.1477997,-81.9645413\n        $overpass_call : The call submitted to the overpass API\n                 $meta : metadata including timestamp and version numbers\n           $osm_points : 'sf' Simple Features Collection with 77 points\n            $osm_lines : NULL\n         $osm_polygons : 'sf' Simple Features Collection with 0 polygons\n       $osm_multilines : NULL\n    $osm_multipolygons : NULL\n\n\n\nky_bookcase_sf &lt;- ky_bookcase_results$osm_points\n\n\n# ky_convex_sf &lt;- ky_sf |&gt; st_convex_hull() |&gt; st_buffer()\n# ky_convex_sf |&gt; mapview()\nky_bbox_sf &lt;- ky_sf |&gt; st_bbox() |&gt; st_as_sfc() |&gt; st_as_sf(crs = 4326)\nky_bbox_sf |&gt; mapview()",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#tessellation",
    "href": "w13-idx.html#tessellation",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Tessellation",
    "text": "Tessellation\n\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\n\n\nAttachement du package : 'tigris'\n\n\nL'objet suivant est masqué depuis 'package:terra':\n\n    blocks\n\n\n\nuac_sf &lt;- urban_areas(year = 2020, progress_bar = FALSE)\n\n\nuac_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\nky_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nuac_sf &lt;- uac_sf |&gt; st_transform(4326)\n\n\nky_uac_sf &lt;- uac_sf[ky_sf,]\nky_urban_bookcase_sf &lt;- ky_bookcase_sf[ky_uac_sf,]\nky_urban_bookcase_sf |&gt; dim()\n\n[1] 64 24\n\n\n\nmapview(ky_sf, col.region = 'lightblue', alpha.regions = 0.6, map.types = 'CartoDB.Positron') +\n  mapview(ky_uac_sf, col.regions = 'yellow') + \n  mapview(ky_urban_bookcase_sf, cex = 4)",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#observation-window",
    "href": "w13-idx.html#observation-window",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Observation Window",
    "text": "Observation Window\n\nkybb_uac_sf &lt;- uac_sf[ky_bbox_sf,]\nkybb_uac_sf |&gt; mapview()\n\n\n\n\n\n\nky_bookcase_sf[kybb_uac_sf,] |&gt; dim()\n\n[1] 70 24",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#ppp",
    "href": "w13-idx.html#ppp",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "ppp",
    "text": "ppp\n\nky_owin &lt;- ky_bbox_sf |&gt; st_transform(3857) |&gt; as.owin()\n\nky_urban_owin &lt;- kybb_uac_sf |&gt;\n  st_simplify(dTolerance = 200) |&gt;\n  st_intersection(ky_bbox_sf) |&gt;\n  st_transform(3857) |&gt;\n  as.owin()\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n# plot(ky_urban_owin)\n\n\nky_bookcase_ppp &lt;- ky_bookcase_sf |&gt;\n  st_as_sfc() |&gt;\n  st_transform(3857) |&gt;\n  as.ppp(W = ky_owin)\nplot(ky_bookcase_ppp)",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#dividing-the-observation-window",
    "href": "w13-idx.html#dividing-the-observation-window",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Dividing the observation window",
    "text": "Dividing the observation window\n\nurban_rural_tess &lt;- tess(\n  tiles = list(\n    urban = ky_urban_owin,\n    rural = setminus.owin(ky_owin, ky_urban_owin)\n  )\n)\n\n\nurban_rural_tess |&gt; class()\n\n[1] \"tess\" \"list\"",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#simulation",
    "href": "w13-idx.html#simulation",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Simulation",
    "text": "Simulation\n\nset.seed(6805)\ngen_sim_ppp &lt;- function() {\n  prot_sim &lt;- spatstat.random::rpoint(\n    n = nrow(ky_bookcase_sf),\n    w = ky_owin\n  )\n  return(prot_sim)\n}\nsim_prot_ppp &lt;- gen_sim_ppp()\nplot(sim_prot_ppp)\n\n\n\n\n\n\n\n\n\ncompute_tile_counts &lt;- function(ppp_obj) {\n  class_list &lt;- tileindex(\n    ppp_obj,\n    Z = urban_rural_tess\n  )\n  count_tb &lt;- table(class_list)\n  count_df &lt;- tibble(\n    urban = count_tb[1],\n    rural = count_tb[2]\n  )\n\n  return(count_df)\n}\n\n\ncompute_tile_counts(sim_prot_ppp)\n\n\n\n\n\nurban\nrural\n\n\n\n\n4\n73\n\n\n\n\n\n\n\ncompute_tile_counts(ky_bookcase_ppp)\n\n\n\n\n\nurban\nrural\n\n\n\n\n68\n9",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#simulation-1",
    "href": "w13-idx.html#simulation-1",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Simulation",
    "text": "Simulation\n\nset.seed(6805)\ngen_sims_ppp &lt;- function(num_sims = 999) {\n  bkcase_sims &lt;- spatstat.random::rpoint(\n    n = nrow(ky_bookcase_sf),\n    w = ky_owin,\n    nsim = num_sims\n  )\n  return(bkcase_sims)\n}\nbkcase_sims_list &lt;- gen_sims_ppp()\n\n\n# compute_tile_counts &lt;- function(ppp_obj) {\n#   class_list &lt;- tileindex(\n#     ppp_obj,\n#     Z = urban_rural_tess\n#   )\n#   counts &lt;- class_list |&gt;\n#     table() |&gt;\n#     as.vector()\n#   names(counts) &lt;- c('urban', 'rural')\n\n#   return(counts)\n# }\n\n\nsims_tess_counts &lt;- lapply(\n  X = bkcase_sims_list,\n  FUN = compute_tile_counts\n)\nsim_df &lt;- sims_tess_counts |&gt; bind_rows()\nsim_df |&gt; slice_sample(n = 4)\n\n\n\n\n\nurban\nrural\n\n\n\n\n3\n74\n\n\n2\n75\n\n\n2\n75\n\n\n2\n75\n\n\n\n\n\n\n\nobs_df &lt;- compute_tile_counts(ky_bookcase_ppp)\nobs_df\n\n\n\n\n\nurban\nrural\n\n\n\n\n68\n9\n\n\n\n\n\n\n\nbind_df &lt;- bind_rows(sim_df, obs_df)\nbind_df |&gt; dim()\n\n[1] 1000    2\n\n\n\nbind_df |&gt;\n  ggplot(aes(x = rural)) +\n  geom_density(fill = palette4[2], alpha = 0.7) +\n  geom_vline(\n    xintercept = 9,\n    linetype = 'dashed',\n    color = palette4[5]\n  ) +\n    theme_classic()",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-idx.html#raster",
    "href": "w13-idx.html#raster",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Raster",
    "text": "Raster\n\npop_raster &lt;- raster(\n  'data/gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min.tif'\n)\npop_raster\n\nclass      : RasterLayer \ndimensions : 4320, 8640, 37324800  (nrow, ncol, ncell)\nresolution : 0.04166667, 0.04166667  (x, y)\nextent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min.tif \nnames      : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min \n\n\n\nbbox_extent &lt;- extent(-89.57151, -81.96454, 36.49712, 39.14780)\npop_raster_sub &lt;- crop(pop_raster, bbox_extent)\n\n\npop_poly &lt;- pop_raster_sub |&gt; raster::rasterToPolygons(n = 8, na.rm = TRUE)\npop_poly\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 11712 \nextent      : -89.58333, -81.95833, 36.5, 39.16667  (xmin, xmax, ymin, ymax)\ncrs         : +proj=longlat +datum=WGS84 +no_defs \nvariables   : 1\nnames       : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min \nmin values  :                                                                                 0 \nmax values  :                                                                     37111.3984375 \n\n\n\npop_sf &lt;- st_as_sf(pop_poly)\npop_sf |&gt; glimpse()\n\nRows: 11,712\nColumns: 2\n$ gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min &lt;dbl&gt; …\n$ geometry                                                                          &lt;POLYGON [°]&gt; …\n\n\n\npop_sf &lt;- pop_sf |&gt; rename(pop_count = gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min)\n\n\ngpw_map &lt;- pop_sf |&gt;\n  ggplot(aes(fill = pop_count)) +\n  geom_sf(color = scales::alpha(\"white\",0)) +\n  scale_fill_viridis_c(trans = 'pseudo_log') + \n  theme_minimal() +\n  labs(\n    title = \"Population Counts\",\n    subtitle = 'GPW V.4 2020-07-01',\n    fill = \"Population Count\"\n    ) + \n  theme(\n    plot.title = element_text(hjust=0.5),\n    plot.subtitle = element_text(hjust=0.5)\n    )\n\nggsave('image/gpw-raster.png', plot = gpw_map)\n\nSaving 7 x 5 in image\n\ngpw_map",
    "crumbs": [
      "Coding Workshop",
      "Week 13"
    ]
  },
  {
    "objectID": "w13-slides.html#r-coding-workshop-for-gis-10th-meeting",
    "href": "w13-slides.html#r-coding-workshop-for-gis-10th-meeting",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "R Coding Workshop for GIS: 10th Meeting",
    "text": "R Coding Workshop for GIS: 10th Meeting"
  },
  {
    "objectID": "w13-slides.html#outline",
    "href": "w13-slides.html#outline",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Outline",
    "text": "Outline\n\nOpen Street Map\nProject checklist\nRaster Data"
  },
  {
    "objectID": "w13-slides.html#open-street-map",
    "href": "w13-slides.html#open-street-map",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Open Street Map",
    "text": "Open Street Map\n\nuse place name to search for bounding box\n\n\n?getbb\n\n\ntaipei_bb_results &lt;- getbb(place_name = 'taipei', format_out='sf_polygon')\ntaipei_bb_results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplace_id\nlicence\nosm_type\nosm_id\nlat\nlon\nclass\ntype\nplace_rank\nimportance\naddresstype\nname\ndisplay_name\ngeometry\n\n\n\n\n213710844\nData © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright\nrelation\n1293250\n25.0375198\n121.5636796\nboundary\nadministrative\n7\n0.7009468\ncity\n臺北市\n臺北市, 臺灣\nPOLYGON ((121.4571 25.10798…\n\n\n212454050\nData © OpenStreetMap contributors, ODbL 1.0. http://osm.org/copyright\nrelation\n1527220\n25.0119970\n121.4656619\nboundary\nadministrative\n8\n0.6192987\ncity\n新北市\n新北市, 臺灣\nMULTIPOLYGON (((121.2826 25…\n\n\n\n\n\n\n\ntpc_bb &lt;- taipei_bb_results |&gt; filter(place_id == 213710844)\n\n\nntpc_bb &lt;- taipei_bb_results |&gt; filter(place_id == 212454050)\nntpc_bb |&gt; mapview()"
  },
  {
    "objectID": "w13-slides.html#osmdata",
    "href": "w13-slides.html#osmdata",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "osmdata",
    "text": "osmdata\n\ncreate a query\n\n\nassign(\"has_internet_via_proxy\", TRUE, environment(curl::has_internet))\n\n\ntpc_mosque_results &lt;- tpc_bb |&gt;\n  opq() |&gt; \n  add_osm_feature(key='building', value = 'mosque') |&gt;\n  osmdata_sf()\ntpc_mosque_results\n\n\nleaflet visualization\n\n\nleaflet() |&gt;\n  addProviderTiles('CartoDB.Positron') |&gt;\n  addPolygons(\n    data = tpc_mosque_results$osm_polygons,\n    color = \"purple\"\n  )\n\n\n\n\n\n\ntpc_mosque_polygon_sf &lt;- tpc_mosque_results$osm_polygons"
  },
  {
    "objectID": "w13-slides.html#osmdata-1",
    "href": "w13-slides.html#osmdata-1",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "osmdata",
    "text": "osmdata\n\nkentucky_bb &lt;- getbb('kentucky, USA')\nkentucky_bb\n\n        min       max\nx -89.57151 -81.96454\ny  36.49712  39.14780\n\n\n\nBounding Box\n\n\nky_results &lt;- kentucky_bb |&gt;\n  opq() |&gt;\n  add_osm_feature(key = 'boundary', value = 'administrative') |&gt;\n  add_osm_feature(key = 'admin_level', value = '4') |&gt;\n  add_osm_feature(key = 'name', value = 'Kentucky') |&gt;\n  osmdata_sf()\nky_results\n\n\nky_sf &lt;- ky_results$osm_multipolygons\nky_vars &lt;- c(\"osm_id\", \"name\", \"ISO3166-2\", \"admin_level\", \"border_type\", \n\"boundary\", \"nickname\", \"official_name\", \"ref\", \"ref:USCG\", \"ref:USPS\", \"ref:fips\", \n\"short_name\", \"source:short_name\", \"type\", \n\"wikidata\", \"wikipedia\", \"geometry\")\n\n\nky_sf &lt;- ky_sf |&gt; dplyr::select(all_of(ky_vars))\nky_sf |&gt; mapview()\n\n\n\n\n\n\nky_bookcase_results &lt;- kentucky_bb |&gt;\n  opq() |&gt;\n  add_osm_feature(key='amenity', value = 'public_bookcase') |&gt;\n  osmdata_sf()\nky_bookcase_results\n\n\nky_bookcase_sf &lt;- ky_bookcase_results$osm_points\n\n\n# ky_convex_sf &lt;- ky_sf |&gt; st_convex_hull() |&gt; st_buffer()\n# ky_convex_sf |&gt; mapview()\nky_bbox_sf &lt;- ky_sf |&gt; st_bbox() |&gt; st_as_sfc() |&gt; st_as_sf(crs = 4326)\nky_bbox_sf |&gt; mapview()"
  },
  {
    "objectID": "w13-slides.html#tessellation",
    "href": "w13-slides.html#tessellation",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Tessellation",
    "text": "Tessellation\n\nlibrary(tigris)\n\n\nuac_sf &lt;- urban_areas(year = 2020, progress_bar = FALSE)\n\n\nuac_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\nky_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\nuac_sf &lt;- uac_sf |&gt; st_transform(4326)\n\n\nky_uac_sf &lt;- uac_sf[ky_sf,]\nky_urban_bookcase_sf &lt;- ky_bookcase_sf[ky_uac_sf,]\nky_urban_bookcase_sf |&gt; dim()\n\n[1] 64 24\n\n\n\nmapview(ky_sf, col.region = 'lightblue', alpha.regions = 0.6, map.types = 'CartoDB.Positron') +\n  mapview(ky_uac_sf, col.regions = 'yellow') + \n  mapview(ky_urban_bookcase_sf, cex = 4)"
  },
  {
    "objectID": "w13-slides.html#observation-window",
    "href": "w13-slides.html#observation-window",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Observation Window",
    "text": "Observation Window\n\nkybb_uac_sf &lt;- uac_sf[ky_bbox_sf,]\nkybb_uac_sf |&gt; mapview()\n\n\n\n\n\n\nky_bookcase_sf[kybb_uac_sf,] |&gt; dim()\n\n[1] 70 24"
  },
  {
    "objectID": "w13-slides.html#ppp",
    "href": "w13-slides.html#ppp",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "ppp",
    "text": "ppp\n\nky_owin &lt;- ky_bbox_sf |&gt; st_transform(3857) |&gt; as.owin()\n\nky_urban_owin &lt;- kybb_uac_sf |&gt;\n  st_simplify(dTolerance = 200) |&gt;\n  st_intersection(ky_bbox_sf) |&gt;\n  st_transform(3857) |&gt;\n  as.owin()\n# plot(ky_urban_owin)\n\n\nky_bookcase_ppp &lt;- ky_bookcase_sf |&gt;\n  st_as_sfc() |&gt;\n  st_transform(3857) |&gt;\n  as.ppp(W = ky_owin)\nplot(ky_bookcase_ppp)"
  },
  {
    "objectID": "w13-slides.html#dividing-the-observation-window",
    "href": "w13-slides.html#dividing-the-observation-window",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Dividing the observation window",
    "text": "Dividing the observation window\n\nurban_rural_tess &lt;- tess(\n  tiles = list(\n    urban = ky_urban_owin,\n    rural = setminus.owin(ky_owin, ky_urban_owin)\n  )\n)\n\n\nurban_rural_tess |&gt; class()\n\n[1] \"tess\" \"list\""
  },
  {
    "objectID": "w13-slides.html#simulation",
    "href": "w13-slides.html#simulation",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Simulation",
    "text": "Simulation\n\nset.seed(6805)\ngen_sim_ppp &lt;- function() {\n  prot_sim &lt;- spatstat.random::rpoint(\n    n = nrow(ky_bookcase_sf),\n    w = ky_owin\n  )\n  return(prot_sim)\n}\nsim_prot_ppp &lt;- gen_sim_ppp()\nplot(sim_prot_ppp)\n\n\n\ncompute_tile_counts &lt;- function(ppp_obj) {\n  class_list &lt;- tileindex(\n    ppp_obj,\n    Z = urban_rural_tess\n  )\n  count_tb &lt;- table(class_list)\n  count_df &lt;- tibble(\n    urban = count_tb[1],\n    rural = count_tb[2]\n  )\n\n  return(count_df)\n}\n\n\ncompute_tile_counts(sim_prot_ppp)\n\n\n\n\n\nurban\nrural\n\n\n\n\n4\n73\n\n\n\n\n\n\n\ncompute_tile_counts(ky_bookcase_ppp)\n\n\n\n\n\nurban\nrural\n\n\n\n\n68\n9"
  },
  {
    "objectID": "w13-slides.html#simulation-1",
    "href": "w13-slides.html#simulation-1",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Simulation",
    "text": "Simulation\n\nset.seed(6805)\ngen_sims_ppp &lt;- function(num_sims = 999) {\n  bkcase_sims &lt;- spatstat.random::rpoint(\n    n = nrow(ky_bookcase_sf),\n    w = ky_owin,\n    nsim = num_sims\n  )\n  return(bkcase_sims)\n}\nbkcase_sims_list &lt;- gen_sims_ppp()\n\n\n# compute_tile_counts &lt;- function(ppp_obj) {\n#   class_list &lt;- tileindex(\n#     ppp_obj,\n#     Z = urban_rural_tess\n#   )\n#   counts &lt;- class_list |&gt;\n#     table() |&gt;\n#     as.vector()\n#   names(counts) &lt;- c('urban', 'rural')\n\n#   return(counts)\n# }\n\n\nsims_tess_counts &lt;- lapply(\n  X = bkcase_sims_list,\n  FUN = compute_tile_counts\n)\nsim_df &lt;- sims_tess_counts |&gt; bind_rows()\nsim_df |&gt; slice_sample(n = 4)\n\n\n\n\n\nurban\nrural\n\n\n\n\n3\n74\n\n\n2\n75\n\n\n2\n75\n\n\n2\n75\n\n\n\n\n\n\n\nobs_df &lt;- compute_tile_counts(ky_bookcase_ppp)\nobs_df\n\n\n\n\n\nurban\nrural\n\n\n\n\n68\n9\n\n\n\n\n\n\n\nbind_df &lt;- bind_rows(sim_df, obs_df)\nbind_df |&gt; dim()\n\n[1] 1000    2\n\n\n\nbind_df |&gt;\n  ggplot(aes(x = rural)) +\n  geom_density(fill = palette4[2], alpha = 0.7) +\n  geom_vline(\n    xintercept = 9,\n    linetype = 'dashed',\n    color = palette4[5]\n  ) +\n    theme_classic()"
  },
  {
    "objectID": "w13-slides.html#raster",
    "href": "w13-slides.html#raster",
    "title": "R Coding Workshop: 10th Meeting",
    "section": "Raster",
    "text": "Raster\n\npop_raster &lt;- raster(\n  'data/gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min.tif'\n)\npop_raster\n\nclass      : RasterLayer \ndimensions : 4320, 8640, 37324800  (nrow, ncol, ncell)\nresolution : 0.04166667, 0.04166667  (x, y)\nextent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min.tif \nnames      : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min \n\n\n\nbbox_extent &lt;- extent(-89.57151, -81.96454, 36.49712, 39.14780)\npop_raster_sub &lt;- crop(pop_raster, bbox_extent)\n\n\npop_poly &lt;- pop_raster_sub |&gt; raster::rasterToPolygons(n = 8, na.rm = TRUE)\npop_poly\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 11712 \nextent      : -89.58333, -81.95833, 36.5, 39.16667  (xmin, xmax, ymin, ymax)\ncrs         : +proj=longlat +datum=WGS84 +no_defs \nvariables   : 1\nnames       : gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min \nmin values  :                                                                                 0 \nmax values  :                                                                     37111.3984375 \n\n\n\npop_sf &lt;- st_as_sf(pop_poly)\npop_sf |&gt; glimpse()\n\nRows: 11,712\nColumns: 2\n$ gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min &lt;dbl&gt; …\n$ geometry                                                                          &lt;POLYGON [°]&gt; …\n\n\n\npop_sf &lt;- pop_sf |&gt; rename(pop_count = gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_2pt5_min)\n\n\ngpw_map &lt;- pop_sf |&gt;\n  ggplot(aes(fill = pop_count)) +\n  geom_sf(color = scales::alpha(\"white\",0)) +\n  scale_fill_viridis_c(trans = 'pseudo_log') + \n  theme_minimal() +\n  labs(\n    title = \"Population Counts\",\n    subtitle = 'GPW V.4 2020-07-01',\n    fill = \"Population Count\"\n    ) + \n  theme(\n    plot.title = element_text(hjust=0.5),\n    plot.subtitle = element_text(hjust=0.5)\n    )\n\nggsave('image/gpw-raster.png', plot = gpw_map)\n\ngpw_map"
  },
  {
    "objectID": "w12-slides.html#gis-coding-workshop-9th-meeting",
    "href": "w12-slides.html#gis-coding-workshop-9th-meeting",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "GIS Coding Workshop: 9th Meeting",
    "text": "GIS Coding Workshop: 9th Meeting"
  },
  {
    "objectID": "w12-slides.html#outline",
    "href": "w12-slides.html#outline",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Outline",
    "text": "Outline\n\nData Import\nggplot"
  },
  {
    "objectID": "w12-slides.html#data-import",
    "href": "w12-slides.html#data-import",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Data Import",
    "text": "Data Import\ndownload.file() download files from an url\n\ngrandison_url &lt;- \"https://www.gutenberg.org/cache/epub/13884/pg13884.txt\"\n\ndownload.file(url = grandison_url, destfile = 'grandison.txt', quiet = TRUE)\n\n\ngrandison_text &lt;- readLines('grandison.txt')\ngrandison_text |&gt; head()\n\n[1] \"The Project Gutenberg eBook of The History of Sir Charles Grandison, Volume 4 (of 7)\"\n[2] \"    \"                                                                                \n[3] \"This ebook is for the use of anyone anywhere in the United States and\"               \n[4] \"most other parts of the world at no cost and with almost no restrictions\"            \n[5] \"whatsoever. You may copy it, give it away or re-use it under the terms\"              \n[6] \"of the Project Gutenberg License included with this ebook or online\""
  },
  {
    "objectID": "w12-slides.html#components-of-ggplot",
    "href": "w12-slides.html#components-of-ggplot",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Components of ggplot",
    "text": "Components of ggplot\n\n\nWe can define an ggplot object by specifying:\n\ndata\naesthetic mapping\ngeometry layer\n\n\nPatterns - use + to introduce more layers or components\n\nbk_df &lt;- read_csv('data/us-main-books.csv')\nbk_df |&gt; glimpse()\n\nRows: 48\nColumns: 25\n$ state                 &lt;chr&gt; \"WY\", \"PA\", \"OH\", \"NM\", \"MD\", \"RI\", \"OR\", \"WI\", …\n$ division_code         &lt;dbl&gt; 8, 2, 3, 8, 5, 1, 9, 3, 4, 8, 5, 2, 7, 4, 4, 8, …\n$ division_str          &lt;chr&gt; \"Mountain\", \"Middle Atlantic\", \"East North Centr…\n$ political_value_index &lt;dbl&gt; -19.7, 2.0, -0.7, 2.4, 8.5, 11.2, 4.0, 2.4, -10.…\n$ median_income         &lt;dbl&gt; 4081.5, 4218.0, 2469.0, -2401.5, 19404.5, 8141.0…\n$ hs_grad_rate          &lt;dbl&gt; 8.3380421, 2.3380421, 3.4380421, -0.6619579, 4.2…\n$ college_grad_rate     &lt;dbl&gt; -2.1237299, -1.6237299, -2.9237299, -0.5237299, …\n$ challenge_count       &lt;dbl&gt; 4, 148, 29, 3, 5, 3, 118, 10, 6, 0, 13, 25, 5, 1…\n$ explicit_count        &lt;dbl&gt; 1, 15, 13, 1, 2, 3, 26, 5, 2, 0, 4, 7, 1, 6, 1, …\n$ antifamily_count      &lt;dbl&gt; 0, 2, 5, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ occult_count          &lt;dbl&gt; 0, 3, 2, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 0, 0, …\n$ language_count        &lt;dbl&gt; 0, 16, 14, 1, 3, 2, 14, 3, 2, 0, 7, 9, 3, 5, 1, …\n$ lgbtq_count           &lt;dbl&gt; 1, 5, 1, 0, 2, 0, 10, 1, 0, 0, 3, 3, 0, 0, 0, 0,…\n$ violent_count         &lt;dbl&gt; 1, 6, 2, 0, 2, 0, 19, 2, 1, 0, 3, 3, 1, 3, 1, 0,…\n$ removed_count         &lt;dbl&gt; 1, 11, 10, 2, 0, 1, 5, 3, 2, 0, 4, 11, 0, 10, 0,…\n$ removed_pct           &lt;dbl&gt; 25.000000, 7.432432, 34.482759, 66.666667, 0.000…\n$ POPU_LSA              &lt;dbl&gt; 544270, 12054201, 11551941, 1588981, 5633514, 14…\n$ POPU_ST               &lt;dbl&gt; 544270, 12284183, 11551941, 2009671, 5618344, 10…\n$ CENTLIB               &lt;dbl&gt; 23, 451, 240, 91, 15, 47, 122, 378, 80, 19, 61, …\n$ BRANLIB               &lt;dbl&gt; 53, 183, 480, 27, 169, 26, 94, 82, 10, 67, 331, …\n$ BKMOB                 &lt;dbl&gt; 2, 29, 58, 1, 18, 2, 8, 6, 12, 4, 17, 6, 1, 4, 7…\n$ BKVOL                 &lt;dbl&gt; 2497545, 27790282, 45224425, 4518130, 13954140, …\n$ LIBRARIA              &lt;dbl&gt; 189.16, 1445.81, 2725.65, 290.37, 1297.29, 232.1…\n$ VISITS                &lt;dbl&gt; 3872783, 47188171, 88255852, 8324986, 33662473, …\n$ REGBOR                &lt;dbl&gt; 383126, 5549200, 8767349, 1140637, 3271760, 5747…\n\n\n\nbkmob_plot &lt;- bk_df |&gt;\n    ggplot(aes(x = BKMOB)) +\n    geom_histogram()\n\n\nbkmob_plot |&gt; class()\n\n[1] \"gg\"     \"ggplot\""
  },
  {
    "objectID": "w12-slides.html#data",
    "href": "w12-slides.html#data",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Data",
    "text": "Data\n\ntigris_vars &lt;- c(\"STUSPS10\", \"NAME10\", \"ALAND10\", \"AWATER10\", \"INTPTLAT10\", \"INTPTLON10\")\nmain_states &lt;- bk_df |&gt; pull(state)\nlibrary(tigris)\nstate_sf &lt;- states(year = 2010, progress_bar = FALSE) |&gt; \n    select(any_of(tigris_vars)) |&gt;\n    filter(STUSPS10 %in% main_states)\n\nstate_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\n\n\nbk_sf &lt;- state_sf |&gt;\n    left_join(bk_df, join_by(STUSPS10 == state))\nbk_sf |&gt; slice_sample(n = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\ndivision_code\ndivision_str\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\nchallenge_count\nexplicit_count\nantifamily_count\noccult_count\nlanguage_count\nlgbtq_count\nviolent_count\nremoved_count\nremoved_pct\nPOPU_LSA\nPOPU_ST\nCENTLIB\nBRANLIB\nBKMOB\nBKVOL\nLIBRARIA\nVISITS\nREGBOR\ngeometry\n\n\n\n\nNY\nNew York\n122056806947\n19239924100\n+42.9133974\n-075.5962723\n2\nMiddle Atlantic\n10.2\n5007.5\n-0.4619579\n3.37627\n25\n7\n2\n1\n9\n3\n3\n11\n44.00000\n19121677\n18976664\n755\n311\n6\n73077567\n4062.49\n117795146\n10589289\nMULTIPOLYGON (((-74.0394 40…\n\n\nIL\nIllinois\n143793362385\n6202038080\n+40.1028754\n-089.1526108\n3\nEast North Central\n7.7\n6489.5\n1.8380421\n2.07627\n39\n16\n2\n0\n9\n4\n6\n12\n30.76923\n11802452\n12830632\n634\n161\n23\n45333092\n3113.71\n83072172\n5348139\nMULTIPOLYGON (((-90.45081 3…"
  },
  {
    "objectID": "w12-slides.html#aesthetic-mapping",
    "href": "w12-slides.html#aesthetic-mapping",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Aesthetic Mapping",
    "text": "Aesthetic Mapping\nCommon aesthetic attributes\n\nPosition (x, y)\nColor (or, fill)\nOther visual features: size and shape (size, shape, linewidth)\n\n\nbk_sf |&gt;\n    ggplot(\n        aes(\n            x = CENTLIB,\n            y = BKMOB,\n            color = division_str,\n            label = STUSPS10\n        )\n    ) +\n    geom_label(size = 2) +\n    labs(\n        x = 'Central Library Count',\n        y = 'Bookmobile Count'\n    )\n\n\n\n\n\n\n\n\nTip\n\n\nlabs(): to customize plot labels"
  },
  {
    "objectID": "w12-slides.html#save-your-plot",
    "href": "w12-slides.html#save-your-plot",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Save your plot",
    "text": "Save your plot\n\nplot1 &lt;- bk_sf |&gt;\n    ggplot(\n        aes(\n            x = CENTLIB,\n            y = BKMOB,\n            color = division_str,\n            label = STUSPS10\n        )\n    ) +\n    geom_label(size = 3.5) +\n    labs(\n        x = 'Central Library Count',\n        y = 'Bookmobile Count'\n    )\n\n\nggsave(\n    filename = 'lib-bkmob-scatterplot.png',\n    plot = plot1,\n    width = 20,\n    height = 10,\n    dpi = 300\n)"
  },
  {
    "objectID": "w12-slides.html#geom_sf",
    "href": "w12-slides.html#geom_sf",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "geom_sf",
    "text": "geom_sf\n\nbk_sf |&gt; mapview(zcol = 'BKMOB')\n\n\n\n\n\n\nbk_sf |&gt;\n    ggplot() +\n    geom_sf(aes(fill = (BKMOB / POPU_LSA))) +\n    geom_sf_label(aes(label = STUSPS10), size = 1.5, fill = \"white\", alpha = 0.7, color = \"black\") +\n    theme_classic() +\n    scale_fill_viridis() +\n    labs(\n        x = 'Longitude',\n        y = 'Latitude',\n        fill = \"Number of Bookmobiles per Capita\"\n    )"
  },
  {
    "objectID": "w12-idx.html#outline",
    "href": "w12-idx.html#outline",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Outline",
    "text": "Outline\n\nData Import\nggplot",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#data-import",
    "href": "w12-idx.html#data-import",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Data Import",
    "text": "Data Import\ndownload.file() download files from an url\n\ngrandison_url &lt;- \"https://www.gutenberg.org/cache/epub/13884/pg13884.txt\"\n\ndownload.file(url = grandison_url, destfile = 'grandison.txt', quiet = TRUE)\n\n\ngrandison_text &lt;- readLines('grandison.txt')\ngrandison_text |&gt; head()\n\n[1] \"The Project Gutenberg eBook of The History of Sir Charles Grandison, Volume 4 (of 7)\"\n[2] \"    \"                                                                                \n[3] \"This ebook is for the use of anyone anywhere in the United States and\"               \n[4] \"most other parts of the world at no cost and with almost no restrictions\"            \n[5] \"whatsoever. You may copy it, give it away or re-use it under the terms\"              \n[6] \"of the Project Gutenberg License included with this ebook or online\"",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#components-of-ggplot",
    "href": "w12-idx.html#components-of-ggplot",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Components of ggplot",
    "text": "Components of ggplot\n\n\nWe can define an ggplot object by specifying:\n\ndata\naesthetic mapping\ngeometry layer\n\n\nPatterns - use + to introduce more layers or components\n\nbk_df &lt;- read_csv('data/us-main-books.csv')\n\nRows: 48 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): state, division_str\ndbl (23): division_code, political_value_index, median_income, hs_grad_rate,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbk_df |&gt; glimpse()\n\nRows: 48\nColumns: 25\n$ state                 &lt;chr&gt; \"WY\", \"PA\", \"OH\", \"NM\", \"MD\", \"RI\", \"OR\", \"WI\", …\n$ division_code         &lt;dbl&gt; 8, 2, 3, 8, 5, 1, 9, 3, 4, 8, 5, 2, 7, 4, 4, 8, …\n$ division_str          &lt;chr&gt; \"Mountain\", \"Middle Atlantic\", \"East North Centr…\n$ political_value_index &lt;dbl&gt; -19.7, 2.0, -0.7, 2.4, 8.5, 11.2, 4.0, 2.4, -10.…\n$ median_income         &lt;dbl&gt; 4081.5, 4218.0, 2469.0, -2401.5, 19404.5, 8141.0…\n$ hs_grad_rate          &lt;dbl&gt; 8.3380421, 2.3380421, 3.4380421, -0.6619579, 4.2…\n$ college_grad_rate     &lt;dbl&gt; -2.1237299, -1.6237299, -2.9237299, -0.5237299, …\n$ challenge_count       &lt;dbl&gt; 4, 148, 29, 3, 5, 3, 118, 10, 6, 0, 13, 25, 5, 1…\n$ explicit_count        &lt;dbl&gt; 1, 15, 13, 1, 2, 3, 26, 5, 2, 0, 4, 7, 1, 6, 1, …\n$ antifamily_count      &lt;dbl&gt; 0, 2, 5, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, …\n$ occult_count          &lt;dbl&gt; 0, 3, 2, 0, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 0, 0, …\n$ language_count        &lt;dbl&gt; 0, 16, 14, 1, 3, 2, 14, 3, 2, 0, 7, 9, 3, 5, 1, …\n$ lgbtq_count           &lt;dbl&gt; 1, 5, 1, 0, 2, 0, 10, 1, 0, 0, 3, 3, 0, 0, 0, 0,…\n$ violent_count         &lt;dbl&gt; 1, 6, 2, 0, 2, 0, 19, 2, 1, 0, 3, 3, 1, 3, 1, 0,…\n$ removed_count         &lt;dbl&gt; 1, 11, 10, 2, 0, 1, 5, 3, 2, 0, 4, 11, 0, 10, 0,…\n$ removed_pct           &lt;dbl&gt; 25.000000, 7.432432, 34.482759, 66.666667, 0.000…\n$ POPU_LSA              &lt;dbl&gt; 544270, 12054201, 11551941, 1588981, 5633514, 14…\n$ POPU_ST               &lt;dbl&gt; 544270, 12284183, 11551941, 2009671, 5618344, 10…\n$ CENTLIB               &lt;dbl&gt; 23, 451, 240, 91, 15, 47, 122, 378, 80, 19, 61, …\n$ BRANLIB               &lt;dbl&gt; 53, 183, 480, 27, 169, 26, 94, 82, 10, 67, 331, …\n$ BKMOB                 &lt;dbl&gt; 2, 29, 58, 1, 18, 2, 8, 6, 12, 4, 17, 6, 1, 4, 7…\n$ BKVOL                 &lt;dbl&gt; 2497545, 27790282, 45224425, 4518130, 13954140, …\n$ LIBRARIA              &lt;dbl&gt; 189.16, 1445.81, 2725.65, 290.37, 1297.29, 232.1…\n$ VISITS                &lt;dbl&gt; 3872783, 47188171, 88255852, 8324986, 33662473, …\n$ REGBOR                &lt;dbl&gt; 383126, 5549200, 8767349, 1140637, 3271760, 5747…\n\n\n\nbkmob_plot &lt;- bk_df |&gt;\n    ggplot(aes(x = BKMOB)) +\n    geom_histogram()\n\n\nbkmob_plot |&gt; class()\n\n[1] \"gg\"     \"ggplot\"",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#data",
    "href": "w12-idx.html#data",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Data",
    "text": "Data\n\ntigris_vars &lt;- c(\"STUSPS10\", \"NAME10\", \"ALAND10\", \"AWATER10\", \"INTPTLAT10\", \"INTPTLON10\")\nmain_states &lt;- bk_df |&gt; pull(state)\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\n\n\nAttachement du package : 'tigris'\n\n\nL'objet suivant est masqué depuis 'package:terra':\n\n    blocks\n\nstate_sf &lt;- states(year = 2010, progress_bar = FALSE) |&gt; \n    select(any_of(tigris_vars)) |&gt;\n    filter(STUSPS10 %in% main_states)\n\nstate_sf |&gt; st_crs() |&gt; print()\n\nCoordinate Reference System:\n  User input: NAD83 \n  wkt:\nGEOGCRS[\"NAD83\",\n    DATUM[\"North American Datum 1983\",\n        ELLIPSOID[\"GRS 1980\",6378137,298.257222101,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4269]]\n\n\n\nbk_sf &lt;- state_sf |&gt;\n    left_join(bk_df, join_by(STUSPS10 == state))\nbk_sf |&gt; slice_sample(n = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTUSPS10\nNAME10\nALAND10\nAWATER10\nINTPTLAT10\nINTPTLON10\ndivision_code\ndivision_str\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\nchallenge_count\nexplicit_count\nantifamily_count\noccult_count\nlanguage_count\nlgbtq_count\nviolent_count\nremoved_count\nremoved_pct\nPOPU_LSA\nPOPU_ST\nCENTLIB\nBRANLIB\nBKMOB\nBKVOL\nLIBRARIA\nVISITS\nREGBOR\ngeometry\n\n\n\n\nOR\nOregon\n248607802255\n6191433228\n+43.9715225\n-120.6226269\n9\nPacific\n4.0\n1274.5\n5.538042\n1.07627\n118\n26\n1\n3\n14\n10\n19\n5\n4.237288\n3657597\n3823465\n122\n94\n8\n10052777\n503.41\n25034546\n1938999\nMULTIPOLYGON (((-124.5523 4…\n\n\nMI\nMichigan\n146435075220\n104051765840\n+44.8410835\n-085.6593197\n3\nEast North Central\n3.8\n2966.0\n3.838042\n-2.22373\n36\n11\n2\n7\n8\n3\n5\n7\n19.444444\n9935266\n9952969\n380\n274\n11\n35339085\n1905.85\n59474967\n5257023\nMULTIPOLYGON (((-87.08834 4…",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#aesthetic-mapping",
    "href": "w12-idx.html#aesthetic-mapping",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Aesthetic Mapping",
    "text": "Aesthetic Mapping\nCommon aesthetic attributes\n\nPosition (x, y)\nColor (or, fill)\nOther visual features: size and shape (size, shape, linewidth)\n\n\nbk_sf |&gt;\n    ggplot(\n        aes(\n            x = CENTLIB,\n            y = BKMOB,\n            color = division_str,\n            label = STUSPS10\n        )\n    ) +\n    geom_label(size = 2) +\n    labs(\n        x = 'Central Library Count',\n        y = 'Bookmobile Count'\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nlabs(): to customize plot labels",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#save-your-plot",
    "href": "w12-idx.html#save-your-plot",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "Save your plot",
    "text": "Save your plot\n\nplot1 &lt;- bk_sf |&gt;\n    ggplot(\n        aes(\n            x = CENTLIB,\n            y = BKMOB,\n            color = division_str,\n            label = STUSPS10\n        )\n    ) +\n    geom_label(size = 3.5) +\n    labs(\n        x = 'Central Library Count',\n        y = 'Bookmobile Count'\n    )\n\n\nggsave(\n    filename = 'lib-bkmob-scatterplot.png',\n    plot = plot1,\n    width = 20,\n    height = 10,\n    dpi = 300\n)",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w12-idx.html#geom_sf",
    "href": "w12-idx.html#geom_sf",
    "title": "R Coding Workshop: 9th Meeting",
    "section": "geom_sf",
    "text": "geom_sf\n\nbk_sf |&gt; mapview(zcol = 'BKMOB')\n\n\n\n\n\n\nbk_sf |&gt;\n    ggplot() +\n    geom_sf(aes(fill = (BKMOB / POPU_LSA))) +\n    geom_sf_label(aes(label = STUSPS10), size = 1.5, fill = \"white\", alpha = 0.7, color = \"black\") +\n    theme_classic() +\n    scale_fill_viridis() +\n    labs(\n        x = 'Longitude',\n        y = 'Latitude',\n        fill = \"Number of Bookmobiles per Capita\"\n    )\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data",
    "crumbs": [
      "Coding Workshop",
      "Week 12"
    ]
  },
  {
    "objectID": "w10-slides.html#r-coding-workshop-for-gis-7th-meeting",
    "href": "w10-slides.html#r-coding-workshop-for-gis-7th-meeting",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "R Coding Workshop for GIS: 7th Meeting",
    "text": "R Coding Workshop for GIS: 7th Meeting"
  },
  {
    "objectID": "w10-slides.html#outline",
    "href": "w10-slides.html#outline",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Outline",
    "text": "Outline\n\nOrganize and save analysis results\nggplot"
  },
  {
    "objectID": "w10-slides.html#initialize-a-ggplot-object",
    "href": "w10-slides.html#initialize-a-ggplot-object",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Initialize a ggplot object",
    "text": "Initialize a ggplot object\nTo create a ggplot object, we need…\n\n\nComponents:\n\ndata\nmapping\ngeometry layer\n\n\nSteps:\n\nPrepare your data (often in the structure of a dataframe object)\nThink about the variable(s) that you’re interested in and what type of geometry (marks: point/line/polygon) might best help you understand their distribution or relationship.\nSpecify them using the grammar of graphics –map the variables to corresponding aesthetic or spatial properties of the geometry (color/size/position x, y)"
  },
  {
    "objectID": "w10-slides.html#ggplot-data-being-the-first-argument",
    "href": "w10-slides.html#ggplot-data-being-the-first-argument",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot(): data being the first argument",
    "text": "ggplot(): data being the first argument\n\nbook_df &lt;- read_csv('data/book-df-us-main.csv')\nbook_df |&gt; glimpse()\n\nRows: 47\nColumns: 25\n$ state                 &lt;chr&gt; \"WY\", \"PA\", \"OH\", \"NM\", \"MD\", \"RI\", \"OR\", \"WI\", …\n$ division_code         &lt;dbl&gt; 8, 2, 3, 8, 5, 1, 9, 3, 4, 8, 5, 2, 7, 4, 4, 8, …\n$ division_str          &lt;chr&gt; \"Mountain\", \"Middle Atlantic\", \"East North Centr…\n$ political_value_index &lt;dbl&gt; -19.7, 2.0, -0.7, 2.4, 8.5, 11.2, 4.0, 2.4, -10.…\n$ median_income         &lt;dbl&gt; 4081.5, 4218.0, 2469.0, -2401.5, 19404.5, 8141.0…\n$ hs_grad_rate          &lt;dbl&gt; 8.3380421, 2.3380421, 3.4380421, -0.6619579, 4.2…\n$ college_grad_rate     &lt;dbl&gt; -2.1237299, -1.6237299, -2.9237299, -0.5237299, …\n$ challenge_count       &lt;dbl&gt; 4, 148, 29, 3, 5, 3, 118, 10, 6, NA, 13, 25, 5, …\n$ explicit_count        &lt;dbl&gt; 1, 15, 13, 1, 2, 3, 26, 5, 2, NA, 4, 7, 1, 6, 1,…\n$ antifamily_count      &lt;dbl&gt; 0, 2, 5, 0, 1, 0, 1, 0, 0, NA, 1, 2, 0, 0, 0, 0,…\n$ occult_count          &lt;dbl&gt; 0, 3, 2, 0, 0, 0, 3, 1, 0, NA, 0, 1, 1, 1, 0, 0,…\n$ language_count        &lt;dbl&gt; 0, 16, 14, 1, 3, 2, 14, 3, 2, NA, 7, 9, 3, 5, 1,…\n$ lgbtq_count           &lt;dbl&gt; 1, 5, 1, 0, 2, 0, 10, 1, 0, NA, 3, 3, 0, 0, 0, 0…\n$ violent_count         &lt;dbl&gt; 1, 6, 2, 0, 2, 0, 19, 2, 1, NA, 3, 3, 1, 3, 1, 0…\n$ removed_count         &lt;dbl&gt; 1, 11, 10, 2, 0, 1, 5, 3, 2, NA, 4, 11, 0, 10, 0…\n$ removed_pct           &lt;dbl&gt; 25.000000, 7.432432, 34.482759, 66.666667, 0.000…\n$ POPU_LSA              &lt;dbl&gt; 544270, 12054201, 11551941, 1588981, 5633514, 14…\n$ POPU_ST               &lt;dbl&gt; 544270, 12284183, 11551941, 2009671, 5618344, 10…\n$ CENTLIB               &lt;dbl&gt; 23, 451, 240, 91, 15, 47, 122, 378, 80, 19, 61, …\n$ BRANLIB               &lt;dbl&gt; 53, 183, 480, 27, 169, 26, 94, 82, 10, 67, 331, …\n$ BKMOB                 &lt;dbl&gt; 2, 29, 58, 1, 18, 2, 8, 6, 12, 4, 17, 6, 1, 4, 7…\n$ BKVOL                 &lt;dbl&gt; 2497545, 27790282, 45224425, 4518130, 13954140, …\n$ LIBRARIA              &lt;dbl&gt; 189.16, 1445.81, 2725.65, 290.37, 1297.29, 232.1…\n$ VISITS                &lt;dbl&gt; 3872783, 47188171, 88255852, 8324986, 33662473, …\n$ REGBOR                &lt;dbl&gt; 383126, 5549200, 8767349, 1140637, 3271760, 5747…\n\n\nPlotting the distribution of a single variable\n\nview()\n\n\n# book_df |&gt; view()\n\n\n\nlayer geom_histogram(): for a numeric variable\n\n\nbook_df |&gt;\n  ggplot(mapping = aes(VISITS)) +\n  geom_histogram() +\n  scale_x_continuous(labels = comma)\n\n\n\n\n\n\n\n\n\nlayer geom_bar(): for a categorical variable\n\n\nbook_df |&gt;\n    ggplot(aes(x = division_str)) +\n    geom_bar() +\n    guides(x = guide_axis(angle = 60))"
  },
  {
    "objectID": "w10-slides.html#distribution",
    "href": "w10-slides.html#distribution",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Distribution",
    "text": "Distribution\ngeom_boxplot()\ndecompose the elements of ggplot specification\n\nmap variable name to aes attribute\nadd geometry layer with + sign\nextra: change the theme layer to classic\n\n\nbook_df |&gt;\n  ggplot(mapping = aes(y = BKMOB)) +\n  geom_boxplot() +\n  theme_classic()"
  },
  {
    "objectID": "w10-slides.html#association",
    "href": "w10-slides.html#association",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Association",
    "text": "Association\n\ngeom_point(), geom_text(), geom_label(): two variable, using points to mark position\n\n\nbk_df &lt;- read_csv('data/bkdf-us-main.csv')\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_text(size = 2)\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_label(size = 2)\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_point(size = 2) +\n    geom_smooth(method = 'lm')"
  },
  {
    "objectID": "w10-slides.html#comparison",
    "href": "w10-slides.html#comparison",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Comparison",
    "text": "Comparison\n\nAdd a z variable: color, size, facet_wrap()\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, color = division_str)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, color = division_str)) +\n    geom_point() +\n    facet_wrap(~division_str) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n  filter(division_str == 'Mountain') |&gt;\n  ggplot(aes(x = CENTLIB, y = challenge_count, color = state)) +\n  geom_point()"
  },
  {
    "objectID": "w10-slides.html#ggplot-for-sf",
    "href": "w10-slides.html#ggplot-for-sf",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot for sf",
    "text": "ggplot for sf\n\ngeom_sf()\n\n\nlibrary(tigris)\nstates_sf &lt;- states(year = 2010, progress_bar = FALSE)\n# states_sf\n\n\nstates_sf |&gt;\n  ggplot() +\n  geom_sf(aes(fill = DIVISION10))"
  },
  {
    "objectID": "w10-slides.html#ggplot-for-cda",
    "href": "w10-slides.html#ggplot-for-cda",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot for CDA",
    "text": "ggplot for CDA\n\nlibrary(HistData)\ndata(Nightingale)\n\n\nnightingale_df &lt;- Nightingale |&gt; as_tibble()\n\n\nnightingale_df |&gt;\n    ggplot() +\n    geom_line(aes(x = Date, y = Disease), color = 'deepskyblue') +\n    geom_line(aes(x = Date, y = Wounds), color = 'orange') + \n    geom_line(aes(x = Date, y = Other), color = 'green') +\n    scale_x_date(date_breaks = 'month', date_labels = '%Y %b') +\n    guides(x = guide_axis(angle = 60)) +\n    geom_vline(xintercept = ymd('1855-03-01'), colour = \"red\") +\n    labs(y = 'Count') +\n    theme_classic()"
  },
  {
    "objectID": "w10-slides.html#public-library-survey-2010-book-mobiles",
    "href": "w10-slides.html#public-library-survey-2010-book-mobiles",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Public Library Survey 2010: Book Mobiles",
    "text": "Public Library Survey 2010: Book Mobiles\n\n# bk_df"
  },
  {
    "objectID": "w10-idx.html#outline",
    "href": "w10-idx.html#outline",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Outline",
    "text": "Outline\n\nOrganize and save analysis results\nggplot",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#initialize-a-ggplot-object",
    "href": "w10-idx.html#initialize-a-ggplot-object",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Initialize a ggplot object",
    "text": "Initialize a ggplot object\nTo create a ggplot object, we need…\n\n\nComponents:\n\ndata\nmapping\ngeometry layer\n\n\nSteps:\n\nPrepare your data (often in the structure of a dataframe object)\nThink about the variable(s) that you’re interested in and what type of geometry (marks: point/line/polygon) might best help you understand their distribution or relationship.\nSpecify them using the grammar of graphics –map the variables to corresponding aesthetic or spatial properties of the geometry (color/size/position x, y)",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#ggplot-data-being-the-first-argument",
    "href": "w10-idx.html#ggplot-data-being-the-first-argument",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot(): data being the first argument",
    "text": "ggplot(): data being the first argument\n\nbook_df &lt;- read_csv('data/book-df-us-main.csv')\n\nRows: 47 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): state, division_str\ndbl (23): division_code, political_value_index, median_income, hs_grad_rate,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nbook_df |&gt; glimpse()\n\nRows: 47\nColumns: 25\n$ state                 &lt;chr&gt; \"WY\", \"PA\", \"OH\", \"NM\", \"MD\", \"RI\", \"OR\", \"WI\", …\n$ division_code         &lt;dbl&gt; 8, 2, 3, 8, 5, 1, 9, 3, 4, 8, 5, 2, 7, 4, 4, 8, …\n$ division_str          &lt;chr&gt; \"Mountain\", \"Middle Atlantic\", \"East North Centr…\n$ political_value_index &lt;dbl&gt; -19.7, 2.0, -0.7, 2.4, 8.5, 11.2, 4.0, 2.4, -10.…\n$ median_income         &lt;dbl&gt; 4081.5, 4218.0, 2469.0, -2401.5, 19404.5, 8141.0…\n$ hs_grad_rate          &lt;dbl&gt; 8.3380421, 2.3380421, 3.4380421, -0.6619579, 4.2…\n$ college_grad_rate     &lt;dbl&gt; -2.1237299, -1.6237299, -2.9237299, -0.5237299, …\n$ challenge_count       &lt;dbl&gt; 4, 148, 29, 3, 5, 3, 118, 10, 6, NA, 13, 25, 5, …\n$ explicit_count        &lt;dbl&gt; 1, 15, 13, 1, 2, 3, 26, 5, 2, NA, 4, 7, 1, 6, 1,…\n$ antifamily_count      &lt;dbl&gt; 0, 2, 5, 0, 1, 0, 1, 0, 0, NA, 1, 2, 0, 0, 0, 0,…\n$ occult_count          &lt;dbl&gt; 0, 3, 2, 0, 0, 0, 3, 1, 0, NA, 0, 1, 1, 1, 0, 0,…\n$ language_count        &lt;dbl&gt; 0, 16, 14, 1, 3, 2, 14, 3, 2, NA, 7, 9, 3, 5, 1,…\n$ lgbtq_count           &lt;dbl&gt; 1, 5, 1, 0, 2, 0, 10, 1, 0, NA, 3, 3, 0, 0, 0, 0…\n$ violent_count         &lt;dbl&gt; 1, 6, 2, 0, 2, 0, 19, 2, 1, NA, 3, 3, 1, 3, 1, 0…\n$ removed_count         &lt;dbl&gt; 1, 11, 10, 2, 0, 1, 5, 3, 2, NA, 4, 11, 0, 10, 0…\n$ removed_pct           &lt;dbl&gt; 25.000000, 7.432432, 34.482759, 66.666667, 0.000…\n$ POPU_LSA              &lt;dbl&gt; 544270, 12054201, 11551941, 1588981, 5633514, 14…\n$ POPU_ST               &lt;dbl&gt; 544270, 12284183, 11551941, 2009671, 5618344, 10…\n$ CENTLIB               &lt;dbl&gt; 23, 451, 240, 91, 15, 47, 122, 378, 80, 19, 61, …\n$ BRANLIB               &lt;dbl&gt; 53, 183, 480, 27, 169, 26, 94, 82, 10, 67, 331, …\n$ BKMOB                 &lt;dbl&gt; 2, 29, 58, 1, 18, 2, 8, 6, 12, 4, 17, 6, 1, 4, 7…\n$ BKVOL                 &lt;dbl&gt; 2497545, 27790282, 45224425, 4518130, 13954140, …\n$ LIBRARIA              &lt;dbl&gt; 189.16, 1445.81, 2725.65, 290.37, 1297.29, 232.1…\n$ VISITS                &lt;dbl&gt; 3872783, 47188171, 88255852, 8324986, 33662473, …\n$ REGBOR                &lt;dbl&gt; 383126, 5549200, 8767349, 1140637, 3271760, 5747…\n\n\n\nPlotting the distribution of a single variable\n\nview()\n\n\n# book_df |&gt; view()\n\n\n\nlayer geom_histogram(): for a numeric variable\n\n\nbook_df |&gt;\n  ggplot(mapping = aes(VISITS)) +\n  geom_histogram() +\n  scale_x_continuous(labels = comma)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nlayer geom_bar(): for a categorical variable\n\n\nbook_df |&gt;\n    ggplot(aes(x = division_str)) +\n    geom_bar() +\n    guides(x = guide_axis(angle = 60))",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#distribution",
    "href": "w10-idx.html#distribution",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Distribution",
    "text": "Distribution\ngeom_boxplot()\ndecompose the elements of ggplot specification\n\nmap variable name to aes attribute\nadd geometry layer with + sign\nextra: change the theme layer to classic\n\n\nbook_df |&gt;\n  ggplot(mapping = aes(y = BKMOB)) +\n  geom_boxplot() +\n  theme_classic()",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#association",
    "href": "w10-idx.html#association",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Association",
    "text": "Association\n\ngeom_point(), geom_text(), geom_label(): two variable, using points to mark position\n\n\nbk_df &lt;- read_csv('data/bkdf-us-main.csv')\n\nRows: 47 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): state, division_str\ndbl (23): division_code, political_value_index, median_income, hs_grad_rate,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_text(size = 2)\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_label(size = 2)\n\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, label = state)) +\n    geom_point(size = 2) +\n    geom_smooth(method = 'lm')\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: The following aesthetics were dropped during statistical transformation: label.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#comparison",
    "href": "w10-idx.html#comparison",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Comparison",
    "text": "Comparison\n\nAdd a z variable: color, size, facet_wrap()\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, color = division_str)) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n    ggplot(aes(x = CENTLIB, y = challenge_count, color = division_str)) +\n    geom_point() +\n    facet_wrap(~division_str) +\n    theme_classic()\n\n\n\n\n\n\n\n\n\nbk_df |&gt;\n  filter(division_str == 'Mountain') |&gt;\n  ggplot(aes(x = CENTLIB, y = challenge_count, color = state)) +\n  geom_point()",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#ggplot-for-sf",
    "href": "w10-idx.html#ggplot-for-sf",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot for sf",
    "text": "ggplot for sf\n\ngeom_sf()\n\n\nlibrary(tigris)\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\n\n\nAttachement du package : 'tigris'\n\n\nL'objet suivant est masqué depuis 'package:terra':\n\n    blocks\n\nstates_sf &lt;- states(year = 2010, progress_bar = FALSE)\n# states_sf\n\n\nstates_sf |&gt;\n  ggplot() +\n  geom_sf(aes(fill = DIVISION10))",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#ggplot-for-cda",
    "href": "w10-idx.html#ggplot-for-cda",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "ggplot for CDA",
    "text": "ggplot for CDA\n\nlibrary(HistData)\n\n\nAttachement du package : 'HistData'\n\n\nL'objet suivant est masqué depuis 'package:nlme':\n\n    Wheat\n\ndata(Nightingale)\n\n\nnightingale_df &lt;- Nightingale |&gt; as_tibble()\n\n\nnightingale_df |&gt;\n    ggplot() +\n    geom_line(aes(x = Date, y = Disease), color = 'deepskyblue') +\n    geom_line(aes(x = Date, y = Wounds), color = 'orange') + \n    geom_line(aes(x = Date, y = Other), color = 'green') +\n    scale_x_date(date_breaks = 'month', date_labels = '%Y %b') +\n    guides(x = guide_axis(angle = 60)) +\n    geom_vline(xintercept = ymd('1855-03-01'), colour = \"red\") +\n    labs(y = 'Count') +\n    theme_classic()",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "w10-idx.html#public-library-survey-2010-book-mobiles",
    "href": "w10-idx.html#public-library-survey-2010-book-mobiles",
    "title": "R Coding Workshop: 8th Meeting",
    "section": "Public Library Survey 2010: Book Mobiles",
    "text": "Public Library Survey 2010: Book Mobiles\n\n# bk_df",
    "crumbs": [
      "Coding Workshop",
      "Week 10"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Taman",
    "section": "",
    "text": "In winter, when night’s shade\npossesses longer half the world,\nand longer in the idle stillness,\nby the bemisted moon,\nthe lazy orient sleeps,\nawakened at her customary hour\nshe would get up by candles.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "2024-2026",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "w5-slides.html#r-coding-workshop-3rd-meeting",
    "href": "w5-slides.html#r-coding-workshop-3rd-meeting",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "R Coding Workshop: 3rd Meeting",
    "text": "R Coding Workshop: 3rd Meeting"
  },
  {
    "objectID": "w5-slides.html#outline-for-today",
    "href": "w5-slides.html#outline-for-today",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Outline for today",
    "text": "Outline for today\n\nInstall and load R Packages\nTidyverse: coding style and collection of packages\n\nPipeline operator\nreadr: Read and write data\nTidy Data: prepared for data analysis (next week)\n\nExploratory Data Analysis:dplyr continued\nggplot: Data Visualization"
  },
  {
    "objectID": "w5-slides.html#tidyverse",
    "href": "w5-slides.html#tidyverse",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Tidyverse",
    "text": "Tidyverse\nTidyverse coding style and packages\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "w5-slides.html#read-and-write-data",
    "href": "w5-slides.html#read-and-write-data",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Read and write data",
    "text": "Read and write data\n\nuni_df &lt;- tibble::tribble(\n  ~university, ~year, ~current_country, ~lat, ~lon, ~exist_today,\n  \"Paris\", 1150, \"France\", 48.8566, 2.3522, TRUE,\n  \"Salerno\", 1173,  \"Italy\", 40.7711, 14.7905, TRUE,\n  \"Reggio\", 1188, \"Italy\", 44.6450, 10.9277, TRUE,\n  \"Oxford\", 1190, \"United Kingdom\", 51.7520, -1.2576, TRUE,\n  \"Bologna\", 1200, \"Italy\", 44.4989, 11.3275, TRUE\n)\nuni_df\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nlat\nlon\nexist_today\n\n\n\n\nParis\n1150\nFrance\n48.8566\n2.3522\nTRUE\n\n\nSalerno\n1173\nItaly\n40.7711\n14.7905\nTRUE\n\n\nReggio\n1188\nItaly\n44.6450\n10.9277\nTRUE\n\n\nOxford\n1190\nUnited Kingdom\n51.7520\n-1.2576\nTRUE\n\n\nBologna\n1200\nItaly\n44.4989\n11.3275\nTRUE\n\n\n\n\n\n\n\nuni_fpath &lt;- 'data/university-1200.csv'\nuni_df |&gt; write_csv(uni_fpath)\n\n\nuni_df |&gt; rm()\n\n\nuni_df &lt;- read_csv(uni_fpath)\nuni_df |&gt; class()\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n\nlibrary(sf)\nlibrary(mapview)\n\n\nuni_sf &lt;- uni_df |&gt; st_as_sf(coords = c('lon','lat'), crs = 4326)\nuni_sf |&gt; mapview(label = 'university')\n\n\n\n\n\n\nuni_sf_fpath &lt;- 'data/uni-1200-sf.gpkg'\n# uni_sf |&gt; st_write(uni_sf_fpath)\n\n\nuni_sf |&gt; rm()\nuni_sf &lt;- st_read(uni_sf_fpath)\n\nReading layer `uni-1200-sf' from data source \n  `/Users/toyuan/dohnanyi/data/uni-1200-sf.gpkg' using driver `GPKG'\nSimple feature collection with 5 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -1.2576 ymin: 40.7711 xmax: 14.7905 ymax: 51.752\nGeodetic CRS:  WGS 84\n\nuni_sf |&gt; mapview(label = 'university')"
  },
  {
    "objectID": "w5-slides.html#dplyr-for-exploratory-data-analysis",
    "href": "w5-slides.html#dplyr-for-exploratory-data-analysis",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr for Exploratory Data Analysis",
    "text": "dplyr for Exploratory Data Analysis\n\nMore functions from dplyr\nMerits of pipeline operator |&gt;"
  },
  {
    "objectID": "w5-slides.html#tidyverse-eda",
    "href": "w5-slides.html#tidyverse-eda",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Tidyverse EDA",
    "text": "Tidyverse EDA\nImport Data: Challenged Books from 2000 to 2010\n\nsource: American Library Society (America Library Association)\n\n\nlibrary(bayesrules)\n\nbook_challenge_df &lt;- book_banning |&gt; as_tibble()\nbook_challenge_df |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nHouse of the Spirits, The\n927\nAllende, Isabel\n2005-04-01\n2005\n0\n1\n0\n1\n1\n1\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nIt’s Not the Stork!: A Book About Girls, Boys, Babies and Bodies\n1024\nHarris, Robie\n2008-02-06\n2008\n1\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nKing Stork\n1087\nPyle, Howard\n2008-10-02\n2008\n0\n0\n0\n0\n0\n0\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nHow They Met and Other Stories\n936\nLevithan, David\n2008-10-05\n2008\n0\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nGhost in the Shell\n764\nMasamune, Shirow\n2008-10-02\n2008\n0\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nKing Stork\n1087\nPyle, Howard\n2003-09-13\n2003\n0\n0\n0\n0\n0\n0\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\n\n\n\n\n\n\n\n\nTidy Data and Data Cleaning (next week)\n\n\n\nbook_challenge_df |&gt; summary()\n\n    title              book_id       author               date           \n Length:931         143    : 17   Length:931         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):868                      NA's   :11          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:714   0:632    0:891      0:895   0:694    0:842   0:797  \n 1st Qu.:2002   1:217   1:299    1: 40      1: 36   1:237    1: 89   1:134  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n NA's   :11                                                                 \n    state           political_value_index median_income    hs_grad_rate   \n Length:931         Min.   :-20.2000      Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -1.8000      1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.0000      Median : 4218   Median : 2.338  \n                    Mean   :  0.0304      Mean   : 4530   Mean   : 2.833  \n                    3rd Qu.:  4.0000      3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.4000      Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-2.0237  \n Median : 0.2763  \n Mean   : 0.6043  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763  \n                  \n\n\n\nbook_challenge_df |&gt; dim()\n\n[1] 931  17\n\n\n\nremove 11 books with missing values (require justification!)\n\n\nbook_challenge_df &lt;- book_challenge_df |&gt; drop_na()\nbook_challenge_df |&gt; dim()\n\n[1] 920  17\n\n\n\nduplicated rows?\n\n\n# book_challenge_df |&gt; group_by(book_id) |&gt; filter(n_distinct(title) &gt; 1) |&gt; arrange(book_id) |&gt; tail()\n\n\n# book_challenge_df |&gt; distinct(book_id, title)\n\n\n\n\n\nDimension:\n\n(row x column)\n920 Observations: number of recorded book challenges\n17 Variables:\n\nobservation-level\n\ntitle, author, date\n\nstate-level variables\n\nmedian_income, political_value_index\n\n\n\nSummary statistics:\n\nthe data type and the value range of the dataset\n\n\nbook_challenge_df |&gt; summary()\n\n    title              book_id       author               date           \n Length:920         143    : 17   Length:920         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):857                                          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:706   0:628    0:880      0:884   0:686    0:832   0:788  \n 1st Qu.:2002   1:214   1:292    1: 40      1: 36   1:234    1: 88   1:132  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n                                                                            \n    state           political_value_index median_income    hs_grad_rate   \n Length:920         Min.   :-20.20000     Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -2.12500     1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.00000     Median : 4218   Median : 2.338  \n                    Mean   :  0.01326     Mean   : 4522   Mean   : 2.808  \n                    3rd Qu.:  4.00000     3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.40000     Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-1.7237  \n Median : 0.2763  \n Mean   : 0.6042  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763"
  },
  {
    "objectID": "w5-slides.html#dplyr-functions-mutate",
    "href": "w5-slides.html#dplyr-functions-mutate",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: mutate()",
    "text": "dplyr functions: mutate()\n\nmutate(): creating new variables (columns) from existing variables\ncase: typecasting\n\n\nbook_challenge_df &lt;- book_challenge_df |&gt;\n  mutate(\n    yr = year(date),\n    month = month(date),\n    day = day(date),\n    week_day = wday(date, label = TRUE)\n    )\n\n\nall(book_challenge_df$year == as.numeric(book_challenge_df$yr))\n\n[1] TRUE\n\n\n\n# book_challenge_df &lt;- book_challenge_df |&gt; mutate(year = yr) |&gt; select(-yr)\n\n\ncount()\n\n\nbook_challenge_df |&gt; count(week_day)\n\n\n\n\n\nweek_day\nn\n\n\n\n\nSun\n119\n\n\nMon\n182\n\n\nTue\n95\n\n\nWed\n132\n\n\nThu\n148\n\n\nFri\n155\n\n\nSat\n89"
  },
  {
    "objectID": "w5-slides.html#dplyr-functions-group_by",
    "href": "w5-slides.html#dplyr-functions-group_by",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: group_by()",
    "text": "dplyr functions: group_by()\n\ngroup observations by like variable value, why?\n\n\nnrow(book_challenge_df[book_challenge_df$removed == 1,]) / nrow(book_challenge_df)\n\n[1] 0.2326087"
  },
  {
    "objectID": "w5-slides.html#dplyr-functions-group_by-1",
    "href": "w5-slides.html#dplyr-functions-group_by-1",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: group_by()",
    "text": "dplyr functions: group_by()\n\nsubset, stratify\n\n\nbook_challenge_df |&gt; group_by(year) |&gt; summarize(\n    total_count = n(),\n    removed_count = sum(removed == 1),\n    removed_pct = (removed_count / total_count) * 100\n)\n\n\n\n\n\nyear\ntotal_count\nremoved_count\nremoved_pct\n\n\n\n\n2000\n71\n26\n36.61972\n\n\n2001\n111\n26\n23.42342\n\n\n2002\n52\n16\n30.76923\n\n\n2003\n88\n14\n15.90909\n\n\n2004\n83\n20\n24.09639\n\n\n2005\n52\n15\n28.84615\n\n\n2006\n54\n9\n16.66667\n\n\n2007\n38\n15\n39.47368\n\n\n2008\n122\n37\n30.32787\n\n\n2009\n197\n22\n11.16751\n\n\n2010\n52\n14\n26.92308\n\n\n\n\n\n\n# A tibble: 11 × 4\n    year total_count removed_count removed_pct\n   &lt;dbl&gt;       &lt;int&gt;         &lt;int&gt;       &lt;dbl&gt;\n 1  2000          71            26        36.6\n 2  2001         111            26        23.4\n 3  2002          52            16        30.8\n 4  2003          88            14        15.9\n 5  2004          83            20        24.1\n 6  2005          52            15        28.8\n 7  2006          54             9        16.7\n 8  2007          38            15        39.5\n 9  2008         122            37        30.3\n10  2009         197            22        11.2\n11  2010          52            14        26.9\n\nexpressive pipeline that aligns with DS workflow!\nBase R:\n\ntotal_count &lt;- as.vector(\n    tapply(\n        book_challenge_df$removed,\n        book_challenge_df$year,\n        length\n        )\n)\nremoved_count &lt;- as.vector(\n    tapply(\n        book_challenge_df$removed == 1,\n        book_challenge_df$year,\n        sum\n        )\n)\nyear_summary &lt;- data.frame(\n    year = 2000:2010,\n    total_count = total_count,\n    removed_count = removed_count,\n    removed_pct = (removed_count / total_count) * 100\n)\nyear_summary"
  },
  {
    "objectID": "w5-slides.html#group-data-by-geounit",
    "href": "w5-slides.html#group-data-by-geounit",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Group Data by Geounit",
    "text": "Group Data by Geounit\n\nstate_level_vars &lt;- c(\n    \"state\", \"political_value_index\",\n    \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n    )\n# book_challenge_df |&gt; group_by(across(state_level_vars)) |&gt; summarize(count = n())\n\n\nstate_summary &lt;- book_challenge_df |&gt;\n  group_by_at(state_level_vars) |&gt;\n  summarize(count = n())\n\nstate_summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\n\n\n\n\nAK\n-13.4\n15707.5\n8.7380421\n0.6762701\n9\n\n\nAL\n-13.2\n-5054.0\n-4.2619579\n-5.0237299\n10\n\n\nAR\n-8.8\n-6258.5\n-4.2619579\n-7.3237299\n5\n\n\nAZ\n-6.1\n3490.5\n1.4380421\n-0.5237299\n12\n\n\nCA\n7.4\n10119.0\n-2.7619579\n2.5762701\n50\n\n\nCO\n-0.2\n10346.5\n7.3380421\n8.6762701\n80\n\n\nCT\n7.1\n16247.5\n4.4380421\n7.3762701\n6\n\n\nDE\n7.0\n9167.5\n3.0380421\n0.9762701\n2\n\n\nFL\n-1.8\n372.0\n0.3380421\n-1.7237299\n26\n\n\nGA\n-6.8\n2239.5\n-0.9619579\n0.2762701\n13\n\n\nIA\n1.0\n3921.5\n6.5380421\n-2.8237299\n13\n\n\nID\n-17.4\n3194.0\n5.1380421\n-2.3237299\n14\n\n\nIL\n7.7\n6489.5\n1.8380421\n2.0762701\n39\n\n\nIN\n-6.2\n1086.5\n2.5380421\n-4.6237299\n20\n\n\nKS\n-11.5\n144.5\n6.4380421\n1.7762701\n13\n\n\nKY\n-10.4\n-5880.5\n-5.4619579\n-6.9237299\n13\n\n\nLA\n-9.7\n-5120.5\n-4.7619579\n-5.3237299\n12\n\n\nMA\n11.7\n14048.5\n5.2380421\n9.1762701\n8\n\n\nMD\n8.5\n19404.5\n4.2380421\n7.3762701\n5\n\n\nME\n5.5\n1335.5\n5.8380421\n-1.1237299\n3\n\n\nMI\n3.8\n2966.0\n3.8380421\n-2.2237299\n34\n\n\nMN\n2.3\n15378.0\n8.3380421\n3.3762701\n17\n\n\nMO\n-3.1\n1279.5\n1.7380421\n-2.4237299\n11\n\n\nMS\n-9.5\n-8466.5\n-6.6619579\n-7.1237299\n1\n\n\nMT\n-7.1\n-6482.0\n7.6380421\n0.3762701\n7\n\n\nNC\n-4.3\n-310.0\n-1.4619579\n-1.5237299\n20\n\n\nND\n-10.4\n-813.0\n4.3380421\n-2.0237299\n6\n\n\nNE\n-13.5\n4927.5\n7.0380421\n-0.3237299\n2\n\n\nNH\n1.6\n17303.0\n7.8380421\n4.6762701\n7\n\n\nNJ\n4.4\n19935.5\n2.5380421\n5.7762701\n11\n\n\nNM\n2.4\n-2401.5\n-0.6619579\n-0.5237299\n3\n\n\nNY\n10.2\n5007.5\n-0.4619579\n3.3762701\n24\n\n\nOH\n-0.7\n2469.0\n3.4380421\n-2.9237299\n29\n\n\nOK\n-16.9\n-3087.5\n1.0380421\n-3.7237299\n23\n\n\nOR\n4.0\n1274.5\n5.5380421\n1.0762701\n118\n\n\nPA\n2.0\n4218.0\n2.3380421\n-1.6237299\n147\n\n\nRI\n11.2\n8141.0\n-1.5619579\n1.5762701\n3\n\n\nSC\n-7.8\n-2191.5\n-3.2619579\n-3.6237299\n15\n\n\nSD\n-8.9\n785.0\n5.0380421\n-2.5237299\n3\n\n\nTN\n-8.7\n-2995.5\n-3.6619579\n-4.4237299\n13\n\n\nUT\n-20.2\n12735.5\n8.1380421\n2.0762701\n1\n\n\nVA\n-1.7\n11296.0\n1.9380421\n5.4762701\n33\n\n\nVT\n13.4\n8467.0\n6.8380421\n5.3762701\n13\n\n\nWA\n5.0\n9907.5\n7.5380421\n3.6762701\n9\n\n\nWI\n2.4\n4234.5\n5.5380421\n-1.6237299\n10\n\n\nWV\n-7.9\n-7290.0\n-4.3619579\n-9.2237299\n3\n\n\nWY\n-19.7\n4081.5\n8.3380421\n-2.1237299\n4\n\n\n\n\n\n\n\n# sanity check\nstate_summary |&gt; dim() |&gt; print()\n\n[1] 47  6\n\nstate_summary$count |&gt; sum()\n\n[1] 920"
  },
  {
    "objectID": "w5-slides.html#adding-spatial-dimension",
    "href": "w5-slides.html#adding-spatial-dimension",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Adding Spatial Dimension",
    "text": "Adding Spatial Dimension\n\nlibrary(sf)\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\n\n\nPrepare the Geometry\n\n\nstate_sf &lt;- ne_states(country = 'United States of America') |&gt; select(postal, gn_name, gadm_level, region)\nstate_sf |&gt; dim() |&gt; print()\n\n[1] 51  5\n\nstate_sf |&gt; mapview()\n\n\n\n\n\n\nCombine by column value match\n\n\nplot_sf &lt;- state_sf |&gt;\n  left_join(\n    state_summary,\n    by = join_by(postal == state)\n)\nplot_sf |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npostal\ngn_name\ngadm_level\nregion\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\ngeometry\n\n\n\n\nWA\nWashington\n1\nWest\n5.0\n9907.5\n7.538042\n3.6762701\n9\nMULTIPOLYGON (((-122.753 48…\n\n\nID\nIdaho\n1\nWest\n-17.4\n3194.0\n5.138042\n-2.3237299\n14\nMULTIPOLYGON (((-117.0382 4…\n\n\nMT\nMontana\n1\nWest\n-7.1\n-6482.0\n7.638042\n0.3762701\n7\nMULTIPOLYGON (((-116.0482 4…\n\n\nND\nNorth Dakota\n1\nMidwest\n-10.4\n-813.0\n4.338042\n-2.0237299\n6\nMULTIPOLYGON (((-104.0476 4…\n\n\nMN\nMinnesota\n1\nMidwest\n2.3\n15378.0\n8.338042\n3.3762701\n17\nMULTIPOLYGON (((-97.22609 4…\n\n\nMI\nMichigan\n1\nMidwest\n3.8\n2966.0\n3.838042\n-2.2237299\n34\nMULTIPOLYGON (((-84.4913 46…\n\n\n\n\n\n\n\nstate_summary |&gt; select(state, count) |&gt; filter(state == 'WA')\n\n\n\n\n\npolitical_value_index\nmedian_income\nhs_grad_rate\nstate\ncount\n\n\n\n\n5\n9907.5\n7.538042\nWA\n9"
  },
  {
    "objectID": "w5-slides.html#choropleth",
    "href": "w5-slides.html#choropleth",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Choropleth",
    "text": "Choropleth\n\nplot_sf |&gt; mapview(zcol = 'count', label = 'gn_name')\n\n\n\n\n\n\nplot_sf |&gt; filter(is.na(count))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npostal\ngn_name\ngadm_level\nregion\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\ngeometry\n\n\n\n\nTX\nTexas\n1\nSouth\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-103.3115 2…\n\n\nDC\nDistrict of Columbia\n1\nSouth\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-77.02293 3…\n\n\nHI\nHawaii\n1\nWest\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-154.8996 1…\n\n\nNV\nNevada\n1\nWest\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-114.0425 4…"
  },
  {
    "objectID": "w5-slides.html#ggplot-plot-with-more-controls",
    "href": "w5-slides.html#ggplot-plot-with-more-controls",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "ggplot plot with more controls",
    "text": "ggplot plot with more controls\n\nplot_sf |&gt; ggplot() + geom_sf(aes(fill = count), color = 'white', size = 0.01) + scale_fill_viridis() + theme_bw()"
  },
  {
    "objectID": "w5-idx.html#outline-for-today",
    "href": "w5-idx.html#outline-for-today",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Outline for today",
    "text": "Outline for today\n\nInstall and load R Packages\nTidyverse: coding style and collection of packages\n\nPipeline operator\nreadr: Read and write data\nTidy Data: prepared for data analysis (next week)\n\nExploratory Data Analysis:dplyr continued\nggplot: Data Visualization",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#tidyverse",
    "href": "w5-idx.html#tidyverse",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Tidyverse",
    "text": "Tidyverse\nTidyverse coding style and packages\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#read-and-write-data",
    "href": "w5-idx.html#read-and-write-data",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Read and write data",
    "text": "Read and write data\n\nuni_df &lt;- tibble::tribble(\n  ~university, ~year, ~current_country, ~lat, ~lon, ~exist_today,\n  \"Paris\", 1150, \"France\", 48.8566, 2.3522, TRUE,\n  \"Salerno\", 1173,  \"Italy\", 40.7711, 14.7905, TRUE,\n  \"Reggio\", 1188, \"Italy\", 44.6450, 10.9277, TRUE,\n  \"Oxford\", 1190, \"United Kingdom\", 51.7520, -1.2576, TRUE,\n  \"Bologna\", 1200, \"Italy\", 44.4989, 11.3275, TRUE\n)\nuni_df\n\n\n\n\n\nuniversity\nyear\ncurrent_country\nlat\nlon\nexist_today\n\n\n\n\nParis\n1150\nFrance\n48.8566\n2.3522\nTRUE\n\n\nSalerno\n1173\nItaly\n40.7711\n14.7905\nTRUE\n\n\nReggio\n1188\nItaly\n44.6450\n10.9277\nTRUE\n\n\nOxford\n1190\nUnited Kingdom\n51.7520\n-1.2576\nTRUE\n\n\nBologna\n1200\nItaly\n44.4989\n11.3275\nTRUE\n\n\n\n\n\n\n\nuni_fpath &lt;- 'data/university-1200.csv'\nuni_df |&gt; write_csv(uni_fpath)\n\n\nuni_df |&gt; rm()\n\n\nuni_df &lt;- read_csv(uni_fpath)\n\nRows: 5 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): university, current_country\ndbl (3): year, lat, lon\nlgl (1): exist_today\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nuni_df |&gt; class()\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(mapview)\n\n\nuni_sf &lt;- uni_df |&gt; st_as_sf(coords = c('lon','lat'), crs = 4326)\nuni_sf |&gt; mapview(label = 'university')\n\n\n\n\n\n\nuni_sf_fpath &lt;- 'data/uni-1200-sf.gpkg'\n# uni_sf |&gt; st_write(uni_sf_fpath)\n\n\nuni_sf |&gt; rm()\nuni_sf &lt;- st_read(uni_sf_fpath)\n\nReading layer `uni-1200-sf' from data source \n  `/Users/toyuan/dohnanyi/data/uni-1200-sf.gpkg' using driver `GPKG'\nSimple feature collection with 5 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -1.2576 ymin: 40.7711 xmax: 14.7905 ymax: 51.752\nGeodetic CRS:  WGS 84\n\nuni_sf |&gt; mapview(label = 'university')",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#dplyr-for-exploratory-data-analysis",
    "href": "w5-idx.html#dplyr-for-exploratory-data-analysis",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr for Exploratory Data Analysis",
    "text": "dplyr for Exploratory Data Analysis\n\nMore functions from dplyr\nMerits of pipeline operator |&gt;",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#tidyverse-eda",
    "href": "w5-idx.html#tidyverse-eda",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Tidyverse EDA",
    "text": "Tidyverse EDA\nImport Data: Challenged Books from 2000 to 2010\n\nsource: American Library Society (America Library Association)\n\n\nlibrary(bayesrules)\n\nbook_challenge_df &lt;- book_banning |&gt; as_tibble()\nbook_challenge_df |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntitle\nbook_id\nauthor\ndate\nyear\nremoved\nexplicit\nantifamily\noccult\nlanguage\nlgbtq\nviolent\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\n\n\n\n\nHouse of the Spirits, The\n927\nAllende, Isabel\n2005-04-01\n2005\n0\n1\n0\n1\n1\n1\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nIt’s Not the Stork!: A Book About Girls, Boys, Babies and Bodies\n1024\nHarris, Robie\n2008-02-06\n2008\n1\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nKing Stork\n1087\nPyle, Howard\n2008-10-02\n2008\n0\n0\n0\n0\n0\n0\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nHow They Met and Other Stories\n936\nLevithan, David\n2008-10-05\n2008\n0\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nGhost in the Shell\n764\nMasamune, Shirow\n2008-10-02\n2008\n0\n0\n0\n0\n0\n0\n0\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\nKing Stork\n1087\nPyle, Howard\n2003-09-13\n2003\n0\n0\n0\n0\n0\n0\n1\nAK\n-13.4\n15707.5\n8.738042\n0.6762701\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Data and Data Cleaning (next week)\n\n\n\n\n\n\nbook_challenge_df |&gt; summary()\n\n    title              book_id       author               date           \n Length:931         143    : 17   Length:931         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):868                      NA's   :11          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:714   0:632    0:891      0:895   0:694    0:842   0:797  \n 1st Qu.:2002   1:217   1:299    1: 40      1: 36   1:237    1: 89   1:134  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n NA's   :11                                                                 \n    state           political_value_index median_income    hs_grad_rate   \n Length:931         Min.   :-20.2000      Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -1.8000      1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.0000      Median : 4218   Median : 2.338  \n                    Mean   :  0.0304      Mean   : 4530   Mean   : 2.833  \n                    3rd Qu.:  4.0000      3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.4000      Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-2.0237  \n Median : 0.2763  \n Mean   : 0.6043  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763  \n                  \n\n\n\nbook_challenge_df |&gt; dim()\n\n[1] 931  17\n\n\n\nremove 11 books with missing values (require justification!)\n\n\nbook_challenge_df &lt;- book_challenge_df |&gt; drop_na()\nbook_challenge_df |&gt; dim()\n\n[1] 920  17\n\n\n\nduplicated rows?\n\n\n# book_challenge_df |&gt; group_by(book_id) |&gt; filter(n_distinct(title) &gt; 1) |&gt; arrange(book_id) |&gt; tail()\n\n\n# book_challenge_df |&gt; distinct(book_id, title)\n\n\n\n\nDimension:\n\n(row x column)\n920 Observations: number of recorded book challenges\n17 Variables:\n\nobservation-level\n\ntitle, author, date\n\nstate-level variables\n\nmedian_income, political_value_index\n\n\n\nSummary statistics:\n\nthe data type and the value range of the dataset\n\n\nbook_challenge_df |&gt; summary()\n\n    title              book_id       author               date           \n Length:920         143    : 17   Length:920         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):857                                          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:706   0:628    0:880      0:884   0:686    0:832   0:788  \n 1st Qu.:2002   1:214   1:292    1: 40      1: 36   1:234    1: 88   1:132  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n                                                                            \n    state           political_value_index median_income    hs_grad_rate   \n Length:920         Min.   :-20.20000     Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -2.12500     1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.00000     Median : 4218   Median : 2.338  \n                    Mean   :  0.01326     Mean   : 4522   Mean   : 2.808  \n                    3rd Qu.:  4.00000     3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.40000     Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-1.7237  \n Median : 0.2763  \n Mean   : 0.6042  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#dplyr-functions-mutate",
    "href": "w5-idx.html#dplyr-functions-mutate",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: mutate()",
    "text": "dplyr functions: mutate()\n\nmutate(): creating new variables (columns) from existing variables\ncase: typecasting\n\n\nbook_challenge_df &lt;- book_challenge_df |&gt;\n  mutate(\n    yr = year(date),\n    month = month(date),\n    day = day(date),\n    week_day = wday(date, label = TRUE)\n    )\n\n\nall(book_challenge_df$year == as.numeric(book_challenge_df$yr))\n\n[1] TRUE\n\n\n\n# book_challenge_df &lt;- book_challenge_df |&gt; mutate(year = yr) |&gt; select(-yr)\n\n\ncount()\n\n\nbook_challenge_df |&gt; count(week_day)\n\n\n\n\n\nweek_day\nn\n\n\n\n\nSun\n119\n\n\nMon\n182\n\n\nTue\n95\n\n\nWed\n132\n\n\nThu\n148\n\n\nFri\n155\n\n\nSat\n89",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#dplyr-functions-group_by",
    "href": "w5-idx.html#dplyr-functions-group_by",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: group_by()",
    "text": "dplyr functions: group_by()\n\ngroup observations by like variable value, why?\n\n\nnrow(book_challenge_df[book_challenge_df$removed == 1,]) / nrow(book_challenge_df)\n\n[1] 0.2326087",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#dplyr-functions-group_by-1",
    "href": "w5-idx.html#dplyr-functions-group_by-1",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "dplyr functions: group_by()",
    "text": "dplyr functions: group_by()\n\nsubset, stratify\n\n\nbook_challenge_df |&gt; group_by(year) |&gt; summarize(\n    total_count = n(),\n    removed_count = sum(removed == 1),\n    removed_pct = (removed_count / total_count) * 100\n)\n\n\n\n\n\nyear\ntotal_count\nremoved_count\nremoved_pct\n\n\n\n\n2000\n71\n26\n36.61972\n\n\n2001\n111\n26\n23.42342\n\n\n2002\n52\n16\n30.76923\n\n\n2003\n88\n14\n15.90909\n\n\n2004\n83\n20\n24.09639\n\n\n2005\n52\n15\n28.84615\n\n\n2006\n54\n9\n16.66667\n\n\n2007\n38\n15\n39.47368\n\n\n2008\n122\n37\n30.32787\n\n\n2009\n197\n22\n11.16751\n\n\n2010\n52\n14\n26.92308\n\n\n\n\n\n\n# A tibble: 11 × 4\n    year total_count removed_count removed_pct\n   &lt;dbl&gt;       &lt;int&gt;         &lt;int&gt;       &lt;dbl&gt;\n 1  2000          71            26        36.6\n 2  2001         111            26        23.4\n 3  2002          52            16        30.8\n 4  2003          88            14        15.9\n 5  2004          83            20        24.1\n 6  2005          52            15        28.8\n 7  2006          54             9        16.7\n 8  2007          38            15        39.5\n 9  2008         122            37        30.3\n10  2009         197            22        11.2\n11  2010          52            14        26.9\n\nexpressive pipeline that aligns with DS workflow!\nBase R:\n\ntotal_count &lt;- as.vector(\n    tapply(\n        book_challenge_df$removed,\n        book_challenge_df$year,\n        length\n        )\n)\nremoved_count &lt;- as.vector(\n    tapply(\n        book_challenge_df$removed == 1,\n        book_challenge_df$year,\n        sum\n        )\n)\nyear_summary &lt;- data.frame(\n    year = 2000:2010,\n    total_count = total_count,\n    removed_count = removed_count,\n    removed_pct = (removed_count / total_count) * 100\n)\nyear_summary",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#group-data-by-geounit",
    "href": "w5-idx.html#group-data-by-geounit",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Group Data by Geounit",
    "text": "Group Data by Geounit\n\nstate_level_vars &lt;- c(\n    \"state\", \"political_value_index\",\n    \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n    )\n# book_challenge_df |&gt; group_by(across(state_level_vars)) |&gt; summarize(count = n())\n\n\nstate_summary &lt;- book_challenge_df |&gt;\n  group_by_at(state_level_vars) |&gt;\n  summarize(count = n())\n\n`summarise()` has grouped output by 'state', 'political_value_index',\n'median_income', 'hs_grad_rate'. You can override using the `.groups` argument.\n\nstate_summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nstate\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\n\n\n\n\nAK\n-13.4\n15707.5\n8.7380421\n0.6762701\n9\n\n\nAL\n-13.2\n-5054.0\n-4.2619579\n-5.0237299\n10\n\n\nAR\n-8.8\n-6258.5\n-4.2619579\n-7.3237299\n5\n\n\nAZ\n-6.1\n3490.5\n1.4380421\n-0.5237299\n12\n\n\nCA\n7.4\n10119.0\n-2.7619579\n2.5762701\n50\n\n\nCO\n-0.2\n10346.5\n7.3380421\n8.6762701\n80\n\n\nCT\n7.1\n16247.5\n4.4380421\n7.3762701\n6\n\n\nDE\n7.0\n9167.5\n3.0380421\n0.9762701\n2\n\n\nFL\n-1.8\n372.0\n0.3380421\n-1.7237299\n26\n\n\nGA\n-6.8\n2239.5\n-0.9619579\n0.2762701\n13\n\n\nIA\n1.0\n3921.5\n6.5380421\n-2.8237299\n13\n\n\nID\n-17.4\n3194.0\n5.1380421\n-2.3237299\n14\n\n\nIL\n7.7\n6489.5\n1.8380421\n2.0762701\n39\n\n\nIN\n-6.2\n1086.5\n2.5380421\n-4.6237299\n20\n\n\nKS\n-11.5\n144.5\n6.4380421\n1.7762701\n13\n\n\nKY\n-10.4\n-5880.5\n-5.4619579\n-6.9237299\n13\n\n\nLA\n-9.7\n-5120.5\n-4.7619579\n-5.3237299\n12\n\n\nMA\n11.7\n14048.5\n5.2380421\n9.1762701\n8\n\n\nMD\n8.5\n19404.5\n4.2380421\n7.3762701\n5\n\n\nME\n5.5\n1335.5\n5.8380421\n-1.1237299\n3\n\n\nMI\n3.8\n2966.0\n3.8380421\n-2.2237299\n34\n\n\nMN\n2.3\n15378.0\n8.3380421\n3.3762701\n17\n\n\nMO\n-3.1\n1279.5\n1.7380421\n-2.4237299\n11\n\n\nMS\n-9.5\n-8466.5\n-6.6619579\n-7.1237299\n1\n\n\nMT\n-7.1\n-6482.0\n7.6380421\n0.3762701\n7\n\n\nNC\n-4.3\n-310.0\n-1.4619579\n-1.5237299\n20\n\n\nND\n-10.4\n-813.0\n4.3380421\n-2.0237299\n6\n\n\nNE\n-13.5\n4927.5\n7.0380421\n-0.3237299\n2\n\n\nNH\n1.6\n17303.0\n7.8380421\n4.6762701\n7\n\n\nNJ\n4.4\n19935.5\n2.5380421\n5.7762701\n11\n\n\nNM\n2.4\n-2401.5\n-0.6619579\n-0.5237299\n3\n\n\nNY\n10.2\n5007.5\n-0.4619579\n3.3762701\n24\n\n\nOH\n-0.7\n2469.0\n3.4380421\n-2.9237299\n29\n\n\nOK\n-16.9\n-3087.5\n1.0380421\n-3.7237299\n23\n\n\nOR\n4.0\n1274.5\n5.5380421\n1.0762701\n118\n\n\nPA\n2.0\n4218.0\n2.3380421\n-1.6237299\n147\n\n\nRI\n11.2\n8141.0\n-1.5619579\n1.5762701\n3\n\n\nSC\n-7.8\n-2191.5\n-3.2619579\n-3.6237299\n15\n\n\nSD\n-8.9\n785.0\n5.0380421\n-2.5237299\n3\n\n\nTN\n-8.7\n-2995.5\n-3.6619579\n-4.4237299\n13\n\n\nUT\n-20.2\n12735.5\n8.1380421\n2.0762701\n1\n\n\nVA\n-1.7\n11296.0\n1.9380421\n5.4762701\n33\n\n\nVT\n13.4\n8467.0\n6.8380421\n5.3762701\n13\n\n\nWA\n5.0\n9907.5\n7.5380421\n3.6762701\n9\n\n\nWI\n2.4\n4234.5\n5.5380421\n-1.6237299\n10\n\n\nWV\n-7.9\n-7290.0\n-4.3619579\n-9.2237299\n3\n\n\nWY\n-19.7\n4081.5\n8.3380421\n-2.1237299\n4\n\n\n\n\n\n\n\n# sanity check\nstate_summary |&gt; dim() |&gt; print()\n\n[1] 47  6\n\nstate_summary$count |&gt; sum()\n\n[1] 920",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#adding-spatial-dimension",
    "href": "w5-idx.html#adding-spatial-dimension",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Adding Spatial Dimension",
    "text": "Adding Spatial Dimension\n\nlibrary(sf)\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\n\nLe chargement a nécessité le package : viridisLite\n\n\n\nPrepare the Geometry\n\n\nstate_sf &lt;- ne_states(country = 'United States of America') |&gt; select(postal, gn_name, gadm_level, region)\nstate_sf |&gt; dim() |&gt; print()\n\n[1] 51  5\n\nstate_sf |&gt; mapview()\n\n\n\n\n\n\nCombine by column value match\n\n\nplot_sf &lt;- state_sf |&gt;\n  left_join(\n    state_summary,\n    by = join_by(postal == state)\n)\nplot_sf |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npostal\ngn_name\ngadm_level\nregion\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\ngeometry\n\n\n\n\nWA\nWashington\n1\nWest\n5.0\n9907.5\n7.538042\n3.6762701\n9\nMULTIPOLYGON (((-122.753 48…\n\n\nID\nIdaho\n1\nWest\n-17.4\n3194.0\n5.138042\n-2.3237299\n14\nMULTIPOLYGON (((-117.0382 4…\n\n\nMT\nMontana\n1\nWest\n-7.1\n-6482.0\n7.638042\n0.3762701\n7\nMULTIPOLYGON (((-116.0482 4…\n\n\nND\nNorth Dakota\n1\nMidwest\n-10.4\n-813.0\n4.338042\n-2.0237299\n6\nMULTIPOLYGON (((-104.0476 4…\n\n\nMN\nMinnesota\n1\nMidwest\n2.3\n15378.0\n8.338042\n3.3762701\n17\nMULTIPOLYGON (((-97.22609 4…\n\n\nMI\nMichigan\n1\nMidwest\n3.8\n2966.0\n3.838042\n-2.2237299\n34\nMULTIPOLYGON (((-84.4913 46…\n\n\n\n\n\n\n\nstate_summary |&gt; select(state, count) |&gt; filter(state == 'WA')\n\nAdding missing grouping variables: `political_value_index`, `median_income`,\n`hs_grad_rate`\n\n\n\n\n\n\npolitical_value_index\nmedian_income\nhs_grad_rate\nstate\ncount\n\n\n\n\n5\n9907.5\n7.538042\nWA\n9",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#choropleth",
    "href": "w5-idx.html#choropleth",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "Choropleth",
    "text": "Choropleth\n\nplot_sf |&gt; mapview(zcol = 'count', label = 'gn_name')\n\n\n\n\n\n\nplot_sf |&gt; filter(is.na(count))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npostal\ngn_name\ngadm_level\nregion\npolitical_value_index\nmedian_income\nhs_grad_rate\ncollege_grad_rate\ncount\ngeometry\n\n\n\n\nTX\nTexas\n1\nSouth\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-103.3115 2…\n\n\nDC\nDistrict of Columbia\n1\nSouth\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-77.02293 3…\n\n\nHI\nHawaii\n1\nWest\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-154.8996 1…\n\n\nNV\nNevada\n1\nWest\nNA\nNA\nNA\nNA\nNA\nMULTIPOLYGON (((-114.0425 4…",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "w5-idx.html#ggplot-plot-with-more-controls",
    "href": "w5-idx.html#ggplot-plot-with-more-controls",
    "title": "R Coding Workshop: 3rd Meeting",
    "section": "ggplot plot with more controls",
    "text": "ggplot plot with more controls\n\nplot_sf |&gt; ggplot() + geom_sf(aes(fill = count), color = 'white', size = 0.01) + scale_fill_viridis() + theme_bw()",
    "crumbs": [
      "Coding Workshop",
      "Week 5"
    ]
  },
  {
    "objectID": "slides.html#r-coding-workshop-2nd-meeting",
    "href": "slides.html#r-coding-workshop-2nd-meeting",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "R Coding Workshop: 2nd Meeting",
    "text": "R Coding Workshop: 2nd Meeting"
  },
  {
    "objectID": "slides.html#outline",
    "href": "slides.html#outline",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Outline",
    "text": "Outline\n\nRecap\nR Operators\nImport files\nSubsetting a Data Frame\n\nBase R advanced:\n\ntapply()\nsample()\n\nThe Tidyverse approach: dplyr package"
  },
  {
    "objectID": "slides.html#recap",
    "href": "slides.html#recap",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Recap",
    "text": "Recap\n\nName your Variables smartly and annotate your code with comments\n\n\nName your variables as nouns1\nlowercase, concatenate with underscores _\nConcise and Meaningful\nrm() command\n\n\nprint() , class() and mapview()\nR Data Types and Data Structures\n\nfunctions should take on verbs as their names"
  },
  {
    "objectID": "slides.html#r-operators",
    "href": "slides.html#r-operators",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "R Operators",
    "text": "R Operators\nTry them out:\n\n\nArithmetic Operators\n\n+ - * / ^\n\n\nComparison Operators\n\n&gt; &lt;\n==\n!=\n\n\nOther Binary Operators\n\n&\n|\n!\n%in%\n\n\n\\(\\sqrt{x^2 + y^2}\\)\n\nx &lt;- 3\ny &lt;- 4\nprint((x^2 + y^2)^(1/2))\n\n[1] 5\n\n\n\\(mile = kilometer * 0.62137\\)\n\nprint((3000 * 0.62137))\n\n[1] 1864.11\n\nprint((3000 * 0.62137) * 1.609344)\n\n[1] 2999.994\n\n\n\n# | code-fold: true\n# install.packages('measurements')\nlibrary(measurements)\nconv_unit(3000, 'km', 'mi')\n\n[1] 1864.114\n\n\n\n\n\n\nR Binary Operators\n\n\nBinary operators in R: Be aware of the left hand side and the right hand side of binary operators.\nVector Recycling\n\nvector1 &lt;- 1:5\nprint(vector1)\n\n[1] 1 2 3 4 5\n\nprint(vector1 + 1)\n\n[1] 2 3 4 5 6\n\nprint(vector1 * 1.609344)\n\n[1] 1.609344 3.218688 4.828032 6.437376 8.046720\n\n\nThis helps us make sense of the following evaluation:\n\nprint(vector1 &gt; 3)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n\n\n\n\n\n\n# vector1 &lt;- 1:5\nprint(vector1 != 3)\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n\n\n'capitol' == 'CAPITOL'\n\n[1] FALSE\n\n\n\n# ascii or utf8\nprint('&gt;' &lt; '0')\n\n[1] FALSE\n\nprint('a' &lt; 'A')\n\n[1] FALSE\n\n\n\nus_states &lt;- state.abb\nmidwest_states &lt;- c(\n  \"IL\", \"IN\", \"MI\", \"OH\", \"WI\",\"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"\n)\nus_states %in% midwest_states\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[25]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49]  TRUE FALSE\n\n\n\nus_states &lt;- state.abb\nmidwest_states &lt;- c(\n  \"IL\", \"IN\", \"MI\", \"OH\",\n  \"WI\", \"IA\", \"KS\", \"MN\",\n  \"MO\", \"NE\", \"ND\", \"SD\"\n)\nprint(is.vector(midwest_states))\n\n[1] TRUE\n\n!is.vector(midwest_states)\n\n[1] FALSE\n\n\n\nus_states %in% midwest_states\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[25]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49]  TRUE FALSE\n\n\nwhat happened here?\n\ndouble_vector &lt;- seq(21.9, 25.3, 0.1)\nint_vector &lt;- 20L:26L\ndouble_vector %in% int_vector\n\n [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE"
  },
  {
    "objectID": "slides.html#import-and-export-files",
    "href": "slides.html#import-and-export-files",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Import and Export Files",
    "text": "Import and Export Files"
  },
  {
    "objectID": "slides.html#subsetting-data.frame-continued",
    "href": "slides.html#subsetting-data.frame-continued",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Subsetting data.frame Continued",
    "text": "Subsetting data.frame Continued\nWe want to extract or access certain rows or columns of our dataframe.\n\nutah_df &lt;- data.frame(\n    national_park = c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    ),\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\nutah_df\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n2   Canyonlands 38.47878 -109.8252\n3        Arches 38.61676 -109.6198\n4          Zion 37.20027 -112.9870\n5  Capitol Reef 38.29160 -111.2619"
  },
  {
    "objectID": "slides.html#tapply-advanced-way-for-data-subsetting",
    "href": "slides.html#tapply-advanced-way-for-data-subsetting",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "tapply(): Advanced way for data subsetting",
    "text": "tapply(): Advanced way for data subsetting\n\n\n\n\nDemo Dataset Description\n\n\nVariable Documentation \n\n\n\n\n\n# install.packages('bayesrules')\n# import bayesrules package and \nlibrary(bayesrules)\n\n# bookban_df &lt;- bayesrules::book_banning\nbookban_df &lt;- book_banning\n# print(head(bookban_df))\nsummary(bookban_df)\n\n    title              book_id       author               date           \n Length:931         143    : 17   Length:931         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):868                      NA's   :11          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:714   0:632    0:891      0:895   0:694    0:842   0:797  \n 1st Qu.:2002   1:217   1:299    1: 40      1: 36   1:237    1: 89   1:134  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n NA's   :11                                                                 \n    state           political_value_index median_income    hs_grad_rate   \n Length:931         Min.   :-20.2000      Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -1.8000      1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.0000      Median : 4218   Median : 2.338  \n                    Mean   :  0.0304      Mean   : 4530   Mean   : 2.833  \n                    3rd Qu.:  4.0000      3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.4000      Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-2.0237  \n Median : 0.2763  \n Mean   : 0.6043  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763  \n                  \n\n\n\nask your data questions:\n\n\ntapply(\n    bookban_df$removed == '1',\n    bookban_df$state,\n    mean\n    )\n\n        AK         AL         AR         AZ         CA         CO         CT \n0.11111111 0.50000000 0.00000000 0.41666667 0.32000000 0.12345679 0.16666667 \n        DE         FL         GA         IA         ID         IL         IN \n0.50000000 0.30769231 0.30769231 0.25000000 0.85714286 0.30769231 0.30000000 \n        KS         KY         LA         MA         MD         ME         MI \n0.76923077 0.15384615 0.41666667 0.37500000 0.00000000 0.00000000 0.19444444 \n        MN         MO         MS         MT         NC         ND         NE \n0.05555556 0.72727273 1.00000000 0.00000000 0.20000000 0.33333333 0.00000000 \n        NH         NJ         NM         NY         OH         OK         OR \n0.28571429 0.18181818 0.66666667 0.44000000 0.34482759 0.34782609 0.04237288 \n        PA         RI         SC         SD         TN         UT         VA \n0.07432432 0.33333333 0.40000000 0.33333333 0.38461538 0.00000000 0.52941176 \n        VT         WA         WI         WV         WY \n0.00000000 0.33333333 0.30000000 0.00000000 0.25000000 \n\n\nThe data science question that is asked here: What fraction of book challenges were successful in each state?\n\nThe first argument: specify the variable we are interested in which is the books that their remove request were approved\nThe 2nd argument: how we want to group our data, often for the purpose of comparison, and this case we naturally want to compare between states.\nThe 3rd argument: takes a function, which is the operation that we want to apply to our variable of interest, here it is the mean() function for acquiring the fraction of approved request.\n\n\n\n\n\nR factor\n\n\nAs we have observed, the bookban_df$removed, removed column is of factor data type, taking on values ‘0’ and ‘1’. And by making the comparison (add == 1), we get a logical vector of TRUE(1) and FALSE(0) which can be treated as 1 and 0 correspondingly, which mean() can operate on.\n\n\n\n\nWhat are we trying to ask for the following two code blocks?\n\ntapply(\n    bookban_df$political_value_ind,\n    bookban_df$lgbtq,\n    mean)\n\n        0         1 \n 0.102019 -0.647191 \n\n\n\ntapply(bookban_df$title, bookban_df$state, length)\n\n AK  AL  AR  AZ  CA  CO  CT  DE  FL  GA  IA  ID  IL  IN  KS  KY  LA  MA  MD  ME \n  9  10   5  12  50  81   6   2  26  13  16  14  39  20  13  13  12   8   5   3 \n MI  MN  MO  MS  MT  NC  ND  NE  NH  NJ  NM  NY  OH  OK  OR  PA  RI  SC  SD  TN \n 36  18  11   1   8  20   6   2   7  11   3  25  29  23 118 148   3  15   3  13 \n UT  VA  VT  WA  WI  WV  WY \n  1  34  13   9  10   3   4"
  },
  {
    "objectID": "slides.html#tidyverse",
    "href": "slides.html#tidyverse",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Tidyverse",
    "text": "Tidyverse\n\ntidyverse is a selection of R packages, by running the following import code, we can have most of the packages that we will use to do data analysis\nAmong them, dplyr and ggplot2 will be used for almost all of the upcoming assignments\n\n\nlibrary(tidyverse)\n\n|&gt;: meet the pipeline operator\n\nbookban_df |&gt; select(date) |&gt; pull(date) |&gt; class()\n\n[1] \"Date\"\n\n\n\nbookban_df['date']$date |&gt; class()\n\n[1] \"Date\""
  },
  {
    "objectID": "slides.html#the-tidyverse-way-of-initializing-data-frames",
    "href": "slides.html#the-tidyverse-way-of-initializing-data-frames",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "The Tidyverse way of initializing data frames",
    "text": "The Tidyverse way of initializing data frames\n\n\n\nutah_df &lt;- data.frame(\n    national_park = c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    ),\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\nutah_df\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n2   Canyonlands 38.47878 -109.8252\n3        Arches 38.61676 -109.6198\n4          Zion 37.20027 -112.9870\n5  Capitol Reef 38.29160 -111.2619\n\n\n\n\nutah_tribble &lt;- tibble::tribble(\n    ~national_park, ~lat, ~lon,\n    \"Bryce Canyon\", 37.640621053549125, -112.16957627116382,\n    \"Canyonlands\", 38.478777627059635, -109.8251716515892,\n    \"Arches\", 38.6167568289248, -109.61982474559946,\n    \"Zion\", 37.200271934321734, -112.98700616100083,\n    \"Capitol Reef\", 38.291603924096385, -111.2619347149233\n)\nutah_tribble\n\n# A tibble: 5 × 3\n  national_park   lat   lon\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 Bryce Canyon   37.6 -112.\n2 Canyonlands    38.5 -110.\n3 Arches         38.6 -110.\n4 Zion           37.2 -113.\n5 Capitol Reef   38.3 -111."
  },
  {
    "objectID": "slides.html#why-tibble-object",
    "href": "slides.html#why-tibble-object",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Why tibble object?",
    "text": "Why tibble object?\n\nTry uncomment the first line of the code!\n\n\n# print(bookban_df)\n\nas_tibble(bookban_df)\n\n# A tibble: 931 × 17\n   title      book_id author date        year removed explicit antifamily occult\n   &lt;chr&gt;      &lt;fct&gt;   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;      &lt;fct&gt; \n 1 House of … 927     Allen… 2005-04-01  2005 0       1        0          1     \n 2 It's Not … 1024    Harri… 2008-02-06  2008 1       0        0          0     \n 3 King Stork 1087    Pyle,… 2008-10-02  2008 0       0        0          0     \n 4 How They … 936     Levit… 2008-10-05  2008 0       0        0          0     \n 5 Ghost in … 764     Masam… 2008-10-02  2008 0       0        0          0     \n 6 King Stork 1087    Pyle,… 2003-09-13  2003 0       0        0          0     \n 7 Queer      1489    Gage,… 2003-09-13  2003 0       0        0          0     \n 8 Witness    2023    Hesse… 2003-09-13  2003 0       0        0          0     \n 9 It's Perf… 1025    Harri… 2001-12-22  2001 0       1        0          0     \n10 Brimstone… 318     Koert… 2006-01-30  2006 1       0        1          0     \n# ℹ 921 more rows\n# ℹ 8 more variables: language &lt;fct&gt;, lgbtq &lt;fct&gt;, violent &lt;fct&gt;, state &lt;chr&gt;,\n#   political_value_index &lt;dbl&gt;, median_income &lt;dbl&gt;, hs_grad_rate &lt;dbl&gt;,\n#   college_grad_rate &lt;dbl&gt;\n\n\n\ntibble object print the data type of each column by default"
  },
  {
    "objectID": "slides.html#dplyr",
    "href": "slides.html#dplyr",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "dplyr",
    "text": "dplyr\nselect(): subset by column name\n\ntip: uncomment the following code block in Positron to acquire a copiable vector of all the column names of your dataset\n\n\n# bookban_df |&gt; colnames() |&gt; View()\n\n\nor\n\n\nvarnames &lt;- c(\"title\", \"book_id\", \"author\", \"date\", \"year\", \"removed\", \"explicit\", \n\"antifamily\", \"occult\", \"language\", \"lgbtq\", \"violent\", \"state\", \n\"political_value_index\", \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n)\n\nSometimes, we are not interested in all the given variables\n\nstate_level_vars &lt;- c( \n\"political_value_index\", \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n)\n\n\nbookban_df |&gt; select(-any_of(state_level_vars)) |&gt; tail(4)\n\n                        title book_id                               author\n928       When Dad Killed Mom    1964                       Lester, Julius\n929         Geology Book, The     755                  Morris, Dr. John D.\n930     And Tango Makes Three     143 Parnell, Peter and Justin Richardson\n931 Darkest Night of the Year     505                         Koontz, Dean\n          date year removed explicit antifamily occult language lgbtq violent\n928 2002-04-21 2002       1        0          0      0        0     0       1\n929 2010-05-05 2010       0        0          0      0        0     0       0\n930 2009-08-22 2009       0        0          0      0        0     1       0\n931 2007-12-03 2007       0        1          0      0        0     0       0\n    state\n928    WY\n929    WY\n930    WY\n931    WY\n\n\n\nBeing mindful of the data type after subsetting\n\n\nbookban_df |&gt; select(title) |&gt; class()\n\n[1] \"data.frame\"\n\n\n\nbookban_df[, 'title'] |&gt; class()\n\n[1] \"character\""
  },
  {
    "objectID": "slides.html#dplyr-1",
    "href": "slides.html#dplyr-1",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "dplyr",
    "text": "dplyr\nfilter(): keep rows that match our criteria\nWe might have a particular interest in Wisconsin\n\nbookban_df |&gt; filter(state == 'WI')\n\n                                                                   title\n1                                               Lords of Discipline, The\n2                                                                 Damage\n3                                                        Athletic Shorts\n4                                                            Teens & Sex\n5  Doing It Right:  Making Smart, Safe, and Satisfying Choices About Sex\n6                                                          Carry Me Down\n7                                                   Grapes of Wrath, The\n8                                                                   TTYL\n9                                                  It's Perfectly Normal\n10                                                 Harry Potter (series)\n   book_id          author       date year removed explicit antifamily occult\n1     1177     Conroy, Pat 2002-11-16 2002       1        1          0      0\n2      487    Jenkis, A.M. 2009-11-18 2009       0        1          0      0\n3      171 Crutcher, Chris 2006-10-10 2006       1        0          0      0\n4     1766  Marcovitz, Hal 2010-03-20 2010       0        1          0      0\n5      560 Pardes, Bronwen 2010-03-20 2010       0        1          0      0\n6      361    Hyland, M.J. 2007-07-22 2007       0        0          0      0\n7      745 Steinbeck, John 2003-07-14 2003       1        0          0      0\n8     1849 Myracle, Lauren 2009-02-25 2009       0        1          0      0\n9     1025   Harris, Robie 2001-09-22 2001       0        0          0      0\n10     868   Rowling, J.K. 2000-09-30 2000       0        0          0      1\n   language lgbtq violent state political_value_index median_income\n1         1     0       1    WI                   2.4        4234.5\n2         0     0       0    WI                   2.4        4234.5\n3         1     1       0    WI                   2.4        4234.5\n4         0     0       0    WI                   2.4        4234.5\n5         0     0       0    WI                   2.4        4234.5\n6         0     0       1    WI                   2.4        4234.5\n7         1     0       0    WI                   2.4        4234.5\n8         0     0       0    WI                   2.4        4234.5\n9         0     0       0    WI                   2.4        4234.5\n10        0     0       0    WI                   2.4        4234.5\n   hs_grad_rate college_grad_rate\n1      5.538042          -1.62373\n2      5.538042          -1.62373\n3      5.538042          -1.62373\n4      5.538042          -1.62373\n5      5.538042          -1.62373\n6      5.538042          -1.62373\n7      5.538042          -1.62373\n8      5.538042          -1.62373\n9      5.538042          -1.62373\n10     5.538042          -1.62373\n\n\n\n# bookban_df[bookban_df$state != \"WI\", ]"
  },
  {
    "objectID": "slides.html#data-cleaning",
    "href": "slides.html#data-cleaning",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nbookban_df |&gt; filter(year &gt; 2004) |&gt; dim()\n\n[1] 515  17\n\n\n\nbookban_df[bookban_df$year &gt; 2004, ] |&gt; dim()\n\n[1] 526  17\n\n\nWhat happened?\n\nwe have missing values in the **year* column\n\ncount(): result in a new dataframe with the distribution of the values that a given column takes on\n\nbookban_df |&gt; count(year)\n\n   year   n\n1  2000  71\n2  2001 111\n3  2002  52\n4  2003  88\n5  2004  83\n6  2005  52\n7  2006  54\n8  2007  38\n9  2008 122\n10 2009 197\n11 2010  52\n12   NA  11"
  },
  {
    "objectID": "idx.html#outline",
    "href": "idx.html#outline",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Outline",
    "text": "Outline\n\nRecap\nR Operators\nImport files\nSubsetting a Data Frame\n\nBase R advanced:\n\ntapply()\nsample()\n\nThe Tidyverse approach: dplyr package",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#recap",
    "href": "idx.html#recap",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Recap",
    "text": "Recap\n\nName your Variables smartly and annotate your code with comments\n\n\nName your variables as nouns1\nlowercase, concatenate with underscores _\nConcise and Meaningful\nrm() command\n\n\nprint() , class() and mapview()\nR Data Types and Data Structures",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#r-operators",
    "href": "idx.html#r-operators",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "R Operators",
    "text": "R Operators\nTry them out:\n\n\n\nArithmetic Operators\n\n+ - * / ^\n\n\n\n\nComparison Operators\n\n&gt; &lt;\n==\n!=\n\n\n\n\nOther Binary Operators\n\n&\n|\n!\n%in%\n\n\n\n\n\\(\\sqrt{x^2 + y^2}\\)\n\nx &lt;- 3\ny &lt;- 4\nprint((x^2 + y^2)^(1/2))\n\n[1] 5\n\n\n\\(mile = kilometer * 0.62137\\)\n\nprint((3000 * 0.62137))\n\n[1] 1864.11\n\nprint((3000 * 0.62137) * 1.609344)\n\n[1] 2999.994\n\n\n\n# | code-fold: true\n# install.packages('measurements')\nlibrary(measurements)\nconv_unit(3000, 'km', 'mi')\n\n[1] 1864.114\n\n\n\n\n\n\n\n\nR Binary Operators\n\n\n\nBinary operators in R: Be aware of the left hand side and the right hand side of binary operators.\nVector Recycling\n\nvector1 &lt;- 1:5\nprint(vector1)\n\n[1] 1 2 3 4 5\n\nprint(vector1 + 1)\n\n[1] 2 3 4 5 6\n\nprint(vector1 * 1.609344)\n\n[1] 1.609344 3.218688 4.828032 6.437376 8.046720\n\n\nThis helps us make sense of the following evaluation:\n\nprint(vector1 &gt; 3)\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n\n\n\n\n# vector1 &lt;- 1:5\nprint(vector1 != 3)\n\n[1]  TRUE  TRUE FALSE  TRUE  TRUE\n\n\n\n'capitol' == 'CAPITOL'\n\n[1] FALSE\n\n\n\n# ascii or utf8\nprint('&gt;' &lt; '0')\n\n[1] FALSE\n\nprint('a' &lt; 'A')\n\n[1] FALSE\n\n\n\nus_states &lt;- state.abb\nmidwest_states &lt;- c(\n  \"IL\", \"IN\", \"MI\", \"OH\", \"WI\",\"IA\", \"KS\", \"MN\", \"MO\", \"NE\", \"ND\", \"SD\"\n)\nus_states %in% midwest_states\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[25]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49]  TRUE FALSE\n\n\n\nus_states &lt;- state.abb\nmidwest_states &lt;- c(\n  \"IL\", \"IN\", \"MI\", \"OH\",\n  \"WI\", \"IA\", \"KS\", \"MN\",\n  \"MO\", \"NE\", \"ND\", \"SD\"\n)\nprint(is.vector(midwest_states))\n\n[1] TRUE\n\n!is.vector(midwest_states)\n\n[1] FALSE\n\n\n\nus_states %in% midwest_states\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[25]  TRUE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE\n[37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[49]  TRUE FALSE\n\n\nwhat happened here?\n\ndouble_vector &lt;- seq(21.9, 25.3, 0.1)\nint_vector &lt;- 20L:26L\ndouble_vector %in% int_vector\n\n [1] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#import-and-export-files",
    "href": "idx.html#import-and-export-files",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Import and Export Files",
    "text": "Import and Export Files",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#subsetting-data.frame-continued",
    "href": "idx.html#subsetting-data.frame-continued",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Subsetting data.frame Continued",
    "text": "Subsetting data.frame Continued\nWe want to extract or access certain rows or columns of our dataframe.\n\nutah_df &lt;- data.frame(\n    national_park = c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    ),\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\nutah_df\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n2   Canyonlands 38.47878 -109.8252\n3        Arches 38.61676 -109.6198\n4          Zion 37.20027 -112.9870\n5  Capitol Reef 38.29160 -111.2619",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#tapply-advanced-way-for-data-subsetting",
    "href": "idx.html#tapply-advanced-way-for-data-subsetting",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "tapply(): Advanced way for data subsetting",
    "text": "tapply(): Advanced way for data subsetting\n\n\n\n\n\n\nDemo Dataset Description\n\n\n\nVariable Documentation \n\n\n\n# install.packages('bayesrules')\n# import bayesrules package and \nlibrary(bayesrules)\n\n# bookban_df &lt;- bayesrules::book_banning\nbookban_df &lt;- book_banning\n# print(head(bookban_df))\nsummary(bookban_df)\n\n    title              book_id       author               date           \n Length:931         143    : 17   Length:931         Min.   :2000-01-01  \n Class :character   868    : 12   Class :character   1st Qu.:2002-11-16  \n Mode  :character   1849   : 10   Mode  :character   Median :2006-02-10  \n                    1025   :  9                      Mean   :2005-12-16  \n                    1083   :  8                      3rd Qu.:2009-03-18  \n                    399    :  7                      Max.   :2010-09-09  \n                    (Other):868                      NA's   :11          \n      year      removed explicit antifamily occult  language lgbtq   violent\n Min.   :2000   0:714   0:632    0:891      0:895   0:694    0:842   0:797  \n 1st Qu.:2002   1:217   1:299    1: 40      1: 36   1:237    1: 89   1:134  \n Median :2006                                                               \n Mean   :2005                                                               \n 3rd Qu.:2009                                                               \n Max.   :2010                                                               \n NA's   :11                                                                 \n    state           political_value_index median_income    hs_grad_rate   \n Length:931         Min.   :-20.2000      Min.   :-8466   Min.   :-6.662  \n Class :character   1st Qu.: -1.8000      1st Qu.: 1274   1st Qu.: 1.038  \n Mode  :character   Median :  2.0000      Median : 4218   Median : 2.338  \n                    Mean   :  0.0304      Mean   : 4530   Mean   : 2.833  \n                    3rd Qu.:  4.0000      3rd Qu.: 9908   3rd Qu.: 5.538  \n                    Max.   : 13.4000      Max.   :19936   Max.   : 8.738  \n                                                                          \n college_grad_rate\n Min.   :-9.2237  \n 1st Qu.:-2.0237  \n Median : 0.2763  \n Mean   : 0.6043  \n 3rd Qu.: 2.5763  \n Max.   : 9.1763  \n                  \n\n\n\nask your data questions:\n\n\ntapply(\n    bookban_df$removed == '1',\n    bookban_df$state,\n    mean\n    )\n\n        AK         AL         AR         AZ         CA         CO         CT \n0.11111111 0.50000000 0.00000000 0.41666667 0.32000000 0.12345679 0.16666667 \n        DE         FL         GA         IA         ID         IL         IN \n0.50000000 0.30769231 0.30769231 0.25000000 0.85714286 0.30769231 0.30000000 \n        KS         KY         LA         MA         MD         ME         MI \n0.76923077 0.15384615 0.41666667 0.37500000 0.00000000 0.00000000 0.19444444 \n        MN         MO         MS         MT         NC         ND         NE \n0.05555556 0.72727273 1.00000000 0.00000000 0.20000000 0.33333333 0.00000000 \n        NH         NJ         NM         NY         OH         OK         OR \n0.28571429 0.18181818 0.66666667 0.44000000 0.34482759 0.34782609 0.04237288 \n        PA         RI         SC         SD         TN         UT         VA \n0.07432432 0.33333333 0.40000000 0.33333333 0.38461538 0.00000000 0.52941176 \n        VT         WA         WI         WV         WY \n0.00000000 0.33333333 0.30000000 0.00000000 0.25000000 \n\n\nThe data science question that is asked here: What fraction of book challenges were successful in each state?\n\nThe first argument: specify the variable we are interested in which is the books that their remove request were approved\nThe 2nd argument: how we want to group our data, often for the purpose of comparison, and this case we naturally want to compare between states.\nThe 3rd argument: takes a function, which is the operation that we want to apply to our variable of interest, here it is the mean() function for acquiring the fraction of approved request.\n\n\n\n\n\n\n\nR factor\n\n\n\nAs we have observed, the bookban_df$removed, removed column is of factor data type, taking on values ‘0’ and ‘1’. And by making the comparison (add == 1), we get a logical vector of TRUE(1) and FALSE(0) which can be treated as 1 and 0 correspondingly, which mean() can operate on.\n\n\nWhat are we trying to ask for the following two code blocks?\n\ntapply(\n    bookban_df$political_value_ind,\n    bookban_df$lgbtq,\n    mean)\n\n        0         1 \n 0.102019 -0.647191 \n\n\n\ntapply(bookban_df$title, bookban_df$state, length)\n\n AK  AL  AR  AZ  CA  CO  CT  DE  FL  GA  IA  ID  IL  IN  KS  KY  LA  MA  MD  ME \n  9  10   5  12  50  81   6   2  26  13  16  14  39  20  13  13  12   8   5   3 \n MI  MN  MO  MS  MT  NC  ND  NE  NH  NJ  NM  NY  OH  OK  OR  PA  RI  SC  SD  TN \n 36  18  11   1   8  20   6   2   7  11   3  25  29  23 118 148   3  15   3  13 \n UT  VA  VT  WA  WI  WV  WY \n  1  34  13   9  10   3   4",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#tidyverse",
    "href": "idx.html#tidyverse",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Tidyverse",
    "text": "Tidyverse\n\ntidyverse is a selection of R packages, by running the following import code, we can have most of the packages that we will use to do data analysis\nAmong them, dplyr and ggplot2 will be used for almost all of the upcoming assignments\n\n\nlibrary(tidyverse)\n\n\n|&gt;: meet the pipeline operator\n\nbookban_df |&gt; select(date) |&gt; pull(date) |&gt; class()\n\n[1] \"Date\"\n\n\n\nbookban_df['date']$date |&gt; class()\n\n[1] \"Date\"",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#the-tidyverse-way-of-initializing-data-frames",
    "href": "idx.html#the-tidyverse-way-of-initializing-data-frames",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "The Tidyverse way of initializing data frames",
    "text": "The Tidyverse way of initializing data frames\n\n\n\nutah_df &lt;- data.frame(\n    national_park = c(\n    \"Bryce Canyon\", \"Canyonlands\", \"Arches\", \"Zion\", \"Capitol Reef\"\n    ),\n    lat = c(\n        37.640621053549125, 38.478777627059635, 38.6167568289248,\n        37.200271934321734, 38.291603924096385\n        ),\n    lon = c(\n        -112.16957627116382, -109.8251716515892, -109.61982474559946, \n        -112.98700616100083, -111.2619347149233\n        )\n)\nutah_df\n\n  national_park      lat       lon\n1  Bryce Canyon 37.64062 -112.1696\n2   Canyonlands 38.47878 -109.8252\n3        Arches 38.61676 -109.6198\n4          Zion 37.20027 -112.9870\n5  Capitol Reef 38.29160 -111.2619\n\n\n\n\nutah_tribble &lt;- tibble::tribble(\n    ~national_park, ~lat, ~lon,\n    \"Bryce Canyon\", 37.640621053549125, -112.16957627116382,\n    \"Canyonlands\", 38.478777627059635, -109.8251716515892,\n    \"Arches\", 38.6167568289248, -109.61982474559946,\n    \"Zion\", 37.200271934321734, -112.98700616100083,\n    \"Capitol Reef\", 38.291603924096385, -111.2619347149233\n)\nutah_tribble\n\n# A tibble: 5 × 3\n  national_park   lat   lon\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt;\n1 Bryce Canyon   37.6 -112.\n2 Canyonlands    38.5 -110.\n3 Arches         38.6 -110.\n4 Zion           37.2 -113.\n5 Capitol Reef   38.3 -111.",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#why-tibble-object",
    "href": "idx.html#why-tibble-object",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Why tibble object?",
    "text": "Why tibble object?\n\nTry uncomment the first line of the code!\n\n\n# print(bookban_df)\n\nas_tibble(bookban_df)\n\n# A tibble: 931 × 17\n   title      book_id author date        year removed explicit antifamily occult\n   &lt;chr&gt;      &lt;fct&gt;   &lt;chr&gt;  &lt;date&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt;    &lt;fct&gt;      &lt;fct&gt; \n 1 House of … 927     Allen… 2005-04-01  2005 0       1        0          1     \n 2 It's Not … 1024    Harri… 2008-02-06  2008 1       0        0          0     \n 3 King Stork 1087    Pyle,… 2008-10-02  2008 0       0        0          0     \n 4 How They … 936     Levit… 2008-10-05  2008 0       0        0          0     \n 5 Ghost in … 764     Masam… 2008-10-02  2008 0       0        0          0     \n 6 King Stork 1087    Pyle,… 2003-09-13  2003 0       0        0          0     \n 7 Queer      1489    Gage,… 2003-09-13  2003 0       0        0          0     \n 8 Witness    2023    Hesse… 2003-09-13  2003 0       0        0          0     \n 9 It's Perf… 1025    Harri… 2001-12-22  2001 0       1        0          0     \n10 Brimstone… 318     Koert… 2006-01-30  2006 1       0        1          0     \n# ℹ 921 more rows\n# ℹ 8 more variables: language &lt;fct&gt;, lgbtq &lt;fct&gt;, violent &lt;fct&gt;, state &lt;chr&gt;,\n#   political_value_index &lt;dbl&gt;, median_income &lt;dbl&gt;, hs_grad_rate &lt;dbl&gt;,\n#   college_grad_rate &lt;dbl&gt;\n\n\n\ntibble object print the data type of each column by default",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#dplyr",
    "href": "idx.html#dplyr",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "dplyr",
    "text": "dplyr\nselect(): subset by column name\n\ntip: uncomment the following code block in Positron to acquire a copiable vector of all the column names of your dataset\n\n\n# bookban_df |&gt; colnames() |&gt; View()\n\n\nor\n\n\nvarnames &lt;- c(\"title\", \"book_id\", \"author\", \"date\", \"year\", \"removed\", \"explicit\", \n\"antifamily\", \"occult\", \"language\", \"lgbtq\", \"violent\", \"state\", \n\"political_value_index\", \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n)\n\nSometimes, we are not interested in all the given variables\n\nstate_level_vars &lt;- c( \n\"political_value_index\", \"median_income\", \"hs_grad_rate\", \"college_grad_rate\"\n)\n\n\nbookban_df |&gt; select(-any_of(state_level_vars)) |&gt; tail(4)\n\n                        title book_id                               author\n928       When Dad Killed Mom    1964                       Lester, Julius\n929         Geology Book, The     755                  Morris, Dr. John D.\n930     And Tango Makes Three     143 Parnell, Peter and Justin Richardson\n931 Darkest Night of the Year     505                         Koontz, Dean\n          date year removed explicit antifamily occult language lgbtq violent\n928 2002-04-21 2002       1        0          0      0        0     0       1\n929 2010-05-05 2010       0        0          0      0        0     0       0\n930 2009-08-22 2009       0        0          0      0        0     1       0\n931 2007-12-03 2007       0        1          0      0        0     0       0\n    state\n928    WY\n929    WY\n930    WY\n931    WY\n\n\n\nBeing mindful of the data type after subsetting\n\n\nbookban_df |&gt; select(title) |&gt; class()\n\n[1] \"data.frame\"\n\n\n\nbookban_df[, 'title'] |&gt; class()\n\n[1] \"character\"",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#dplyr-1",
    "href": "idx.html#dplyr-1",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "dplyr",
    "text": "dplyr\nfilter(): keep rows that match our criteria\nWe might have a particular interest in Wisconsin\n\nbookban_df |&gt; filter(state == 'WI')\n\n                                                                   title\n1                                               Lords of Discipline, The\n2                                                                 Damage\n3                                                        Athletic Shorts\n4                                                            Teens & Sex\n5  Doing It Right:  Making Smart, Safe, and Satisfying Choices About Sex\n6                                                          Carry Me Down\n7                                                   Grapes of Wrath, The\n8                                                                   TTYL\n9                                                  It's Perfectly Normal\n10                                                 Harry Potter (series)\n   book_id          author       date year removed explicit antifamily occult\n1     1177     Conroy, Pat 2002-11-16 2002       1        1          0      0\n2      487    Jenkis, A.M. 2009-11-18 2009       0        1          0      0\n3      171 Crutcher, Chris 2006-10-10 2006       1        0          0      0\n4     1766  Marcovitz, Hal 2010-03-20 2010       0        1          0      0\n5      560 Pardes, Bronwen 2010-03-20 2010       0        1          0      0\n6      361    Hyland, M.J. 2007-07-22 2007       0        0          0      0\n7      745 Steinbeck, John 2003-07-14 2003       1        0          0      0\n8     1849 Myracle, Lauren 2009-02-25 2009       0        1          0      0\n9     1025   Harris, Robie 2001-09-22 2001       0        0          0      0\n10     868   Rowling, J.K. 2000-09-30 2000       0        0          0      1\n   language lgbtq violent state political_value_index median_income\n1         1     0       1    WI                   2.4        4234.5\n2         0     0       0    WI                   2.4        4234.5\n3         1     1       0    WI                   2.4        4234.5\n4         0     0       0    WI                   2.4        4234.5\n5         0     0       0    WI                   2.4        4234.5\n6         0     0       1    WI                   2.4        4234.5\n7         1     0       0    WI                   2.4        4234.5\n8         0     0       0    WI                   2.4        4234.5\n9         0     0       0    WI                   2.4        4234.5\n10        0     0       0    WI                   2.4        4234.5\n   hs_grad_rate college_grad_rate\n1      5.538042          -1.62373\n2      5.538042          -1.62373\n3      5.538042          -1.62373\n4      5.538042          -1.62373\n5      5.538042          -1.62373\n6      5.538042          -1.62373\n7      5.538042          -1.62373\n8      5.538042          -1.62373\n9      5.538042          -1.62373\n10     5.538042          -1.62373\n\n\n\n# bookban_df[bookban_df$state != \"WI\", ]",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#data-cleaning",
    "href": "idx.html#data-cleaning",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nbookban_df |&gt; filter(year &gt; 2004) |&gt; dim()\n\n[1] 515  17\n\n\n\nbookban_df[bookban_df$year &gt; 2004, ] |&gt; dim()\n\n[1] 526  17\n\n\nWhat happened?\n\nwe have missing values in the **year* column\n\ncount(): result in a new dataframe with the distribution of the values that a given column takes on\n\nbookban_df |&gt; count(year)\n\n   year   n\n1  2000  71\n2  2001 111\n3  2002  52\n4  2003  88\n5  2004  83\n6  2005  52\n7  2006  54\n8  2007  38\n9  2008 122\n10 2009 197\n11 2010  52\n12   NA  11",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "idx.html#footnotes",
    "href": "idx.html#footnotes",
    "title": "R Coding Workshop: 2nd Meeting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nfunctions should take on verbs as their names↩︎",
    "crumbs": [
      "Coding Workshop",
      "Week 4"
    ]
  },
  {
    "objectID": "w6-demo-idx.html",
    "href": "w6-demo-idx.html",
    "title": "R Coding Workshop: Demo",
    "section": "",
    "text": "This demo is meant to provide a walkthrough that people might find relevant as they begin looking for potential datasets for their final project, especially in showing what steps to take when spatial data appears off during the EDA phase.\nFor illustration, I will be using the replication data for Steven Brooke and Neil Ketchley’s 2018 paper “Social and Institutional Origins of Political Islam” downloaded from dataverse (Brooke and Ketchley (2018))\nThe 2018 study associated the Muslim Brotherhood branches in Interwar Egypt (204 branches in 1937 and 238 in 1940) with the 4230 subdistricts from the 1937 census appendices. Therefore, each row, or a point, in this dataset represents a subdistrict, where there are variables such as population characteristics, presence of Muslim Brotherhood branches, presence of state railway stations, and other attributes that describes the subdistrict.1\n\n\nNow we get the sense that though we have data on subdistricts, yet the granularity for the spatial variable is only at administrative level 2 (disrict or qism)\nWe would like to start with understanding the unit of observation of our dataset, and we especially wanted to look into how these observations are represented spatially in the data that we have.\n\n\n\n\n\n\nNote\n\n\n\nEgypt subnational divisions\n\nGovernoratemuhafatha (administrative level 1)\nDistrict: Qism (level 2), 142 qisms\nSubdistrict: Subdistrict Name (level 3)2\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\n\nLe chargement a nécessité le package : viridisLite\n\n\n\neg_subdistrict_df &lt;- read_csv('data/mb-interwar-egypt-decoded.csv')\n\nRows: 4230 Columns: 40\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): muhafatha, qism, name\ndbl (37): mb_1940, mb_1937, total_population, male_total, male_foreigners, m...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\neg_subdistrict_df |&gt; dim() |&gt; print()\n\n[1] 4230   40\n\neg_subdistrict_df |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nAsyut\nAbnub\nGazirat Bahig\n0\n0\n3142\n1638\n0\n1543\n94\n1\n0\n1426\n78\n0\n1084\n169\n48\n150\n1271\n47\n1192\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nArab al-Atiyat al-bahriyya\n0\n0\n2151\n1188\n0\n1104\n84\n0\n0\n896\n67\n0\n795\n132\n2\n156\n940\n30\n837\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nDayr Bisra\n0\n0\n334\n181\n0\n0\n181\n0\n0\n0\n153\n0\n111\n4\n1\n65\n95\n5\n116\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nBani Murr\n0\n0\n3256\n1660\n0\n1343\n317\n0\n0\n1314\n282\n0\n920\n182\n16\n305\n1146\n82\n1278\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nQasr\n0\n0\n1628\n835\n0\n814\n21\n0\n0\n768\n25\n0\n600\n83\n45\n101\n664\n31\n672\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nSawalim Abnub\n0\n1\n1542\n790\n0\n750\n40\n0\n0\n710\n42\n0\n466\n15\n157\n236\n442\n88\n550\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\n\n\n\n\n\nmb_df &lt;- eg_subdistrict_df |&gt;\n  filter(mb_1940 + mb_1940 &gt; 0)\nmb_df |&gt; count(district_X) |&gt; dim()\n\n[1] 91  2\n\n\n\nset.seed(103)\neg_subdistrict_df |&gt; slice_sample(n = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nGharbiyya\nZifta\nZifta (dakhil al-kurdun) wa-kafr Inan\n1\n1\n23952\n11830\n90\n11097\n635\n98\n84\n11415\n611\n96\n2488\n1414\n847\n3937\n6102\n1345\n8979\n1\n0\n1043\n135686\n147987\n132\n18\n12\n3\n0\n156159\n1\n31.20618\n30.73269\n1\n0\n0\n0\n\n\nGiza\nGiza\nGazirat al-Dahab\n0\n0\n3523\n1686\n0\n1629\n57\n0\n0\n1783\n54\n0\n691\n207\n132\n221\n1250\n78\n1490\n0\n0\n1245\n134725\n115449\n124\n111\n152\n15\n0\n156390\n0\n29.40750\n31.17278\n0\n0\n0\n0\n\n\nGirga\nAkhmim\nSaqulta wa-l-Arab\n0\n0\n5342\n2747\n0\n2559\n188\n0\n1\n2437\n157\n1\n1393\n336\n729\n549\n1844\n133\n2055\n0\n0\n675\n106698\n94942\n0\n0\n0\n0\n0\n124663\n2\n31.71509\n26.62262\n0\n0\n0\n0\n\n\nGirga\nTima\nKum al-Hamid\n0\n0\n1030\n525\n0\n450\n75\n0\n0\n450\n55\n0\n354\n53\n68\n58\n404\n18\n435\n0\n0\n664\n113506\n101882\n12\n0\n2\n0\n0\n130843\n0\n31.42511\n26.86811\n0\n0\n0\n0\n\n\nBuhayra\nKum Hamada\nZawiyyat Firig\n0\n0\n2805\n1319\n0\n1173\n128\n18\n0\n1338\n131\n17\n360\n118\n180\n445\n719\n145\n1171\n1\n0\n863\n146628\n158766\n40\n11\n3\n0\n0\n165740\n0\n30.73368\n30.67402\n0\n0\n0\n0\n\n\nGiza\nAyyat\nZawiyyat Dahshur\n0\n0\n4679\n2407\n0\n2399\n8\n0\n0\n2265\n7\n0\n1533\n282\n245\n220\n1901\n87\n1868\n0\n0\n600\n128299\n117189\n10\n7\n3\n4\n0\n146866\n2\n31.24063\n29.57391\n0\n0\n0\n0\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(mb_1937 + mb_1940 &gt; 0) |&gt; dim()\n\n[1] 326  40\n\n\n\neg_subdistrict_df |&gt;\n  group_by(qism) |&gt;\n  summarize(\n    coords_count = n_distinct(district_X)\n  )\n\n\n\n\n\nqism\ncoords_count\n\n\n\n\nAbdin\n1\n\n\nAbnub\n1\n\n\nAbu Hummus\n1\n\n\nAbu Qurqas\n1\n\n\nAbu Tig\n1\n\n\nAbu al-Matamir\n1\n\n\nAga\n1\n\n\nAkhmim\n1\n\n\nAshmun\n1\n\n\nAswan\n1\n\n\nAsyut\n1\n\n\nAttarin\n1\n\n\nAyyat\n1\n\n\nAzbakiyya\n1\n\n\nBab al-Shariyya\n1\n\n\nBadari\n1\n\n\nBalyana\n1\n\n\nBandar Aswan\n1\n\n\nBandar Asyut\n1\n\n\nBandar Banha\n1\n\n\nBandar Bani Suwayf\n1\n\n\nBandar Damanhur\n1\n\n\nBandar Fayyum\n1\n\n\nBandar Giza\n1\n\n\nBandar Hulwan\n1\n\n\nBandar Mahalla al-Kubra\n1\n\n\nBandar Mansura\n1\n\n\nBandar Minya\n1\n\n\nBandar Qina\n1\n\n\nBandar Shibin al-Kum\n1\n\n\nBandar Suhag\n1\n\n\nBandar Tanta 1\n1\n\n\nBandar Tanta 2\n1\n\n\nBandar Zaqaziq\n1\n\n\nBanha\n1\n\n\nBani Mazar\n1\n\n\nBani Suwayf\n1\n\n\nBarrani\n1\n\n\nBiba\n1\n\n\nBilbays\n1\n\n\nBulaq\n1\n\n\nBurullus\n1\n\n\nDaba\n1\n\n\nDamanhur\n1\n\n\nDarb al-Ahmar\n1\n\n\nDawahi Misr\n1\n\n\nDayrut\n1\n\n\nDikirnis\n1\n\n\nDilingat\n1\n\n\nDishna\n1\n\n\nDisuq\n1\n\n\nDumyat\n1\n\n\nDurr\n1\n\n\nFaqus\n1\n\n\nFariskur\n1\n\n\nFashn\n1\n\n\nFayyum\n1\n\n\nFuwwa\n1\n\n\nGamaliyya\n1\n\n\nGhardaqa\n1\n\n\nGirga\n1\n\n\nGiza\n1\n\n\nGumruk\n1\n\n\nHammam\n1\n\n\nHihya\n1\n\n\nIbshaway\n1\n\n\nIdfu\n1\n\n\nImbaba\n1\n\n\nIsmailliyya\n1\n\n\nIsna\n1\n\n\nItsa\n1\n\n\nItyay al-Barud\n1\n\n\nKafr Saqr\n1\n\n\nKafr al-Dawwar\n1\n\n\nKafr al-Shaykh\n1\n\n\nKafr al-Zayyat\n1\n\n\nKarmuz\n1\n\n\nKhalifa\n1\n\n\nKhalig al-Suways\n1\n\n\nKum Hamada\n1\n\n\nLabban\n1\n\n\nMaghagha\n1\n\n\nMahalla al-Kubra\n1\n\n\nMahmudiyya\n1\n\n\nMallawi\n1\n\n\nManfalut\n1\n\n\nManshiyya\n1\n\n\nMansura\n1\n\n\nMantiqa al-Wusta\n1\n\n\nManzala\n1\n\n\nMarsa Matruh\n1\n\n\nMina\n1\n\n\nMina al-Basal\n1\n\n\nMinuf\n1\n\n\nMinya\n1\n\n\nMinya al-Qamh\n1\n\n\nMisr al-Gadida\n1\n\n\nMisr al-Qadima\n1\n\n\nMit Ghamr\n1\n\n\nMuharram bey\n1\n\n\nMuski\n1\n\n\nNag Hammadi\n1\n\n\nPort Said (qism 1)\n1\n\n\nQalyub\n1\n\n\nQantara sharq\n1\n\n\nQina\n1\n\n\nQism al-Sharq (Maryut)\n1\n\n\nQus\n1\n\n\nQusayr\n1\n\n\nQuwisna\n1\n\n\nRaml\n1\n\n\nRashid\n1\n\n\nSaff\n1\n\n\nSallum\n1\n\n\nSamallut\n1\n\n\nSamannud\n1\n\n\nSanta\n1\n\n\nSayyida Zaynab\n1\n\n\nShibin al-Kum\n1\n\n\nShibin al-Qanatir\n1\n\n\nShirbin\n1\n\n\nShubra gharb\n1\n\n\nShubra sharq\n1\n\n\nShubrakhit\n1\n\n\nSina al-mutawassit\n1\n\n\nSina al-shimali\n1\n\n\nSina“ al-ganubi\n1\n\n\nSinballawayn\n1\n\n\nSinuris\n1\n\n\nSiwa\n1\n\n\nSuhag\n1\n\n\nSuways\n1\n\n\nTahta\n1\n\n\nTala\n1\n\n\nTalkha\n1\n\n\nTanta\n1\n\n\nTima\n1\n\n\nTukh\n1\n\n\nUqsur (Luxor)\n1\n\n\nWahat al-bahriyya\n1\n\n\nWahat al-dakhla\n1\n\n\nWahat al-kharga\n1\n\n\nWasta\n1\n\n\nWayli\n1\n\n\nZaqaziq\n1\n\n\nZifta\n1\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(is.na(district_X))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nBahr al-Ahmar\nKhalig al-Suways\nZafarana (incl. GharibZaytiyyaDayr)\n0\n0\n214\n159\n6\n101\n52\n6\n2\n52\n0\n3\n15\n25\n1\n83\n68\n6\n39\n0\n0\n103\n698\nNA\n2\n5\n0\n1\n0\n764\n0\nNA\nNA\n0\n0\n0\n0\n\n\nBahr al-Ahmar\nKhalig al-Suways\nBi“r Udayb wa-l-Atka wa-ghubbat al-Bus wa-l-Gamasa\n0\n0\n550\n440\n4\n431\n5\n4\n0\n105\n4\n1\n52\n28\n0\n40\n369\n1\n92\n0\n0\n103\n698\nNA\n2\n5\n0\n1\n0\n764\n0\nNA\nNA\n0\n0\n0\n0\n\n\nBahr al-Ahmar\nMantiqa al-Wusta\nCairo-Suez Road\n0\n0\n143\n90\n0\n86\n4\n0\n0\n44\n9\n0\n2\n13\n0\n19\n57\n1\n40\n0\n0\n35\n117\nNA\n0\n0\n0\n0\n0\n143\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nWadi al-Natrun wa-l-Adyira wa-Bir Hukar\n0\n0\n2361\n1292\n6\n1209\n74\n9\n6\n1064\n0\n5\n117\n422\n4\n210\n917\n9\n908\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nAmiriyya\n0\n1\n1296\n645\n17\n634\n11\n0\n17\n639\n12\n0\n156\n149\n13\n210\n355\n26\n506\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nMirghib wa-Abd al-Qadir wa-Mikwariyya\n0\n0\n1421\n708\n7\n704\n4\n0\n7\n709\n4\n0\n436\n143\n37\n15\n592\n1\n606\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nIkingi Maryut wa-l-Dirisa\n0\n0\n746\n437\n2\n435\n0\n2\n0\n308\n0\n1\n188\n138\n12\n20\n358\n2\n257\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nUmm Zaghyu wa-Sidi Krir wa-l-Hawwariyya\n0\n0\n1170\n593\n0\n592\n1\n0\n0\n577\n0\n0\n388\n112\n1\n18\n498\n3\n504\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nAgami wa-l-Dira al-bahri wa-l Dayr\n0\n0\n704\n378\n0\n378\n0\n0\n0\n326\n0\n0\n239\n78\n8\n4\n314\n0\n281\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nBawiti\n0\n0\n1748\n924\n0\n916\n8\n0\n0\n820\n4\n0\n465\n174\n7\n138\n708\n8\n754\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nZabw\n0\n0\n794\n414\n0\n414\n0\n0\n0\n380\n0\n0\n242\n88\n0\n18\n342\n0\n325\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nFarafra\n0\n0\n674\n352\n0\n351\n1\n0\n0\n322\n0\n0\n222\n59\n4\n29\n273\n0\n278\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nQasr\n0\n0\n1504\n788\n0\n788\n0\n0\n0\n716\n0\n0\n418\n182\n9\n80\n597\n0\n584\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(qism == '\nQism al-Sharq (Maryut)') |&gt; filter(is.na(district_X))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\n\n\n\n\n\neg_subdistrict_sf &lt;- eg_subdistrict_df |&gt; filter(!is.na(district_X)) |&gt; st_as_sf(coords = c('district_X', 'district_Y'), crs = 4326)\neg_subdistrict_sf |&gt;\n  count(qism) |&gt;\n  mapview(label = 'muhafatha')\n\n\n\n\n\n\neg_subdistrict_sf |&gt; filter(muhafatha == 'al-Qahira') |&gt; count(name) |&gt; tail()\n\n\n\n\n\nname\nn\ngeometry\n\n\n\n\nZamalik al-qibliyya\n1\nPOINT (31.2451 30.04572)\n\n\nZawiyya al-Hamra\n1\nPOINT (31.24721 30.09319)\n\n\nZaynhum\n1\nPOINT (31.24251 30.03083)\n\n\nZaytun al-gharbiyya\n1\nPOINT (31.32245 30.08976)\n\n\nZaytun al-qibliyya\n1\nPOINT (31.32245 30.08976)\n\n\nZaytun al-sharqiyya\n1\nPOINT (31.32245 30.08976)\n\n\n\n\n\n\n\negypt_sf &lt;- ne_countries(country = 'Egypt', scale = 50) |&gt; select(geounit)",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#note-1-bringing-point-data-in-place",
    "href": "w6-demo-idx.html#note-1-bringing-point-data-in-place",
    "title": "R Coding Workshop: Demo",
    "section": "",
    "text": "This demo is meant to provide a walkthrough that people might find relevant as they begin looking for potential datasets for their final project, especially in showing what steps to take when spatial data appears off during the EDA phase.\nFor illustration, I will be using the replication data for Steven Brooke and Neil Ketchley’s 2018 paper “Social and Institutional Origins of Political Islam” downloaded from dataverse (Brooke and Ketchley (2018))\nThe 2018 study associated the Muslim Brotherhood branches in Interwar Egypt (204 branches in 1937 and 238 in 1940) with the 4230 subdistricts from the 1937 census appendices. Therefore, each row, or a point, in this dataset represents a subdistrict, where there are variables such as population characteristics, presence of Muslim Brotherhood branches, presence of state railway stations, and other attributes that describes the subdistrict.1\n\n\nNow we get the sense that though we have data on subdistricts, yet the granularity for the spatial variable is only at administrative level 2 (disrict or qism)\nWe would like to start with understanding the unit of observation of our dataset, and we especially wanted to look into how these observations are represented spatially in the data that we have.\n\n\n\n\n\n\nNote\n\n\n\nEgypt subnational divisions\n\nGovernoratemuhafatha (administrative level 1)\nDistrict: Qism (level 2), 142 qisms\nSubdistrict: Subdistrict Name (level 3)2\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(sf)\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\nlibrary(mapview)\nlibrary(rnaturalearth)\nlibrary(viridis)\n\nLe chargement a nécessité le package : viridisLite\n\n\n\neg_subdistrict_df &lt;- read_csv('data/mb-interwar-egypt-decoded.csv')\n\nRows: 4230 Columns: 40\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): muhafatha, qism, name\ndbl (37): mb_1940, mb_1937, total_population, male_total, male_foreigners, m...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\neg_subdistrict_df |&gt; dim() |&gt; print()\n\n[1] 4230   40\n\neg_subdistrict_df |&gt; head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nAsyut\nAbnub\nGazirat Bahig\n0\n0\n3142\n1638\n0\n1543\n94\n1\n0\n1426\n78\n0\n1084\n169\n48\n150\n1271\n47\n1192\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nArab al-Atiyat al-bahriyya\n0\n0\n2151\n1188\n0\n1104\n84\n0\n0\n896\n67\n0\n795\n132\n2\n156\n940\n30\n837\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nDayr Bisra\n0\n0\n334\n181\n0\n0\n181\n0\n0\n0\n153\n0\n111\n4\n1\n65\n95\n5\n116\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nBani Murr\n0\n0\n3256\n1660\n0\n1343\n317\n0\n0\n1314\n282\n0\n920\n182\n16\n305\n1146\n82\n1278\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nQasr\n0\n0\n1628\n835\n0\n814\n21\n0\n0\n768\n25\n0\n600\n83\n45\n101\n664\n31\n672\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\nAsyut\nAbnub\nSawalim Abnub\n0\n1\n1542\n790\n0\n750\n40\n0\n0\n710\n42\n0\n466\n15\n157\n236\n442\n88\n550\n0\n0\n603\n111199\n101206\n0\n0\n2\n0\n0\n127499\n0\n31.14603\n27.26193\n0\n0\n0\n0\n\n\n\n\n\n\n\nmb_df &lt;- eg_subdistrict_df |&gt;\n  filter(mb_1940 + mb_1940 &gt; 0)\nmb_df |&gt; count(district_X) |&gt; dim()\n\n[1] 91  2\n\n\n\nset.seed(103)\neg_subdistrict_df |&gt; slice_sample(n = 6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nGharbiyya\nZifta\nZifta (dakhil al-kurdun) wa-kafr Inan\n1\n1\n23952\n11830\n90\n11097\n635\n98\n84\n11415\n611\n96\n2488\n1414\n847\n3937\n6102\n1345\n8979\n1\n0\n1043\n135686\n147987\n132\n18\n12\n3\n0\n156159\n1\n31.20618\n30.73269\n1\n0\n0\n0\n\n\nGiza\nGiza\nGazirat al-Dahab\n0\n0\n3523\n1686\n0\n1629\n57\n0\n0\n1783\n54\n0\n691\n207\n132\n221\n1250\n78\n1490\n0\n0\n1245\n134725\n115449\n124\n111\n152\n15\n0\n156390\n0\n29.40750\n31.17278\n0\n0\n0\n0\n\n\nGirga\nAkhmim\nSaqulta wa-l-Arab\n0\n0\n5342\n2747\n0\n2559\n188\n0\n1\n2437\n157\n1\n1393\n336\n729\n549\n1844\n133\n2055\n0\n0\n675\n106698\n94942\n0\n0\n0\n0\n0\n124663\n2\n31.71509\n26.62262\n0\n0\n0\n0\n\n\nGirga\nTima\nKum al-Hamid\n0\n0\n1030\n525\n0\n450\n75\n0\n0\n450\n55\n0\n354\n53\n68\n58\n404\n18\n435\n0\n0\n664\n113506\n101882\n12\n0\n2\n0\n0\n130843\n0\n31.42511\n26.86811\n0\n0\n0\n0\n\n\nBuhayra\nKum Hamada\nZawiyyat Firig\n0\n0\n2805\n1319\n0\n1173\n128\n18\n0\n1338\n131\n17\n360\n118\n180\n445\n719\n145\n1171\n1\n0\n863\n146628\n158766\n40\n11\n3\n0\n0\n165740\n0\n30.73368\n30.67402\n0\n0\n0\n0\n\n\nGiza\nAyyat\nZawiyyat Dahshur\n0\n0\n4679\n2407\n0\n2399\n8\n0\n0\n2265\n7\n0\n1533\n282\n245\n220\n1901\n87\n1868\n0\n0\n600\n128299\n117189\n10\n7\n3\n4\n0\n146866\n2\n31.24063\n29.57391\n0\n0\n0\n0\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(mb_1937 + mb_1940 &gt; 0) |&gt; dim()\n\n[1] 326  40\n\n\n\neg_subdistrict_df |&gt;\n  group_by(qism) |&gt;\n  summarize(\n    coords_count = n_distinct(district_X)\n  )\n\n\n\n\n\nqism\ncoords_count\n\n\n\n\nAbdin\n1\n\n\nAbnub\n1\n\n\nAbu Hummus\n1\n\n\nAbu Qurqas\n1\n\n\nAbu Tig\n1\n\n\nAbu al-Matamir\n1\n\n\nAga\n1\n\n\nAkhmim\n1\n\n\nAshmun\n1\n\n\nAswan\n1\n\n\nAsyut\n1\n\n\nAttarin\n1\n\n\nAyyat\n1\n\n\nAzbakiyya\n1\n\n\nBab al-Shariyya\n1\n\n\nBadari\n1\n\n\nBalyana\n1\n\n\nBandar Aswan\n1\n\n\nBandar Asyut\n1\n\n\nBandar Banha\n1\n\n\nBandar Bani Suwayf\n1\n\n\nBandar Damanhur\n1\n\n\nBandar Fayyum\n1\n\n\nBandar Giza\n1\n\n\nBandar Hulwan\n1\n\n\nBandar Mahalla al-Kubra\n1\n\n\nBandar Mansura\n1\n\n\nBandar Minya\n1\n\n\nBandar Qina\n1\n\n\nBandar Shibin al-Kum\n1\n\n\nBandar Suhag\n1\n\n\nBandar Tanta 1\n1\n\n\nBandar Tanta 2\n1\n\n\nBandar Zaqaziq\n1\n\n\nBanha\n1\n\n\nBani Mazar\n1\n\n\nBani Suwayf\n1\n\n\nBarrani\n1\n\n\nBiba\n1\n\n\nBilbays\n1\n\n\nBulaq\n1\n\n\nBurullus\n1\n\n\nDaba\n1\n\n\nDamanhur\n1\n\n\nDarb al-Ahmar\n1\n\n\nDawahi Misr\n1\n\n\nDayrut\n1\n\n\nDikirnis\n1\n\n\nDilingat\n1\n\n\nDishna\n1\n\n\nDisuq\n1\n\n\nDumyat\n1\n\n\nDurr\n1\n\n\nFaqus\n1\n\n\nFariskur\n1\n\n\nFashn\n1\n\n\nFayyum\n1\n\n\nFuwwa\n1\n\n\nGamaliyya\n1\n\n\nGhardaqa\n1\n\n\nGirga\n1\n\n\nGiza\n1\n\n\nGumruk\n1\n\n\nHammam\n1\n\n\nHihya\n1\n\n\nIbshaway\n1\n\n\nIdfu\n1\n\n\nImbaba\n1\n\n\nIsmailliyya\n1\n\n\nIsna\n1\n\n\nItsa\n1\n\n\nItyay al-Barud\n1\n\n\nKafr Saqr\n1\n\n\nKafr al-Dawwar\n1\n\n\nKafr al-Shaykh\n1\n\n\nKafr al-Zayyat\n1\n\n\nKarmuz\n1\n\n\nKhalifa\n1\n\n\nKhalig al-Suways\n1\n\n\nKum Hamada\n1\n\n\nLabban\n1\n\n\nMaghagha\n1\n\n\nMahalla al-Kubra\n1\n\n\nMahmudiyya\n1\n\n\nMallawi\n1\n\n\nManfalut\n1\n\n\nManshiyya\n1\n\n\nMansura\n1\n\n\nMantiqa al-Wusta\n1\n\n\nManzala\n1\n\n\nMarsa Matruh\n1\n\n\nMina\n1\n\n\nMina al-Basal\n1\n\n\nMinuf\n1\n\n\nMinya\n1\n\n\nMinya al-Qamh\n1\n\n\nMisr al-Gadida\n1\n\n\nMisr al-Qadima\n1\n\n\nMit Ghamr\n1\n\n\nMuharram bey\n1\n\n\nMuski\n1\n\n\nNag Hammadi\n1\n\n\nPort Said (qism 1)\n1\n\n\nQalyub\n1\n\n\nQantara sharq\n1\n\n\nQina\n1\n\n\nQism al-Sharq (Maryut)\n1\n\n\nQus\n1\n\n\nQusayr\n1\n\n\nQuwisna\n1\n\n\nRaml\n1\n\n\nRashid\n1\n\n\nSaff\n1\n\n\nSallum\n1\n\n\nSamallut\n1\n\n\nSamannud\n1\n\n\nSanta\n1\n\n\nSayyida Zaynab\n1\n\n\nShibin al-Kum\n1\n\n\nShibin al-Qanatir\n1\n\n\nShirbin\n1\n\n\nShubra gharb\n1\n\n\nShubra sharq\n1\n\n\nShubrakhit\n1\n\n\nSina al-mutawassit\n1\n\n\nSina al-shimali\n1\n\n\nSina“ al-ganubi\n1\n\n\nSinballawayn\n1\n\n\nSinuris\n1\n\n\nSiwa\n1\n\n\nSuhag\n1\n\n\nSuways\n1\n\n\nTahta\n1\n\n\nTala\n1\n\n\nTalkha\n1\n\n\nTanta\n1\n\n\nTima\n1\n\n\nTukh\n1\n\n\nUqsur (Luxor)\n1\n\n\nWahat al-bahriyya\n1\n\n\nWahat al-dakhla\n1\n\n\nWahat al-kharga\n1\n\n\nWasta\n1\n\n\nWayli\n1\n\n\nZaqaziq\n1\n\n\nZifta\n1\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(is.na(district_X))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\nBahr al-Ahmar\nKhalig al-Suways\nZafarana (incl. GharibZaytiyyaDayr)\n0\n0\n214\n159\n6\n101\n52\n6\n2\n52\n0\n3\n15\n25\n1\n83\n68\n6\n39\n0\n0\n103\n698\nNA\n2\n5\n0\n1\n0\n764\n0\nNA\nNA\n0\n0\n0\n0\n\n\nBahr al-Ahmar\nKhalig al-Suways\nBi“r Udayb wa-l-Atka wa-ghubbat al-Bus wa-l-Gamasa\n0\n0\n550\n440\n4\n431\n5\n4\n0\n105\n4\n1\n52\n28\n0\n40\n369\n1\n92\n0\n0\n103\n698\nNA\n2\n5\n0\n1\n0\n764\n0\nNA\nNA\n0\n0\n0\n0\n\n\nBahr al-Ahmar\nMantiqa al-Wusta\nCairo-Suez Road\n0\n0\n143\n90\n0\n86\n4\n0\n0\n44\n9\n0\n2\n13\n0\n19\n57\n1\n40\n0\n0\n35\n117\nNA\n0\n0\n0\n0\n0\n143\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nWadi al-Natrun wa-l-Adyira wa-Bir Hukar\n0\n0\n2361\n1292\n6\n1209\n74\n9\n6\n1064\n0\n5\n117\n422\n4\n210\n917\n9\n908\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nAmiriyya\n0\n1\n1296\n645\n17\n634\n11\n0\n17\n639\n12\n0\n156\n149\n13\n210\n355\n26\n506\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nMirghib wa-Abd al-Qadir wa-Mikwariyya\n0\n0\n1421\n708\n7\n704\n4\n0\n7\n709\n4\n0\n436\n143\n37\n15\n592\n1\n606\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nIkingi Maryut wa-l-Dirisa\n0\n0\n746\n437\n2\n435\n0\n2\n0\n308\n0\n1\n188\n138\n12\n20\n358\n2\n257\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n1\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nUmm Zaghyu wa-Sidi Krir wa-l-Hawwariyya\n0\n0\n1170\n593\n0\n592\n1\n0\n0\n577\n0\n0\n388\n112\n1\n18\n498\n3\n504\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nQism al-Sharq (Maryut)\nAgami wa-l-Dira al-bahri wa-l Dayr\n0\n0\n704\n378\n0\n378\n0\n0\n0\n326\n0\n0\n239\n78\n8\n4\n314\n0\n281\n0\n0\n88\n4025\nNA\n0\n8\n0\n42\n0\n7698\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nBawiti\n0\n0\n1748\n924\n0\n916\n8\n0\n0\n820\n4\n0\n465\n174\n7\n138\n708\n8\n754\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nZabw\n0\n0\n794\n414\n0\n414\n0\n0\n0\n380\n0\n0\n242\n88\n0\n18\n342\n0\n325\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nFarafra\n0\n0\n674\n352\n0\n351\n1\n0\n0\n322\n0\n0\n222\n59\n4\n29\n273\n0\n278\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\nSahara“ al-gharbiyya\nWahat al-bahriyya\nQasr\n0\n0\n1504\n788\n0\n788\n0\n0\n0\n716\n0\n0\n418\n182\n9\n80\n597\n0\n584\n0\n0\n78\n3218\n6497\n0\n0\n0\n0\n0\n4720\n0\nNA\nNA\n0\n0\n0\n0\n\n\n\n\n\n\n\neg_subdistrict_df |&gt; filter(qism == '\nQism al-Sharq (Maryut)') |&gt; filter(is.na(district_X))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmuhafatha\nqism\nname\nmb_1940\nmb_1937\ntotal_population\nmale_total\nmale_foreigners\nmale_moslem\nmale_copt\nmale_other_religions\nfemale_foreigners\nfemale_moslem\nfemale_copt\nfemale_other_religions\nmale_farmers_fishermen_and_hunti\nmale_without_occupations\nfemale_farmers_fishermen_and_hun\nmale_age_5_and_above_read_and_wr\nmale_age_5_and_above_illiterate\nfemale_age_5_and_above_read_and_\nfemale_age_5_and_above_illiterat\nfounder_governorate\nfounder_district\n_total_gov_employees\n_population_over_5\npop_1917\ngreek\nfrench\nbritish\nitalian\nadmin_centre\ndistrict_total_pop\ntotal_missionaries\ndistrict_X\ndistrict_Y\nstate_railway_station\nbritish_military_base_1926\nbarracks_capacity_1926\nbritish_military_base_1937\n\n\n\n\n\n\n\n\n\neg_subdistrict_sf &lt;- eg_subdistrict_df |&gt; filter(!is.na(district_X)) |&gt; st_as_sf(coords = c('district_X', 'district_Y'), crs = 4326)\neg_subdistrict_sf |&gt;\n  count(qism) |&gt;\n  mapview(label = 'muhafatha')\n\n\n\n\n\n\neg_subdistrict_sf |&gt; filter(muhafatha == 'al-Qahira') |&gt; count(name) |&gt; tail()\n\n\n\n\n\nname\nn\ngeometry\n\n\n\n\nZamalik al-qibliyya\n1\nPOINT (31.2451 30.04572)\n\n\nZawiyya al-Hamra\n1\nPOINT (31.24721 30.09319)\n\n\nZaynhum\n1\nPOINT (31.24251 30.03083)\n\n\nZaytun al-gharbiyya\n1\nPOINT (31.32245 30.08976)\n\n\nZaytun al-qibliyya\n1\nPOINT (31.32245 30.08976)\n\n\nZaytun al-sharqiyya\n1\nPOINT (31.32245 30.08976)\n\n\n\n\n\n\n\negypt_sf &lt;- ne_countries(country = 'Egypt', scale = 50) |&gt; select(geounit)",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#case-preserving-the-coords",
    "href": "w6-demo-idx.html#case-preserving-the-coords",
    "title": "R Coding Workshop: Demo",
    "section": "Case: preserving the coords",
    "text": "Case: preserving the coords\n\neg_subdistrict_sf &lt;- eg_subdistrict_sf |&gt;\n  mutate(\n    longitude = format(st_coordinates(geometry)[, 1], digits = 12),\n    latitude = format(st_coordinates(geometry)[, 2], digits = 12)\n  )\n\n\neg_subdistrict_sf |&gt; select(name, longitude, latitude) |&gt; slice_sample(n = 5)\n\n\n\n\n\n\n\n\n\n\n\nname\nlongitude\nlatitude\ngeometry\n\n\n\n\nGamaliyya wa-kafr-ha\n31.9382798198\n31.1522718359\nPOINT (31.93828 31.15227)\n\n\nGazirat al-Kuraymat\n31.2964514035\n29.6267505022\nPOINT (31.29645 29.62675)\n\n\nKafr Abu Zahra\n30.4255555556\n31.2116666667\nPOINT (30.42556 31.21167)\n\n\nZahhar\n31.2468819188\n30.0590403534\nPOINT (31.24688 30.05904)\n\n\nDaba wa-Fuka wa-Ghazal\n28.2120000387\n29.8153551044\nPOINT (28.212 29.81536)",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#case-st_intersects-as-a-spatial-filter",
    "href": "w6-demo-idx.html#case-st_intersects-as-a-spatial-filter",
    "title": "R Coding Workshop: Demo",
    "section": "Case: st_intersects() as a spatial filter",
    "text": "Case: st_intersects() as a spatial filter\n\nintersect_list &lt;- st_intersects(eg_subdistrict_sf, egypt_sf)\nintersect_list |&gt; class()\n\n[1] \"sgbp\" \"list\"\n\n\n\neg_subdistrict_sf$n_intersections &lt;- lengths(intersect_list)\n\n\neg_subdistrict_sf |&gt;\n  filter(n_intersections &lt; 1) |&gt; mapview()",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#flip_lonlat-function",
    "href": "w6-demo-idx.html#flip_lonlat-function",
    "title": "R Coding Workshop: Demo",
    "section": "flip_lonlat() Function",
    "text": "flip_lonlat() Function\n\nflip_lonlat &lt;- function(geom) {\n    old_coords &lt;- st_coordinates(geom)\n\n    st_point(c(old_coords[2], old_coords[1]))\n}\n\n\nflipped_sf &lt;- eg_subdistrict_sf |&gt;\n  filter(n_intersections &lt; 1) |&gt;\n  mutate(geometry = map(geometry, flip_lonlat) |&gt;\n  st_sfc(crs = 4326))\nflipped_sf |&gt; mapview()\n\n\n\n\n\n\nflipped_sf |&gt; select(longitude, latitude) |&gt; slice_sample(n = 4)\n\n\n\n\n\nlongitude\nlatitude\ngeometry\n\n\n\n\n29.4075000000\n31.1727777778\nPOINT (31.17278 29.4075)\n\n\n30.5941666667\n32.3027777778\nPOINT (32.30278 30.59417)\n\n\n29.8735910960\n31.1983294747\nPOINT (31.19833 29.87359)\n\n\n29.8735910960\n31.1983294747\nPOINT (31.19833 29.87359)\n\n\n\n\n\n\n\nsanity check here, Rafah crossing, Ismailiya, Giza and Port Said, at a quick look everything seems to be in place\n\n\nflipped_sf |&gt; st_crs()\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        MEMBER[\"World Geodetic System 1984 (G2296)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\n\nflipped_sf |&gt;\n  ggplot() + \n  geom_sf()",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#case-update",
    "href": "w6-demo-idx.html#case-update",
    "title": "R Coding Workshop: Demo",
    "section": "Case: Update",
    "text": "Case: Update\n\nflipped_sf &lt;- flipped_sf |&gt;\n  mutate(\n    old_lon = longitude,\n    longitude = latitude,\n    latitude = old_lon\n  ) |&gt;\n  select(-old_lon)\n\nflipped_sf |&gt; select(longitude, latitude) |&gt; slice_sample(n = 4)\n\n\n\n\n\nlongitude\nlatitude\ngeometry\n\n\n\n\n31.1727777778\n29.4075000000\nPOINT (31.17278 29.4075)\n\n\n34.8955555556\n29.4919444444\nPOINT (34.89556 29.49194)\n\n\n32.3027777778\n30.5941666667\nPOINT (32.30278 30.59417)\n\n\n34.8955555556\n29.4919444444\nPOINT (34.89556 29.49194)\n\n\n\n\n\n\n\nflipped_sf |&gt; mapview(label = 'qism')\n\n\n\n\n\n\nvalid_sf &lt;- eg_subdistrict_sf |&gt;\n  filter(n_intersections &gt; 0)\nvalid_sf |&gt; dim()\n\n[1] 4122   42\n\n\n\nfixed_subdistrict_sf &lt;- bind_rows(valid_sf, flipped_sf)\n\n\nfixed_subdistrict_sf |&gt; count(qism) |&gt; mapview(label = 'muhafatha')\n\n\n\n\n\n\nfixed_subdistrict_sf |&gt; summary()\n\n  muhafatha             qism               name              mb_1940       \n Length:4217        Length:4217        Length:4217        Min.   :0.00000  \n Class :character   Class :character   Class :character   1st Qu.:0.00000  \n Mode  :character   Mode  :character   Mode  :character   Median :0.00000  \n                                                          Mean   :0.05644  \n                                                          3rd Qu.:0.00000  \n                                                          Max.   :1.00000  \n                                                                           \n    mb_1937        total_population   male_total    male_foreigners  \n Min.   :0.00000   Min.   :    0    Min.   :    0   Min.   :   0.00  \n 1st Qu.:0.00000   1st Qu.: 1462    1st Qu.:  713   1st Qu.:   0.00  \n Median :0.00000   Median : 2625    Median : 1296   Median :   0.00  \n Mean   :0.04814   Mean   : 3772    Mean   : 1887   Mean   :  21.61  \n 3rd Qu.:0.00000   3rd Qu.: 4721    3rd Qu.: 2348   3rd Qu.:   0.00  \n Max.   :1.00000   Max.   :68887    Max.   :34702   Max.   :5812.00  \n                                                                     \n  male_moslem      male_copt     male_other_religions female_foreigners\n Min.   :    0   Min.   :    0   Min.   :   0.00      Min.   :   0.0   \n 1st Qu.:  667   1st Qu.:    1   1st Qu.:   0.00      1st Qu.:   0.0   \n Median : 1212   Median :   12   Median :   0.00      Median :   0.0   \n Mean   : 1724   Mean   :  131   Mean   :  32.35      Mean   :  22.6   \n 3rd Qu.: 2203   3rd Qu.:   74   3rd Qu.:   0.00      3rd Qu.:   0.0   \n Max.   :30338   Max.   :10476   Max.   :8684.00      Max.   :6622.0   \n                                                                       \n female_moslem    female_copt     female_other_religions\n Min.   :    0   Min.   :   0.0   Min.   :   0.00       \n 1st Qu.:  686   1st Qu.:   0.0   1st Qu.:   0.00       \n Median : 1236   Median :  11.0   Median :   0.00       \n Mean   : 1724   Mean   : 126.3   Mean   :  34.69       \n 3rd Qu.: 2203   3rd Qu.:  71.0   3rd Qu.:   0.00       \n Max.   :29436   Max.   :9956.0   Max.   :9793.00       \n                                                        \n male_farmers_fishermen_and_hunti male_without_occupations\n Min.   :    0.0                  Min.   :   0.0          \n 1st Qu.:  325.0                  1st Qu.:  56.0          \n Median :  653.0                  Median : 126.0          \n Mean   :  854.2                  Mean   : 209.8          \n 3rd Qu.: 1154.0                  3rd Qu.: 245.0          \n Max.   :10655.0                  Max.   :5315.0          \n                                                          \n female_farmers_fishermen_and_hun male_age_5_and_above_read_and_wr\n Min.   :   0.0                   Min.   :    0.0                 \n 1st Qu.:  10.0                   1st Qu.:  110.0                 \n Median :  59.0                   Median :  226.0                 \n Mean   : 166.7                   Mean   :  447.1                 \n 3rd Qu.: 222.0                   3rd Qu.:  441.0                 \n Max.   :2409.0                   Max.   :20422.0                 \n                                                                  \n male_age_5_and_above_illiterate female_age_5_and_above_read_and_\n Min.   :    0                   Min.   :   0.0                  \n 1st Qu.:  468                   1st Qu.:  30.0                  \n Median :  862                   Median :  65.0                  \n Mean   : 1198                   Mean   : 162.1                  \n 3rd Qu.: 1514                   3rd Qu.: 130.0                  \n Max.   :18105                   Max.   :9382.0                  \n                                                                 \n female_age_5_and_above_illiterat founder_governorate founder_district \n Min.   :    0                    Min.   :0.0000      Min.   :0.00000  \n 1st Qu.:  589                    1st Qu.:0.0000      1st Qu.:0.00000  \n Median : 1060                    Median :0.0000      Median :0.00000  \n Mean   : 1465                    Mean   :0.3118      Mean   :0.03083  \n 3rd Qu.: 1844                    3rd Qu.:1.0000      3rd Qu.:0.00000  \n Max.   :22423                    Max.   :1.0000      Max.   :1.00000  \n                                                                       \n _total_gov_employees _population_over_5    pop_1917          greek        \n Min.   :  13         Min.   :   761     Min.   :   623   Min.   :    0.0  \n 1st Qu.: 709         1st Qu.:109088     1st Qu.:100701   1st Qu.:   12.0  \n Median : 941         Median :134725     Median :132868   Median :   33.0  \n Mean   :1105         Mean   :137403     Mean   :135033   Mean   :  208.2  \n 3rd Qu.:1365         3rd Qu.:174334     3rd Qu.:164472   3rd Qu.:   69.0  \n Max.   :6833         Max.   :237572     Max.   :411898   Max.   :13445.0  \n                                         NA's   :33                        \n     french           british           italian        admin_centre    \n Min.   :   0.00   Min.   :   0.00   Min.   :   0.0   Min.   :0.00000  \n 1st Qu.:   0.00   1st Qu.:   1.00   1st Qu.:   1.0   1st Qu.:0.00000  \n Median :   2.00   Median :   3.00   Median :   4.0   Median :0.00000  \n Mean   :  67.29   Mean   :  98.59   Mean   : 150.9   Mean   :0.02822  \n 3rd Qu.:  18.00   3rd Qu.:   8.00   3rd Qu.:  15.0   3rd Qu.:0.00000  \n Max.   :2165.00   Max.   :4985.00   Max.   :8349.0   Max.   :1.00000  \n                                                                       \n district_total_pop total_missionaries state_railway_station\n Min.   :   847     Min.   : 0.000     Min.   :0.0000       \n 1st Qu.:124482     1st Qu.: 0.000     1st Qu.:0.0000       \n Median :156509     Median : 1.000     Median :0.0000       \n Mean   :158585     Mean   : 1.841     Mean   :0.0913       \n 3rd Qu.:200369     3rd Qu.: 2.000     3rd Qu.:0.0000       \n Max.   :273657     Max.   :67.000     Max.   :1.0000       \n                                                            \n british_military_base_1926 barracks_capacity_1926 british_military_base_1937\n Min.   :0.00000            Min.   :   0.00        Min.   :0.00000           \n 1st Qu.:0.00000            1st Qu.:   0.00        1st Qu.:0.00000           \n Median :0.00000            Median :   0.00        Median :0.00000           \n Mean   :0.03344            Mean   :  42.42        Mean   :0.03249           \n 3rd Qu.:0.00000            3rd Qu.:   0.00        3rd Qu.:0.00000           \n Max.   :1.00000            Max.   :3930.00        Max.   :1.00000           \n                                                                             \n          geometry     longitude           latitude         n_intersections \n POINT        :4217   Length:4217        Length:4217        Min.   :0.0000  \n epsg:4326    :   0   Class :character   Class :character   1st Qu.:1.0000  \n +proj=long...:   0   Mode  :character   Mode  :character   Median :1.0000  \n                                                            Mean   :0.9775  \n                                                            3rd Qu.:1.0000  \n                                                            Max.   :1.0000  \n                                                                            \n\n\n\nfixed_subdistrict_sf |&gt; count(qism, latitude, longitude) |&gt; slice_sample(n = 10)\n\n\n\n\n\n\n\n\n\n\n\n\nqism\nlatitude\nlongitude\nn\ngeometry\n\n\n\n\nDishna\n26.1415364212\n32.4521515901\n17\nPOINT (32.45215 26.14154)\n\n\nBanha\n31.2116666667\n30.4255555556\n40\nPOINT (30.42556 31.21167)\n\n\nSanta\n30.7458440000\n31.1067280000\n55\nPOINT (31.10673 30.74584)\n\n\nSuhag\n26.5586210174\n31.6831132124\n49\nPOINT (31.68311 26.55862)\n\n\nDawahi Misr\n30.0827450000\n31.2760470000\n7\nPOINT (31.27605 30.08274)\n\n\nMansura\n31.0336540485\n31.4665244084\n65\nPOINT (31.46652 31.03365)\n\n\nBarrani\n30.5129737001\n25.8888016118\n1\nPOINT (25.8888 30.51297)\n\n\nItyay al-Barud\n30.8875879413\n30.6579556875\n57\nPOINT (30.65796 30.88759)\n\n\nBani Mazar\n28.4892190000\n30.7524060000\n56\nPOINT (30.75241 28.48922)\n\n\nMuharram bey\n31.1848081714\n29.9359493054\n9\nPOINT (29.93595 31.18481)\n\n\n\n\n\n\n\nfixed_subdistrict_sf |&gt; count(qism, latitude, longitude) |&gt; dim()\n\n[1] 142   5\n\n\n\nfixed_subdistrict_sf |&gt; arrange(desc(greek)) |&gt; head(10) |&gt; mapview()\n\n\n\n\n\n\nfixed_subdistrict_sf |&gt; filter(muhafatha == 'al-Qahira') |&gt; arrange(desc(french)) |&gt; head(10) |&gt; mapview()",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  },
  {
    "objectID": "w6-demo-idx.html#footnotes",
    "href": "w6-demo-idx.html#footnotes",
    "title": "R Coding Workshop: Demo",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nsome variables are attributes of divisions a level higher↩︎\nThere weren’t more than one presence of MB branches in a subdistrict, thus of the 4000 subdistrict, each can be mark as presence or absence of MB branch↩︎",
    "crumbs": [
      "Coding Workshop",
      "Week 6 Demo"
    ]
  }
]